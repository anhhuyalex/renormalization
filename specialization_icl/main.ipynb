{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "from enum import Enum\n",
    "import importlib\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim.lr_scheduler import StepLR, OneCycleLR\n",
    "from torch.utils.data import Subset\n",
    "import attention\n",
    "# import webdataset as wds\n",
    "\n",
    "import datetime\n",
    "import utils\n",
    "import numpy as np\n",
    "import math\n",
    "import einops\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import wandb \n",
    "import sys \n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--data ./cache --fileprefix transformer --SLURM_ARRAY_TASK_ID 0 --batch-size 256 --optimizer SGD --scheduler None --lr 0.1 --wd 0.0  --epochs 90 --arch gpt --gpt_bias True --num_hidden_features 128 --num_layers 8 --len_context 100 --K 1 --D_sum 64 --sigma_xi 0.5 --coarse_graining abstop --no-wandb_log --wandb_project renormalization --is_iso False --wandb_group_name test\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "LOCAL RANK  0\n",
      "args:\n",
      " {'data': './cache', 'cache': './cache', 'wandb_log': False, 'wandb_project': 'renormalization', 'wandb_group_name': 'test', 'seed': 1253529, 'epochs': 90, 'batch_size': 256, 'workers': 4, 'optimizer': 'SGD', 'scheduler': 'None', 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0, 'arch': 'gpt', 'gpt_bias': 'True', 'num_hidden_features': 128, 'num_layers': 8, 'len_context': 100, 'SLURM_ARRAY_TASK_ID': 0, 'no_cuda': False, 'D_sum': 64, 'D_visible_frac': 1.0, 'K': 1, 'coarse_graining': 'abstop', 'sigma_xi': 0.5, 'is_iso': 'False', 'fileprefix': 'transformer', 'D_visible': 1}\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='GMM L2L Training with Sequence Model')\n",
    "parser.add_argument('--data', metavar='DIR', nargs='?', default='./data',\n",
    "                    help='path to dataset (default: imagenet)')\n",
    "parser.add_argument('--cache', default='./cache',\n",
    "                    help='path to cached files (e.g. for previous random weights)')\n",
    "parser.add_argument(\n",
    "    \"--wandb_log\",action=argparse.BooleanOptionalAction,default=False,\n",
    "    help=\"whether to log to wandb\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--wandb_project\",type=str,default=\"stability\",\n",
    "    help=\"wandb project name\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--wandb_group_name\",type=str,default=\"stability\",\n",
    "    help=\"wandb project name\",\n",
    ")\n",
    "parser.add_argument('--seed', default=None, type=int,\n",
    "                    help='seed for initializing training.')\n",
    "parser.add_argument('--epochs', default=90, type=int,  \n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('-b', '--batch-size', default=64, type=int,\n",
    "                    metavar='N',\n",
    "                    help='mini-batch size (default: 256), this is the total '\n",
    "                         'batch size of all GPUs on the current node when '\n",
    "                         'using Data Parallel or Distributed Data Parallel')                         \n",
    "parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 4)')\n",
    "parser.add_argument('--optimizer', default='SGD', type=str, \n",
    "                    choices = ['SGD', 'Adam'],\n",
    "                    help='optimizer')\n",
    "parser.add_argument('--scheduler', default='OneCycleLR', type=str, \n",
    "                    help='scheduler')\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.1, type=float,\n",
    "                    metavar='LR', help='initial learning rate', dest='lr')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
    "                    help='momentum')\n",
    "parser.add_argument('--wd', '--weight-decay', default=1e-5, type=float,\n",
    "                    metavar='W', help='weight decay (default: 1e-4)',\n",
    "                    dest='weight_decay')\n",
    "parser.add_argument('--arch', '-a', metavar='ARCH', default='mlp',\n",
    "                    help='model architecture (default: mlp)')\n",
    "parser.add_argument('--gpt_bias', default=\"True\", type=str,\n",
    "                    help='whether to include bias in GPT')\n",
    "parser.add_argument('--num_hidden_features', default=1, type=int,\n",
    "                    help='num_hidden_features')\n",
    "parser.add_argument('--num_layers', default=1, type=int,\n",
    "                    help='num_layers in transformer')\n",
    "parser.add_argument('--len_context', default=1, type=int,\n",
    "                    help='number of in-context images in sequence')\n",
    "parser.add_argument('--SLURM_ARRAY_TASK_ID', default=1, type=int,\n",
    "                    help='SLURM_ARRAY_TASK_ID')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                        help='disables CUDA training')  \n",
    "parser.add_argument('--D_sum', default=1000, type=int, help='number of visible+ hidden features')\n",
    "parser.add_argument('--D_visible_frac', default=1.0, type=float, help='fraction of features visible') \n",
    "parser.add_argument('--K', default=1, type=int, \n",
    "                    help='number of tasks')\n",
    "parser.add_argument('--coarse_graining', default=\"abstop\", type=str,\n",
    "                    help='coarse graining method')\n",
    "parser.add_argument('--sigma_xi', default=1.0, type=float, help='noise level')\n",
    "parser.add_argument('--data_scale', default=1.0, type=float, help='data scale')\n",
    "parser.add_argument('--is_iso', default=\"True\", type=str, \n",
    "                    help='whether to use isotropic data')\n",
    "parser.add_argument(\n",
    "            '--fileprefix', \n",
    "            default=\"\",\n",
    "            type=str, \n",
    "            action='store') \n",
    "    \n",
    "\n",
    "# if running this interactively, can specify jupyter_args here for argparser to use\n",
    "if utils.is_interactive():\n",
    "    arch = \"pytorch_transformer\"\n",
    "    # arch = \"transformer\"\n",
    "    SLURM_ARRAY_TASK_ID = 0\n",
    "    optimizer = \"SGD\"\n",
    "    lr = 0.1\n",
    "    epochs = 90\n",
    "    gpt_bias = \"True\"\n",
    "    len_context = 100\n",
    "    K = 1\n",
    "    D_sum = 64 \n",
    "    \n",
    "    jupyter_args = f\"--data ./cache --fileprefix transformer --SLURM_ARRAY_TASK_ID ${SLURM_ARRAY_TASK_ID} --batch-size 256 --optimizer ${optimizer} --scheduler None --lr ${lr} --wd 0.0  --epochs ${epochs} --arch gpt --gpt_bias ${gpt_bias} --num_hidden_features 128 --num_layers 8 --len_context ${len_context} --K ${K} --D_sum ${D_sum} --sigma_xi 0.5 --coarse_graining abstop --no-wandb_log --wandb_project renormalization --is_iso False --wandb_group_name test\"\n",
    "    # remove $ from string \n",
    "    jupyter_args = jupyter_args.replace(\"$\",\"\")\n",
    "    print(jupyter_args)\n",
    "    jupyter_args = jupyter_args.split()\n",
    "    \n",
    "    from IPython.display import clear_output # function to clear print outputs in cell\n",
    "    %load_ext autoreload \n",
    "    # this allows you to change functions in models.py or utils.py and have this notebook automatically update with your revisions\n",
    "    %autoreload 2 \n",
    "\n",
    "if utils.is_interactive():\n",
    "    args = parser.parse_args(jupyter_args)\n",
    "else:\n",
    "    args = parser.parse_args()\n",
    "\n",
    "args.D_visible = int(args.D_visible_frac) # just using D=8 max(int(args.D_visible_frac * args.D_sum),1)\n",
    "# assert args.K % args.L == 0, \"K must be divisible by L\"\n",
    "if args.seed is None:\n",
    "    args.seed = np.random.randint(0, 10000000)\n",
    "\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed_all(args.seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "  \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Local Rank for distributed training\n",
    "local_rank = os.getenv('RANK')\n",
    "if local_rank is None: \n",
    "    local_rank = 0\n",
    "else:\n",
    "    local_rank = int(local_rank)\n",
    "print(\"LOCAL RANK \", local_rank)\n",
    "print(\"args:\\n\",vars(args))\n",
    "# setup weights and biases (optional)\n",
    "if local_rank==0 and args.wandb_log: # only use main process for wandb logging\n",
    "    print(f\"wandb {args.wandb_project} run\")\n",
    "    wandb.login(host='https://stability.wandb.io') # need to configure wandb environment beforehand\n",
    "    wandb_model_name = f\"{args.fileprefix}_K_{args.K}_D_{args.D_sum}_L_{args.len_context}_hidden_{args.num_hidden_features}_coarse_{args.coarse_graining}\"\n",
    "    wandb_config = vars(args)\n",
    "    \n",
    "    print(\"wandb_id:\",wandb_model_name)\n",
    "    wandb.init(\n",
    "        project=args.wandb_project,\n",
    "        name=wandb_model_name,\n",
    "        config=wandb_config,\n",
    "        resume=\"allow\",\n",
    "        group=args.wandb_group_name\n",
    "    )\n",
    "    wandb.config.local_file_dir = wandb.run.dir \n",
    "else:\n",
    "    record = {\n",
    "        \"args\": vars(args),\n",
    "        \"logs\": []\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequence(torch.utils.data.Dataset):\n",
    "    def __init__(self, K, D,  \n",
    "                 len_context = 1,\n",
    "                 scale=0.5,\n",
    "                len_data = 60000, skip_generating_betas=False,\n",
    "                input_covariance = None, is_iso = \"True\"\n",
    "                ):\n",
    "\n",
    "        # if K < 40000:\n",
    "        self.len_context = len_context\n",
    "        self.D = D\n",
    "    \n",
    "        # x = rng.standard_normal((K, D)) * (1.0 / np.sqrt(D)) # shape: (K, D) \n",
    "        self.scale = scale\n",
    "        if skip_generating_betas == False:\n",
    "            true_betas = torch.randn((K, D)) * scale #* (1.0 / np.sqrt(D)) # shape: (K, D)\n",
    "            self.true_betas = true_betas\n",
    "        self.K = K \n",
    "        self.D = D\n",
    "        self.len_data = len_data\n",
    "        if is_iso == \"True\":\n",
    "            self.input_covariance_L = None\n",
    "        else:\n",
    "            print (\"anisotropic case\")\n",
    "            sminus = 0.1\n",
    "            splus = 1.0\n",
    "            # The proportion of eigenvalues at s₋ should be ρ₋\n",
    "            rho_minus = 0.5\n",
    "            # The proportion of eigenvalues at s₊ should be 1-ρ₋\n",
    "            input_covariance = torch.eye(D)\n",
    "            \n",
    "            # Calculate number of eigenvalues for each mode \n",
    "            num_minus = int(D * rho_minus)\n",
    "            num_plus = D - num_minus\n",
    "            \n",
    "            # Create diagonal matrix of eigenvalues\n",
    "            eigenvalues = np.concatenate([\n",
    "                np.ones(num_plus) * splus,\n",
    "                np.ones(num_minus) * sminus\n",
    "            ])\n",
    "            \n",
    "            # Generate random orthogonal matrix\n",
    "            # Q = np.linalg.qr(np.random.randn(D_sum, D_sum))[0]\n",
    "            \n",
    "            # Construct covariance matrix \n",
    "            # input_covariance = torch.tensor(Q @ np.diag(eigenvalues) @ Q.T, dtype=torch.float32) \n",
    "            input_covariance = torch.tensor(np.diag(eigenvalues), dtype=torch.float32) \n",
    "            # self.input_covariance_L = torch.linalg.cholesky(input_covariance)  \n",
    "            # self.input_covariance = input_covariance.to(device)  \n",
    "            self.input_covariance_L = torch.sqrt(torch.tensor(eigenvalues, dtype=torch.float32))\n",
    "            self.true_betas[:,num_plus:] = self.true_betas[:,num_plus:] * (np.sqrt(10)) \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len_data\n",
    "\n",
    "    def __getitem__(self, task: int):\n",
    "        task_ind = torch.randint(0, self.K, (1,)).item()\n",
    "        beta_incontext = self.true_betas[task_ind].unsqueeze(1) # shape: (D, 1)\n",
    "        if self.input_covariance_L is None:\n",
    "            x = torch.randn((self.len_context, self.D)) * self.scale  # shape: (self.len_context, D) * (1.0 / np.sqrt(self.D))\n",
    "        else: \n",
    "            x = torch.randn((self.len_context, self.D)) * self.input_covariance_L  \n",
    "            # x = torch.matmul(x, self.input_covariance_L.T) \n",
    "        noise = torch.randn((self.len_context, 1)) * args.sigma_xi\n",
    "        y = torch.matmul(x, beta_incontext) + noise\n",
    "\n",
    "        # concat x and y \n",
    "        samples = x#torch.cat([x, y], axis = 1) # shape: (self.len_context, D+1)\n",
    "        # ytest = samples[-1, -1].clone() \n",
    "        # samples[-1, -1] = 0.0 # remove ytest from samples \n",
    "         \n",
    "          \n",
    "        return samples.type(torch.float32), y.type(torch.float32), beta_incontext.type(torch.float32)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 1620739\n"
     ]
    }
   ],
   "source": [
    "# importlib.reload(gpt)\n",
    "import gpt\n",
    "criterion = nn.MSELoss().to(device)\n",
    "# define the model, optimizer, and scheduler, and criterion\n",
    " \n",
    "if args.arch == \"gpt\":\n",
    "    import gpt \n",
    "    config = gpt.GPTConfig(\n",
    "        block_size = args.len_context,\n",
    "        input_size = args.D_sum,\n",
    "        n_embd=args.num_hidden_features,\n",
    "        n_layer=args.num_layers,\n",
    "        bias = args.gpt_bias == \"True\"\n",
    "    )\n",
    "    model = gpt.GPT(config, criterion).to(device)\n",
    "\n",
    "if args.optimizer == 'SGD': \n",
    "    optimizer = torch.optim.SGD(model.parameters(),  \n",
    "                            lr=args.lr, \n",
    "                            weight_decay=args.weight_decay\n",
    "                            )\n",
    "elif args.optimizer == 'Adam':\n",
    "    optimizer = torch.optim.Adam(model.parameters(),  \n",
    "                            lr=args.lr, \n",
    "                            weight_decay=args.weight_decay\n",
    "                            )\n",
    "else:\n",
    "    raise ValueError(\"optimizer not recognized\")\n",
    "iters_per_epoch = 1000\n",
    "# scheduler = StepLR(optimizer, step_size=50, gamma=0.7)\n",
    "if args.scheduler == 'CosineOneCycleLR':\n",
    "    scheduler = OneCycleLR(optimizer, max_lr=args.lr, \n",
    "                        total_steps=args.epochs * iters_per_epoch, \n",
    "                        pct_start=0.5,\n",
    "                        steps_per_epoch=iters_per_epoch, epochs=args.epochs)\n",
    "elif args.scheduler == 'None':\n",
    "    scheduler = utils.EmptyScheduler()\n",
    "elif args.scheduler == 'Triangle':\n",
    "    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, \n",
    "                               base_lr=args.lr/10,\n",
    "                               max_lr=args.lr, \n",
    "                        step_size_up=args.epochs * iters_per_epoch / 2,\n",
    "                        step_size_down= args.epochs * iters_per_epoch / 2,\n",
    "                        mode = \"triangular\",\n",
    "                        cycle_momentum=False\n",
    "                        )\n",
    "    \n",
    "elif args.scheduler == 'LinearWarmUpCosineDecay':\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "                                                    max_lr=args.lr,\n",
    "    epochs=args.epochs,\n",
    "    steps_per_epoch= iters_per_epoch,\n",
    "    pct_start=0.01,\n",
    "    anneal_strategy='cos',\n",
    "    three_phase=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anisotropic case\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gpfs/qanguyen/learning_to_learn/l2l/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "# define the dataset\n",
    "train_kwargs = {'batch_size': args.batch_size}\n",
    "test_kwargs = {'batch_size': args.batch_size}\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    cuda_kwargs = {'num_workers': args.workers,\n",
    "                    \"shuffle\": True,\n",
    "                    'pin_memory': True}\n",
    "    train_kwargs.update(cuda_kwargs)\n",
    "    test_kwargs.update(cuda_kwargs)\n",
    "train_dataset = Sequence(K=args.K, D=args.D_sum, len_context=args.len_context, len_data = args.batch_size * iters_per_epoch,\n",
    "                         scale = args.data_scale, is_iso = args.is_iso \n",
    "                         )\n",
    "# iwl_dataset = Sequence(K=args.K, D=args.D_sum, len_context=args.len_context, len_data = 1000)\n",
    "# iwl_dataset.true_betas = train_dataset.true_betas\n",
    "# icl_test_dataset = Sequence(K=1000, D=args.D_sum, len_context=args.len_context, len_data = 1000,\n",
    "#                             scale = 1.0)\n",
    "\n",
    "# iwl_test_dataset = Sequence(K=args.K, D=args.D_sum, len_context=args.len_context, len_data = 1000, skip_generating_betas = True,\n",
    "#                             scale = 1.0)\n",
    "# iwl_test_dataset.true_betas = train_dataset.true_betas\n",
    "\n",
    "train_sampler = None\n",
    "val_sampler = None \n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                            sampler=train_sampler, \n",
    "                                            **train_kwargs) \n",
    "# icl_test_loader = torch.utils.data.DataLoader(icl_test_dataset,\n",
    "#                                             sampler=val_sampler,\n",
    "#                                             **test_kwargs)  \n",
    "# iwl_test_loader = torch.utils.data.DataLoader(iwl_test_dataset,\n",
    "#                                             sampler=val_sampler,\n",
    "#                                             **test_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # x, y, b = train_dataset[0]\n",
    "# # print (x.shape, y.shape, b.shape)\n",
    "# plt.hist (b[:32].flatten().cpu().numpy(), bins = 5, alpha = 0.5)\n",
    "# plt.hist (b[32:].flatten().cpu().numpy(), bins = 5, alpha = 0.5)\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.2411e+00],\n",
      "        [ 1.2822e+01],\n",
      "        [ 1.5056e+01],\n",
      "        [ 1.7491e+00],\n",
      "        [ 6.1118e+00],\n",
      "        [ 1.0021e+01],\n",
      "        [-2.4793e+00],\n",
      "        [-4.9127e-01],\n",
      "        [ 7.0526e+00],\n",
      "        [-8.5008e-03],\n",
      "        [ 1.1371e+01],\n",
      "        [ 9.3700e+00],\n",
      "        [-2.2212e+01],\n",
      "        [ 2.3143e+00],\n",
      "        [-1.6704e+01],\n",
      "        [ 1.6840e+00],\n",
      "        [-5.1115e-01],\n",
      "        [-5.9581e+00],\n",
      "        [ 1.1330e+00],\n",
      "        [-1.5890e+01],\n",
      "        [-5.9318e-01],\n",
      "        [ 1.5053e+01],\n",
      "        [ 8.2325e+00],\n",
      "        [-4.5079e+00],\n",
      "        [-8.1646e+00],\n",
      "        [-2.7989e-01],\n",
      "        [-1.7267e+00],\n",
      "        [ 1.8823e+00],\n",
      "        [ 5.8507e-01],\n",
      "        [ 6.7753e+00],\n",
      "        [-1.3547e+00],\n",
      "        [ 1.0367e+01],\n",
      "        [-4.5207e+00],\n",
      "        [-7.3165e+00],\n",
      "        [ 5.3345e+00],\n",
      "        [ 8.3946e+00],\n",
      "        [-1.6163e+00],\n",
      "        [-6.4064e+00],\n",
      "        [-9.1240e+00],\n",
      "        [ 9.8480e+00],\n",
      "        [ 7.3765e+00],\n",
      "        [ 5.1869e+00],\n",
      "        [-2.9770e+00],\n",
      "        [-2.3280e-01],\n",
      "        [-3.9282e+00],\n",
      "        [ 2.8425e+00],\n",
      "        [-6.1672e+00],\n",
      "        [ 6.1085e+00],\n",
      "        [-2.1005e+00],\n",
      "        [-6.6779e+00],\n",
      "        [ 4.1459e+00],\n",
      "        [-5.8224e+00],\n",
      "        [ 8.2491e-01],\n",
      "        [-9.0497e+00],\n",
      "        [ 6.2538e+00],\n",
      "        [-3.0408e+00],\n",
      "        [ 2.3005e+00],\n",
      "        [ 9.3876e+00],\n",
      "        [ 1.2100e+00],\n",
      "        [ 2.8693e+00],\n",
      "        [ 1.6136e+00],\n",
      "        [ 5.8829e+00],\n",
      "        [-9.3422e-01],\n",
      "        [-3.5898e+00],\n",
      "        [ 1.4161e+01],\n",
      "        [ 1.0634e+01],\n",
      "        [ 5.8216e+00],\n",
      "        [ 6.6912e+00],\n",
      "        [-3.3446e-01],\n",
      "        [-6.6434e+00],\n",
      "        [ 8.0530e+00],\n",
      "        [ 3.9468e+00],\n",
      "        [-1.2829e+01],\n",
      "        [ 2.1457e+00],\n",
      "        [ 1.2564e+01],\n",
      "        [-8.9902e+00],\n",
      "        [ 1.1131e+01],\n",
      "        [-2.0539e+01],\n",
      "        [ 4.5820e+00],\n",
      "        [ 3.6950e+00],\n",
      "        [-1.8250e+00],\n",
      "        [ 1.3341e+01],\n",
      "        [ 2.1683e+01],\n",
      "        [ 6.2896e+00],\n",
      "        [-7.1773e-01],\n",
      "        [-1.6111e+01],\n",
      "        [-9.0289e+00],\n",
      "        [-4.1800e+00],\n",
      "        [-1.0833e+01],\n",
      "        [-2.1395e-01],\n",
      "        [ 8.3808e+00],\n",
      "        [ 1.5520e+01],\n",
      "        [ 1.0153e+01],\n",
      "        [-5.5543e+00],\n",
      "        [ 1.0379e+01],\n",
      "        [ 1.3678e+01],\n",
      "        [-8.7876e+00],\n",
      "        [-8.8110e-01],\n",
      "        [-1.3086e+01],\n",
      "        [-1.1909e+00]])\n",
      "tensor([[  4.6124],\n",
      "        [ 12.5444],\n",
      "        [ 14.9370],\n",
      "        [  2.1013],\n",
      "        [  5.7836],\n",
      "        [ 10.0822],\n",
      "        [ -2.6814],\n",
      "        [ -0.5505],\n",
      "        [  7.2947],\n",
      "        [  0.3374],\n",
      "        [ 11.1641],\n",
      "        [  8.9645],\n",
      "        [-22.6487],\n",
      "        [  2.1035],\n",
      "        [-16.3219],\n",
      "        [  2.5376],\n",
      "        [ -0.7936],\n",
      "        [ -5.7545],\n",
      "        [  2.2782],\n",
      "        [-16.1516],\n",
      "        [  0.5527],\n",
      "        [ 14.8114],\n",
      "        [  7.5034],\n",
      "        [ -5.1672],\n",
      "        [ -8.1845],\n",
      "        [  0.1063],\n",
      "        [ -1.2251],\n",
      "        [  1.8292],\n",
      "        [ -0.1699],\n",
      "        [  6.8188],\n",
      "        [ -1.6875],\n",
      "        [ 10.5493],\n",
      "        [ -4.3341],\n",
      "        [ -7.3365],\n",
      "        [  5.5189],\n",
      "        [  7.8953],\n",
      "        [ -0.9479],\n",
      "        [ -7.2565],\n",
      "        [ -8.9237],\n",
      "        [  9.1051],\n",
      "        [  7.5455],\n",
      "        [  5.5540],\n",
      "        [ -3.0047],\n",
      "        [ -0.1112],\n",
      "        [ -3.2564],\n",
      "        [  2.3916],\n",
      "        [ -6.0973],\n",
      "        [  5.1745],\n",
      "        [ -1.2179],\n",
      "        [ -7.2039],\n",
      "        [  4.3213],\n",
      "        [ -5.8732],\n",
      "        [  1.1804],\n",
      "        [ -8.0935],\n",
      "        [  5.9884],\n",
      "        [ -3.6834],\n",
      "        [  2.2348],\n",
      "        [  9.6753],\n",
      "        [  1.5396],\n",
      "        [  2.6552],\n",
      "        [  1.8420],\n",
      "        [  5.9275],\n",
      "        [ -1.5129],\n",
      "        [ -3.4311],\n",
      "        [ 13.5373],\n",
      "        [ 10.2897],\n",
      "        [  5.7451],\n",
      "        [  6.3826],\n",
      "        [ -0.1563],\n",
      "        [ -6.3523],\n",
      "        [  7.9102],\n",
      "        [  4.4914],\n",
      "        [-12.9691],\n",
      "        [  2.0035],\n",
      "        [ 11.7505],\n",
      "        [ -8.4461],\n",
      "        [ 10.6951],\n",
      "        [-19.7906],\n",
      "        [  3.8570],\n",
      "        [  3.8971],\n",
      "        [ -1.8666],\n",
      "        [ 12.7043],\n",
      "        [ 21.4406],\n",
      "        [  6.6746],\n",
      "        [ -0.6676],\n",
      "        [-16.4020],\n",
      "        [ -9.2904],\n",
      "        [ -3.2152],\n",
      "        [-11.4612],\n",
      "        [  0.2350],\n",
      "        [  8.2509],\n",
      "        [ 16.5798],\n",
      "        [ 10.7729],\n",
      "        [ -5.8631],\n",
      "        [  9.8699],\n",
      "        [ 13.4029],\n",
      "        [ -8.1868],\n",
      "        [ -1.3756],\n",
      "        [-13.0095],\n",
      "        [ -0.6255]])\n"
     ]
    }
   ],
   "source": [
    "# # torch.allclose(torch.matmul(x, b), y, atol = 1e-3)\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.scatter(torch.matmul(x, b).detach().cpu(), y.detach().cpu())\n",
    "# plt.show()\n",
    "# print (torch.matmul(x, b))\n",
    "# print (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_ridge_preds(seq, target, xtest, lam=1e-5):\n",
    "#     seqT = seq.permute(0, 2, 1) # batch_size x D x len_context\n",
    "#     ridge_matrix = torch.matmul(seqT, seq) # batch_size x D x D\n",
    "#     ridge_matrix += torch.eye(ridge_matrix.size(1), device=ridge_matrix.device) * lam\n",
    "#     seqT_Y = torch.matmul(seqT, target) # batch_size x D x 1\n",
    "#     w_ridge = torch.linalg.solve(ridge_matrix, seqT_Y) # batch_size x D x 1\n",
    "#     preds = torch.matmul(xtest, w_ridge).squeeze(-1) # batch_size x 1 x 1\n",
    "#     return preds \n",
    "\n",
    "# def get_ridge_preds_seq(seq, target):\n",
    "#     B, N, D = seq.size() \n",
    "#     preds = []\n",
    "#     for _i in range(1, N):\n",
    "#         preds.append(get_ridge_preds(seq[:, :_i, :], target[:, :_i, :], seq[:, _i: _i + 1, :]))\n",
    "#     return torch.stack(preds, dim=1)\n",
    "        \n",
    "        \n",
    "# def validate_gradient_descent(epoch, val_loader, model, args, criterion, device, coarse_graining=\"standard\"):\n",
    "#     # seq_lens = list(range(1, args.len_context+1, 5)) \n",
    "   \n",
    "#     test_losses = [utils.AverageMeter('Loss', ':.4e') for _ in range(args.len_context)]\n",
    "    \n",
    "#     model.eval() # switch to eval mode\n",
    "#     eps = 1e-5\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for i, (seq, target, _true_beta) in enumerate(val_loader):\n",
    "#             seq, target, _true_beta = seq.to(device), target.to(device), _true_beta.to(device)\n",
    "            \n",
    "#             B, N, D = seq.size()\n",
    "#             if coarse_graining == \"absbot\":\n",
    "#                 # true_beta: shape (B, D)\n",
    "#                 true_beta = _true_beta.squeeze(2)\n",
    "#                 argsort_beta_visible = torch.argsort(torch.abs(true_beta), dim=-1)[:, :args.D_visible] # sort each row of true_beta by absolute value, shape (B, D_visible)\n",
    "#                 test_beta_visible = torch.gather(true_beta, dim=1, index=argsort_beta_visible) # shape (B, D_visible)\n",
    "#                 x_test_visible = torch.gather(seq[:, -1, :].squeeze(1), dim=1, index=argsort_beta_visible) # shape (B, D_visible) \n",
    "                \n",
    "#                 new_target = torch.matmul(x_test_visible.unsqueeze(1), test_beta_visible.unsqueeze(2)).squeeze(2) \n",
    "#                 new_target = new_target.squeeze(1)\n",
    "#                 # if args.sigma_xi > 1e-5:\n",
    "#                     # print  (\"-args.D_visible\", -args.D_visible, \"argsort_beta_visible\", argsort_beta_visible.shape, \"test_beta_visible\", test_beta_visible.shape)\n",
    "#                 sigma_test_xi = torch.pow(args.sigma_xi ** 2 + torch.matmul(true_beta.unsqueeze(1), true_beta.unsqueeze(2)) \\\n",
    "#                                         - torch.matmul(test_beta_visible.unsqueeze(1), test_beta_visible.unsqueeze(2))+eps, 0.5).squeeze(2).squeeze(1) # shape (B)\n",
    "#                 # print (\"sigma_test_xi\", sigma_test_xi)\n",
    "#                 new_target += torch.randn(new_target.size(0), device=device) * sigma_test_xi # shape (B, 1) \n",
    "#                 target[:, -1, 0] = new_target\n",
    "                \n",
    "#             elif coarse_graining == \"abstop\":\n",
    "#                 true_beta = _true_beta.squeeze(2) # shape (B, D)\n",
    "#                 # print (\"true_beta\", true_beta.shape)\n",
    "#                 argsort_beta_visible = torch.argsort(torch.abs(true_beta), dim=-1)[:, -args.D_visible:] # sort each row of true_beta by absolute value, shape (B, D_visible)\n",
    "#                 # test_beta_visible = true_beta[argsort_beta_visible] # take top D_visible betas, shape (B, D_visible) \n",
    "#                 test_beta_visible = torch.gather(true_beta, dim=1, index=argsort_beta_visible) # shape (B, D_visible)\n",
    "#                 x_test_visible = torch.gather(seq[:, -1, :].squeeze(1), dim=1, index=argsort_beta_visible) # shape (B, D_visible) \n",
    "                \n",
    "#                 # target = x_test_visible  @ test_beta_visible + np.random.randn(N_test) * sigma_test_xi\n",
    "#                 new_target = torch.matmul(x_test_visible.unsqueeze(1), test_beta_visible.unsqueeze(2)).squeeze(2) \n",
    "#                 new_target = new_target.squeeze(1)\n",
    "#                 # if args.sigma_xi > 1e-5:\n",
    "#                     # print  (\"-args.D_visible\", -args.D_visible, \"argsort_beta_visible\", argsort_beta_visible.shape, \"test_beta_visible\", test_beta_visible.shape)\n",
    "#                 sigma_test_xi = torch.pow(args.sigma_xi ** 2 + torch.matmul(true_beta.unsqueeze(1), true_beta.unsqueeze(2)) \\\n",
    "#                                         - torch.matmul(test_beta_visible.unsqueeze(1), test_beta_visible.unsqueeze(2))+eps, 0.5).squeeze(2).squeeze(1) # shape (B)\n",
    "#                 # print (\"sigma_test_xi\", sigma_test_xi)\n",
    "#                 new_target += torch.randn(new_target.size(0), device=device) * sigma_test_xi # shape (B, 1) \n",
    "#                 # print (\"new_target\", new_target, \"sigma_test_xi\", sigma_test_xi )\n",
    "#                 target[:, -1, 0] = new_target\n",
    "\n",
    "                \n",
    "            \n",
    "\n",
    "            \n",
    "#             # print (\"seq\", seq.shape, \"target\", target.shape)\n",
    "#             output = model(seq, target) \n",
    "#             # print (\"seq\", seq.shape, \"target\", target.shape, \"output\", output.shape )\n",
    "#             preds = output[:, ::2, :]\n",
    "#             # distance to ridge_preds \n",
    "#             # if coarse_graining == \"standard\":\n",
    "#             #     ridge_preds = get_ridge_preds_seq(seq, target) # shape: (B, N-1, 1)\n",
    "#             #     ridge_loss = (ridge_preds - target[:, 1:, :]).pow(2).mean(dim=0)\n",
    "#             #     dist_to_ridge = (preds[:,1:, :] - ridge_preds).pow(2).mean(dim=0)\n",
    "#             #     print (\"ridge_loss\", ridge_loss, \"dist_to_ridge\", dist_to_ridge.shape, dist_to_ridge)\n",
    "                \n",
    "#             loss = (preds - target).pow(2).squeeze(-1).mean(dim=0) \n",
    "#             print (\"test preds\", preds.shape, \"test target\", target.shape, \"test loss\", loss.shape)\n",
    "            \n",
    "#             [test_losses[_].update(loss[_].item(), target.size(0)) for _ in range(N)]\n",
    "#             # acc1 = utils.accuracy(output, seq_target, topk=[1])\n",
    "#             # test_top1[seq_len].update(acc1[0], target.size(0))\n",
    "#             # acc1 = torch.mean(((output.squeeze(1) * (seq_target*2-1)) > 0).float()).item()\n",
    "#             # test_top1[seq_len].update(acc1, target.size(0))\n",
    "\n",
    "#     return test_losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(0.6612, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.6410686661402385, 'epoch': 0, 'icl_indistribution_loss': 0.7887951202392578, 'icl_outdistribution_loss': 0.8135775637626648, 'iwl_indistribution_loss': 0.7497784976959229, 'iwl_outdistribution_loss': 0.7690922451019288}\n",
      "loss tensor(0.6223, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.6366833840052287, 'epoch': 1, 'icl_indistribution_loss': 0.8158242402076721, 'icl_outdistribution_loss': 0.8702371153831482, 'iwl_indistribution_loss': 0.6429867844581604, 'iwl_outdistribution_loss': 0.6558379397392273}\n",
      "loss tensor(0.6375, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.6370165213267008, 'epoch': 2, 'icl_indistribution_loss': 0.8623828115463257, 'icl_outdistribution_loss': 0.879096981048584, 'iwl_indistribution_loss': 0.649561092376709, 'iwl_outdistribution_loss': 0.6558184995651245}\n",
      "loss tensor(0.6531, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.6376108024597168, 'epoch': 3, 'icl_indistribution_loss': 0.8482468962669373, 'icl_outdistribution_loss': 0.8714955005645751, 'iwl_indistribution_loss': 0.6320598044395447, 'iwl_outdistribution_loss': 0.6529285740852356}\n",
      "loss tensor(0.6013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.6359676260948182, 'epoch': 4, 'icl_indistribution_loss': 0.8424761629104615, 'icl_outdistribution_loss': 0.8360203437805176, 'iwl_indistribution_loss': 0.6349305753707886, 'iwl_outdistribution_loss': 0.6473992333412171}\n",
      "loss tensor(0.6003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.635849758720398, 'epoch': 5, 'icl_indistribution_loss': 0.8334214205741882, 'icl_outdistribution_loss': 0.8670865683555603, 'iwl_indistribution_loss': 0.633486487865448, 'iwl_outdistribution_loss': 0.6489988412857056}\n",
      "loss tensor(0.6543, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.6348802095095316, 'epoch': 6, 'icl_indistribution_loss': 0.8267709860801696, 'icl_outdistribution_loss': 0.8662468366622925, 'iwl_indistribution_loss': 0.6288256349563599, 'iwl_outdistribution_loss': 0.6477975163459778}\n",
      "loss tensor(0.6772, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.6360774869918824, 'epoch': 7, 'icl_indistribution_loss': 0.838953378200531, 'icl_outdistribution_loss': 0.8503444147109985, 'iwl_indistribution_loss': 0.6381931853294373, 'iwl_outdistribution_loss': 0.641967869758606}\n",
      "loss tensor(0.6114, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.6373993120829264, 'epoch': 8, 'icl_indistribution_loss': 0.8375634398460389, 'icl_outdistribution_loss': 0.8605996041297913, 'iwl_indistribution_loss': 0.6359687423706055, 'iwl_outdistribution_loss': 0.6527207980155945}\n",
      "loss tensor(0.6518, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.6378787264823914, 'epoch': 9, 'icl_indistribution_loss': 0.8332234930992126, 'icl_outdistribution_loss': 0.869069052696228, 'iwl_indistribution_loss': 0.6415249676704406, 'iwl_outdistribution_loss': 0.6583036732673645}\n",
      "loss tensor(0.6603, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.6368554553031921, 'epoch': 10, 'icl_indistribution_loss': 0.8431539082527161, 'icl_outdistribution_loss': 0.8593065543174744, 'iwl_indistribution_loss': 0.6472359409332276, 'iwl_outdistribution_loss': 0.6483433966636658}\n",
      "loss tensor(0.6185, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.6353668248812357, 'epoch': 11, 'icl_indistribution_loss': 0.8626873230934143, 'icl_outdistribution_loss': 0.8370506448745727, 'iwl_indistribution_loss': 0.6229755206108093, 'iwl_outdistribution_loss': 0.6512517714500428}\n",
      "loss tensor(0.6094, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.6330670917828878, 'epoch': 12, 'icl_indistribution_loss': 0.8196439995765686, 'icl_outdistribution_loss': 0.8459447865486145, 'iwl_indistribution_loss': 0.6298884425163269, 'iwl_outdistribution_loss': 0.6573931803703308}\n",
      "loss tensor(0.6321, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.6316752840995788, 'epoch': 13, 'icl_indistribution_loss': 0.8222306623458863, 'icl_outdistribution_loss': 0.8825545177459717, 'iwl_indistribution_loss': 0.6399888782501221, 'iwl_outdistribution_loss': 0.6537957539558411}\n",
      "loss tensor(0.6318, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.6223752902348836, 'epoch': 14, 'icl_indistribution_loss': 0.8480581722259521, 'icl_outdistribution_loss': 0.865851915359497, 'iwl_indistribution_loss': 0.6306999850273133, 'iwl_outdistribution_loss': 0.656456874370575}\n",
      "loss tensor(0.6485, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.611500510819753, 'epoch': 15, 'icl_indistribution_loss': 0.8298555393218994, 'icl_outdistribution_loss': 0.8618619856834412, 'iwl_indistribution_loss': 0.6090929255485534, 'iwl_outdistribution_loss': 0.6400464253425598}\n",
      "loss tensor(0.6216, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.5979120250066121, 'epoch': 16, 'icl_indistribution_loss': 0.8526217274665833, 'icl_outdistribution_loss': 0.870583598613739, 'iwl_indistribution_loss': 0.5940976843833924, 'iwl_outdistribution_loss': 0.6194521594047546}\n",
      "loss tensor(0.6162, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.5862049221674601, 'epoch': 17, 'icl_indistribution_loss': 0.89264324426651, 'icl_outdistribution_loss': 0.9070388503074646, 'iwl_indistribution_loss': 0.6528135557174682, 'iwl_outdistribution_loss': 0.6788130040168763}\n",
      "loss tensor(0.5239, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.571146295483907, 'epoch': 18, 'icl_indistribution_loss': 0.8283529925346375, 'icl_outdistribution_loss': 0.8546281766891479, 'iwl_indistribution_loss': 0.583130588054657, 'iwl_outdistribution_loss': 0.5932134809494019}\n",
      "loss tensor(0.5452, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.5597991819063822, 'epoch': 19, 'icl_indistribution_loss': 0.8960866055488587, 'icl_outdistribution_loss': 0.9030300378799438, 'iwl_indistribution_loss': 0.5737896780967713, 'iwl_outdistribution_loss': 0.5859269518852234}\n",
      "loss tensor(0.5377, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.549509055519104, 'epoch': 20, 'icl_indistribution_loss': 0.8492085781097413, 'icl_outdistribution_loss': 0.8942217669486999, 'iwl_indistribution_loss': 0.5445464997291565, 'iwl_outdistribution_loss': 0.5541753873825074}\n",
      "loss tensor(0.5803, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.5390328545888265, 'epoch': 21, 'icl_indistribution_loss': 0.8544088006019592, 'icl_outdistribution_loss': 0.9170986146926879, 'iwl_indistribution_loss': 0.5486989440917969, 'iwl_outdistribution_loss': 0.5743392634391785}\n",
      "loss tensor(0.5054, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.5294167903264364, 'epoch': 22, 'icl_indistribution_loss': 0.8550631670951844, 'icl_outdistribution_loss': 0.8688618726730347, 'iwl_indistribution_loss': 0.5310774245262146, 'iwl_outdistribution_loss': 0.5558229198455811}\n",
      "loss tensor(0.5179, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.5202862778981526, 'epoch': 23, 'icl_indistribution_loss': 0.8921776471138001, 'icl_outdistribution_loss': 0.9324118556976319, 'iwl_indistribution_loss': 0.5227765703201294, 'iwl_outdistribution_loss': 0.549427429676056}\n",
      "loss tensor(0.4947, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.5108500878969828, 'epoch': 24, 'icl_indistribution_loss': 0.8455593309402466, 'icl_outdistribution_loss': 0.8875672950744629, 'iwl_indistribution_loss': 0.5027957758903503, 'iwl_outdistribution_loss': 0.5172738838195801}\n",
      "loss tensor(0.5034, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.5044655928293864, 'epoch': 25, 'icl_indistribution_loss': 0.8917446618080139, 'icl_outdistribution_loss': 0.8935797290802002, 'iwl_indistribution_loss': 0.5150059251785278, 'iwl_outdistribution_loss': 0.5255926904678345}\n",
      "loss tensor(0.4681, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.49853172171910604, 'epoch': 26, 'icl_indistribution_loss': 0.8941632204055786, 'icl_outdistribution_loss': 0.9046489572525025, 'iwl_indistribution_loss': 0.4893356964588165, 'iwl_outdistribution_loss': 0.5232297410964966}\n",
      "loss tensor(0.4752, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4938326729774475, 'epoch': 27, 'icl_indistribution_loss': 0.8819784750938415, 'icl_outdistribution_loss': 0.8884584593772888, 'iwl_indistribution_loss': 0.48581218433380124, 'iwl_outdistribution_loss': 0.5053470902442933}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(0.5328, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.48809765113194786, 'epoch': 28, 'icl_indistribution_loss': 0.9034700899124145, 'icl_outdistribution_loss': 0.9349809069633483, 'iwl_indistribution_loss': 0.5325425281524658, 'iwl_outdistribution_loss': 0.5466581292152405}\n",
      "loss tensor(0.4838, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.48301053703625996, 'epoch': 29, 'icl_indistribution_loss': 0.845403573513031, 'icl_outdistribution_loss': 0.8730980005264283, 'iwl_indistribution_loss': 0.4925995652675629, 'iwl_outdistribution_loss': 0.5096753468513489}\n",
      "loss tensor(0.4397, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4780987974802653, 'epoch': 30, 'icl_indistribution_loss': 0.8850189366340637, 'icl_outdistribution_loss': 0.9009322776794434, 'iwl_indistribution_loss': 0.49386332035064695, 'iwl_outdistribution_loss': 0.5065914468765259}\n",
      "loss tensor(0.4616, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4742248488903046, 'epoch': 31, 'icl_indistribution_loss': 0.883356626033783, 'icl_outdistribution_loss': 0.8971921372413635, 'iwl_indistribution_loss': 0.4688175530433655, 'iwl_outdistribution_loss': 0.4932630352973938}\n",
      "loss tensor(0.5044, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.46979132067362467, 'epoch': 32, 'icl_indistribution_loss': 0.8754536371231079, 'icl_outdistribution_loss': 0.9322467145919799, 'iwl_indistribution_loss': 0.4617271900177002, 'iwl_outdistribution_loss': 0.49212007713317873}\n",
      "loss tensor(0.4535, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4665555282274882, 'epoch': 33, 'icl_indistribution_loss': 0.9019989137649536, 'icl_outdistribution_loss': 0.8999789299964904, 'iwl_indistribution_loss': 0.49973308825492857, 'iwl_outdistribution_loss': 0.5238489027023315}\n",
      "loss tensor(0.4557, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.46357989160219826, 'epoch': 34, 'icl_indistribution_loss': 0.899497654914856, 'icl_outdistribution_loss': 0.9161970567703247, 'iwl_indistribution_loss': 0.47686971139907836, 'iwl_outdistribution_loss': 0.49523590350151064}\n",
      "loss tensor(0.4371, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4517348120530446, 'epoch': 35, 'icl_indistribution_loss': 0.8859574151039123, 'icl_outdistribution_loss': 0.9307261238098145, 'iwl_indistribution_loss': 0.4616482105255127, 'iwl_outdistribution_loss': 0.4839864947795868}\n",
      "loss tensor(0.4325, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.44306989844640093, 'epoch': 36, 'icl_indistribution_loss': 0.8709395937919616, 'icl_outdistribution_loss': 0.9160401120185852, 'iwl_indistribution_loss': 0.44096034836769105, 'iwl_outdistribution_loss': 0.4599072275161743}\n",
      "loss tensor(0.4090, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.43787672166824343, 'epoch': 37, 'icl_indistribution_loss': 0.9017648515701294, 'icl_outdistribution_loss': 0.8924591794013977, 'iwl_indistribution_loss': 0.43051981234550474, 'iwl_outdistribution_loss': 0.4522318184375763}\n",
      "loss tensor(0.4509, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4325595927238464, 'epoch': 38, 'icl_indistribution_loss': 0.8740349593162536, 'icl_outdistribution_loss': 0.8761799130439758, 'iwl_indistribution_loss': 0.4353517544269562, 'iwl_outdistribution_loss': 0.45010825181007386}\n",
      "loss tensor(0.4233, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4279076603571574, 'epoch': 39, 'icl_indistribution_loss': 0.8662719860076904, 'icl_outdistribution_loss': 0.9049300670623779, 'iwl_indistribution_loss': 0.4319370551109314, 'iwl_outdistribution_loss': 0.459823028087616}\n",
      "loss tensor(0.4087, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4267424386978149, 'epoch': 40, 'icl_indistribution_loss': 0.8873403654098511, 'icl_outdistribution_loss': 0.888937882900238, 'iwl_indistribution_loss': 0.42566723871231077, 'iwl_outdistribution_loss': 0.44666770362854}\n",
      "loss tensor(0.4433, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.42207288780212404, 'epoch': 41, 'icl_indistribution_loss': 0.8971675209999085, 'icl_outdistribution_loss': 0.9273104839324952, 'iwl_indistribution_loss': 0.41722545337677003, 'iwl_outdistribution_loss': 0.43327622056007387}\n",
      "loss tensor(0.4033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.42390137456258137, 'epoch': 42, 'icl_indistribution_loss': 0.9328789758682251, 'icl_outdistribution_loss': 0.9254019937515259, 'iwl_indistribution_loss': 0.44575015902519227, 'iwl_outdistribution_loss': 0.46341686964035034}\n",
      "loss tensor(0.4095, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.419787149810791, 'epoch': 43, 'icl_indistribution_loss': 0.8897529382705689, 'icl_outdistribution_loss': 0.9142604150772095, 'iwl_indistribution_loss': 0.42145036077499387, 'iwl_outdistribution_loss': 0.4463589072227478}\n",
      "loss tensor(0.4271, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4170294238090515, 'epoch': 44, 'icl_indistribution_loss': 0.9025973997116089, 'icl_outdistribution_loss': 0.9363495759963989, 'iwl_indistribution_loss': 0.41567362141609193, 'iwl_outdistribution_loss': 0.42712974214553834}\n",
      "loss tensor(0.4100, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.41602896941502887, 'epoch': 45, 'icl_indistribution_loss': 0.8550912761688232, 'icl_outdistribution_loss': 0.9137825183868408, 'iwl_indistribution_loss': 0.4183292360305786, 'iwl_outdistribution_loss': 0.43332333636283876}\n",
      "loss tensor(0.3992, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.41248629150390625, 'epoch': 46, 'icl_indistribution_loss': 0.886096197605133, 'icl_outdistribution_loss': 0.9008645195960998, 'iwl_indistribution_loss': 0.40659443855285643, 'iwl_outdistribution_loss': 0.4316867468357086}\n",
      "loss tensor(0.4276, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4119373806317647, 'epoch': 47, 'icl_indistribution_loss': 0.8987892994880676, 'icl_outdistribution_loss': 0.9104074330329895, 'iwl_indistribution_loss': 0.41021070528030396, 'iwl_outdistribution_loss': 0.435123562335968}\n",
      "loss tensor(0.4319, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.41088220202128095, 'epoch': 48, 'icl_indistribution_loss': 0.9063315324783325, 'icl_outdistribution_loss': 0.9012644691467285, 'iwl_indistribution_loss': 0.4068052270412445, 'iwl_outdistribution_loss': 0.43517646145820615}\n",
      "loss tensor(0.4088, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.40947205449740093, 'epoch': 49, 'icl_indistribution_loss': 0.887286596775055, 'icl_outdistribution_loss': 0.9343154339790344, 'iwl_indistribution_loss': 0.4112603671550751, 'iwl_outdistribution_loss': 0.4325282862186432}\n",
      "loss tensor(0.4134, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4082547475973765, 'epoch': 50, 'icl_indistribution_loss': 0.8875047492980958, 'icl_outdistribution_loss': 0.9045470385551453, 'iwl_indistribution_loss': 0.4019326465129852, 'iwl_outdistribution_loss': 0.42516635298728944}\n",
      "loss tensor(0.3980, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4071596742630005, 'epoch': 51, 'icl_indistribution_loss': 0.8718735065460205, 'icl_outdistribution_loss': 0.9158755173683166, 'iwl_indistribution_loss': 0.4122282576560974, 'iwl_outdistribution_loss': 0.43254701685905456}\n",
      "loss tensor(0.4143, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.40560855805079143, 'epoch': 52, 'icl_indistribution_loss': 0.9322603945732116, 'icl_outdistribution_loss': 0.9178587245941162, 'iwl_indistribution_loss': 0.40260185074806215, 'iwl_outdistribution_loss': 0.41605372858047485}\n",
      "loss tensor(0.4056, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4045066745122274, 'epoch': 53, 'icl_indistribution_loss': 0.8514368629455566, 'icl_outdistribution_loss': 0.884122646331787, 'iwl_indistribution_loss': 0.4007513418197632, 'iwl_outdistribution_loss': 0.41618084216117857}\n",
      "loss tensor(0.3797, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4040122812271118, 'epoch': 54, 'icl_indistribution_loss': 0.9071478910446167, 'icl_outdistribution_loss': 0.9156136894226075, 'iwl_indistribution_loss': 0.40693145895004273, 'iwl_outdistribution_loss': 0.4187498288154602}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(0.4153, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4025430416901906, 'epoch': 55, 'icl_indistribution_loss': 0.8946547656059265, 'icl_outdistribution_loss': 0.9100913825035095, 'iwl_indistribution_loss': 0.40138553142547606, 'iwl_outdistribution_loss': 0.4201035923957825}\n",
      "loss tensor(0.4144, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4008309841791789, 'epoch': 56, 'icl_indistribution_loss': 0.8822420110702515, 'icl_outdistribution_loss': 0.9042879462242126, 'iwl_indistribution_loss': 0.4086839456558228, 'iwl_outdistribution_loss': 0.4261040678024292}\n",
      "loss tensor(0.4140, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4004134126186371, 'epoch': 57, 'icl_indistribution_loss': 0.9174967432022094, 'icl_outdistribution_loss': 0.9236121401786804, 'iwl_indistribution_loss': 0.4087437469959259, 'iwl_outdistribution_loss': 0.42503209328651426}\n",
      "loss tensor(0.3960, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4006136758804321, 'epoch': 58, 'icl_indistribution_loss': 0.9092087950706482, 'icl_outdistribution_loss': 0.9141683058738709, 'iwl_indistribution_loss': 0.40308401322364806, 'iwl_outdistribution_loss': 0.41813692593574525}\n",
      "loss tensor(0.4231, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3998515732606252, 'epoch': 59, 'icl_indistribution_loss': 0.8776785621643066, 'icl_outdistribution_loss': 0.8920525479316711, 'iwl_indistribution_loss': 0.39590883898735046, 'iwl_outdistribution_loss': 0.4181801445484161}\n",
      "loss tensor(0.4087, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3993030167897542, 'epoch': 60, 'icl_indistribution_loss': 0.884775086402893, 'icl_outdistribution_loss': 0.9108368978500366, 'iwl_indistribution_loss': 0.40155337285995485, 'iwl_outdistribution_loss': 0.4228126041889191}\n",
      "loss tensor(0.3838, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3974921068191528, 'epoch': 61, 'icl_indistribution_loss': 0.8776725010871888, 'icl_outdistribution_loss': 0.9280418219566345, 'iwl_indistribution_loss': 0.4040942668914795, 'iwl_outdistribution_loss': 0.426801278591156}\n",
      "loss tensor(0.3905, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3964649014472961, 'epoch': 62, 'icl_indistribution_loss': 0.888074321269989, 'icl_outdistribution_loss': 0.9155724120140075, 'iwl_indistribution_loss': 0.3974434101581574, 'iwl_outdistribution_loss': 0.41577345967292784}\n",
      "loss tensor(0.3756, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3957279005686442, 'epoch': 63, 'icl_indistribution_loss': 0.9035772380828857, 'icl_outdistribution_loss': 0.8804091053009033, 'iwl_indistribution_loss': 0.3928840696811676, 'iwl_outdistribution_loss': 0.4151440682411194}\n",
      "loss tensor(0.3976, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.39601983485221864, 'epoch': 64, 'icl_indistribution_loss': 0.9061177477836609, 'icl_outdistribution_loss': 0.9086756768226624, 'iwl_indistribution_loss': 0.39736479640007016, 'iwl_outdistribution_loss': 0.41405809116363523}\n",
      "loss tensor(0.3667, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3941283619880676, 'epoch': 65, 'icl_indistribution_loss': 0.9070055804252625, 'icl_outdistribution_loss': 0.9177710771560669, 'iwl_indistribution_loss': 0.40779332756996156, 'iwl_outdistribution_loss': 0.42596031665802003}\n",
      "loss tensor(0.4055, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.39274811288515726, 'epoch': 66, 'icl_indistribution_loss': 0.8818164796829223, 'icl_outdistribution_loss': 0.8988805437088012, 'iwl_indistribution_loss': 0.4031012234687805, 'iwl_outdistribution_loss': 0.4167476947307587}\n",
      "loss tensor(0.3717, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3892575899283091, 'epoch': 67, 'icl_indistribution_loss': 0.8961709232330323, 'icl_outdistribution_loss': 0.912265209197998, 'iwl_indistribution_loss': 0.3907049996852875, 'iwl_outdistribution_loss': 0.3995946826934814}\n",
      "loss tensor(0.3883, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3845751265525818, 'epoch': 68, 'icl_indistribution_loss': 0.8692645115852355, 'icl_outdistribution_loss': 0.8802849431037902, 'iwl_indistribution_loss': 0.379603435754776, 'iwl_outdistribution_loss': 0.39660277247428893}\n",
      "loss tensor(0.3750, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3815997436841329, 'epoch': 69, 'icl_indistribution_loss': 0.888161319732666, 'icl_outdistribution_loss': 0.8934588379859925, 'iwl_indistribution_loss': 0.38957247376441956, 'iwl_outdistribution_loss': 0.40453036165237427}\n",
      "loss tensor(0.4048, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3792008220831553, 'epoch': 70, 'icl_indistribution_loss': 0.8648501954078675, 'icl_outdistribution_loss': 0.9072794880867004, 'iwl_indistribution_loss': 0.37302803158760073, 'iwl_outdistribution_loss': 0.39829065823554993}\n",
      "loss tensor(0.3707, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.37535988337198894, 'epoch': 71, 'icl_indistribution_loss': 0.8514131894111633, 'icl_outdistribution_loss': 0.881465169429779, 'iwl_indistribution_loss': 0.38521397948265074, 'iwl_outdistribution_loss': 0.40700013184547423}\n",
      "loss tensor(0.3433, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.37526588230133057, 'epoch': 72, 'icl_indistribution_loss': 0.8612380857467652, 'icl_outdistribution_loss': 0.8883500261306763, 'iwl_indistribution_loss': 0.3679630279541016, 'iwl_outdistribution_loss': 0.3870988199710846}\n",
      "loss tensor(0.3484, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3738384458065033, 'epoch': 73, 'icl_indistribution_loss': 0.8788771376609802, 'icl_outdistribution_loss': 0.87093483543396, 'iwl_indistribution_loss': 0.3731009051799774, 'iwl_outdistribution_loss': 0.38679954218864443}\n",
      "loss tensor(0.3523, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.37206934040387474, 'epoch': 74, 'icl_indistribution_loss': 0.8650865845680237, 'icl_outdistribution_loss': 0.8964965229034424, 'iwl_indistribution_loss': 0.37994167852401733, 'iwl_outdistribution_loss': 0.4060572838783264}\n",
      "loss tensor(0.3654, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.37008939146995545, 'epoch': 75, 'icl_indistribution_loss': 0.8906368117332458, 'icl_outdistribution_loss': 0.9125104584693908, 'iwl_indistribution_loss': 0.3688389256000519, 'iwl_outdistribution_loss': 0.39761613082885744}\n",
      "loss tensor(0.4203, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3692810858090719, 'epoch': 76, 'icl_indistribution_loss': 0.8586977343559266, 'icl_outdistribution_loss': 0.8624376964569092, 'iwl_indistribution_loss': 0.364911922454834, 'iwl_outdistribution_loss': 0.3916954324245453}\n",
      "loss tensor(0.3670, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.36759426794052125, 'epoch': 77, 'icl_indistribution_loss': 0.8882525210380554, 'icl_outdistribution_loss': 0.8961853775978088, 'iwl_indistribution_loss': 0.374674551486969, 'iwl_outdistribution_loss': 0.39630469131469725}\n",
      "loss tensor(0.3543, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.36689162060419717, 'epoch': 78, 'icl_indistribution_loss': 0.8946952724456787, 'icl_outdistribution_loss': 0.9303617372512817, 'iwl_indistribution_loss': 0.38029322075843813, 'iwl_outdistribution_loss': 0.3888606824874878}\n",
      "loss tensor(0.3519, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.36581033789316814, 'epoch': 79, 'icl_indistribution_loss': 0.8618398623466492, 'icl_outdistribution_loss': 0.8860542001724243, 'iwl_indistribution_loss': 0.37211122155189513, 'iwl_outdistribution_loss': 0.39478313708305357}\n",
      "loss tensor(0.3775, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3646543521563212, 'epoch': 80, 'icl_indistribution_loss': 0.8848570942878723, 'icl_outdistribution_loss': 0.8952543773651123, 'iwl_indistribution_loss': 0.37028278231620787, 'iwl_outdistribution_loss': 0.3930381212234497}\n",
      "loss tensor(0.3781, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3645292304674784, 'epoch': 81, 'icl_indistribution_loss': 0.8667955212593078, 'icl_outdistribution_loss': 0.8860919165611267, 'iwl_indistribution_loss': 0.36311291003227236, 'iwl_outdistribution_loss': 0.3765360116958618}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(0.3737, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.36395984466870623, 'epoch': 82, 'icl_indistribution_loss': 0.8725483131408691, 'icl_outdistribution_loss': 0.8980012989044189, 'iwl_indistribution_loss': 0.36500910425186156, 'iwl_outdistribution_loss': 0.3847146270275116}\n",
      "loss tensor(0.3719, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.36356106437047325, 'epoch': 83, 'icl_indistribution_loss': 0.8819392113685608, 'icl_outdistribution_loss': 0.9165067319869995, 'iwl_indistribution_loss': 0.3621859290599823, 'iwl_outdistribution_loss': 0.39158475303649903}\n",
      "loss tensor(0.3680, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.36385566517512, 'epoch': 84, 'icl_indistribution_loss': 0.8752757344245911, 'icl_outdistribution_loss': 0.9116448774337769, 'iwl_indistribution_loss': 0.35648180890083314, 'iwl_outdistribution_loss': 0.3755884873867035}\n",
      "loss tensor(0.3554, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.36269873943328856, 'epoch': 85, 'icl_indistribution_loss': 0.8946717796325684, 'icl_outdistribution_loss': 0.8756468000411988, 'iwl_indistribution_loss': 0.35694341111183164, 'iwl_outdistribution_loss': 0.3797533881664276}\n",
      "loss tensor(0.3689, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.36202848631540935, 'epoch': 86, 'icl_indistribution_loss': 0.876816222190857, 'icl_outdistribution_loss': 0.9001541752815246, 'iwl_indistribution_loss': 0.362348185300827, 'iwl_outdistribution_loss': 0.38298598217964175}\n",
      "loss tensor(0.3368, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3627481688340505, 'epoch': 87, 'icl_indistribution_loss': 0.8507961506843567, 'icl_outdistribution_loss': 0.8874710397720337, 'iwl_indistribution_loss': 0.3704887094497681, 'iwl_outdistribution_loss': 0.3864412925243378}\n",
      "loss tensor(0.3521, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3613483485857646, 'epoch': 88, 'icl_indistribution_loss': 0.840713411808014, 'icl_outdistribution_loss': 0.904703754901886, 'iwl_indistribution_loss': 0.3584129993915558, 'iwl_outdistribution_loss': 0.376135892868042}\n",
      "loss tensor(0.3570, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3614671484788259, 'epoch': 89, 'icl_indistribution_loss': 0.8932392964363098, 'icl_outdistribution_loss': 0.8920911641120911, 'iwl_indistribution_loss': 0.36420216608047484, 'iwl_outdistribution_loss': 0.37601502394676206}\n",
      "loss tensor(0.3807, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3597203371842702, 'epoch': 90, 'icl_indistribution_loss': 0.8820786452293397, 'icl_outdistribution_loss': 0.8679620327949524, 'iwl_indistribution_loss': 0.35864560103416443, 'iwl_outdistribution_loss': 0.38058056926727296}\n",
      "loss tensor(0.3502, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3599823272864024, 'epoch': 91, 'icl_indistribution_loss': 0.8872090239524841, 'icl_outdistribution_loss': 0.8971757063865662, 'iwl_indistribution_loss': 0.35172415447235106, 'iwl_outdistribution_loss': 0.3795550889968872}\n",
      "loss tensor(0.3762, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35975977748235066, 'epoch': 92, 'icl_indistribution_loss': 0.8854940071105957, 'icl_outdistribution_loss': 0.8903275346755981, 'iwl_indistribution_loss': 0.36072689270973207, 'iwl_outdistribution_loss': 0.37896812438964844}\n",
      "loss tensor(0.3743, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3587125387986501, 'epoch': 93, 'icl_indistribution_loss': 0.8713897681236267, 'icl_outdistribution_loss': 0.875768807888031, 'iwl_indistribution_loss': 0.36165618419647216, 'iwl_outdistribution_loss': 0.38024641847610474}\n",
      "loss tensor(0.3761, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35782104632059736, 'epoch': 94, 'icl_indistribution_loss': 0.8823817157745362, 'icl_outdistribution_loss': 0.8767783417701721, 'iwl_indistribution_loss': 0.36531507658958434, 'iwl_outdistribution_loss': 0.3825261163711548}\n",
      "loss tensor(0.3354, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35730703897476196, 'epoch': 95, 'icl_indistribution_loss': 0.8803899998664856, 'icl_outdistribution_loss': 0.9341748552322388, 'iwl_indistribution_loss': 0.3550008306503296, 'iwl_outdistribution_loss': 0.3840095863342285}\n",
      "loss tensor(0.3592, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3573409767945607, 'epoch': 96, 'icl_indistribution_loss': 0.8714654927253723, 'icl_outdistribution_loss': 0.8916057367324829, 'iwl_indistribution_loss': 0.3611571171283722, 'iwl_outdistribution_loss': 0.3756839349269867}\n",
      "loss tensor(0.3693, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3578738156795502, 'epoch': 97, 'icl_indistribution_loss': 0.9120300774574279, 'icl_outdistribution_loss': 0.8778668689727783, 'iwl_indistribution_loss': 0.3529093716144562, 'iwl_outdistribution_loss': 0.38837307476997374}\n",
      "loss tensor(0.3446, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35709116191864015, 'epoch': 98, 'icl_indistribution_loss': 0.9046174654960633, 'icl_outdistribution_loss': 0.9105451231002808, 'iwl_indistribution_loss': 0.36062176036834714, 'iwl_outdistribution_loss': 0.38560862946510316}\n",
      "loss tensor(0.3540, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35528170879681903, 'epoch': 99, 'icl_indistribution_loss': 0.8671974511146545, 'icl_outdistribution_loss': 0.8874446907043457, 'iwl_indistribution_loss': 0.34683895897865297, 'iwl_outdistribution_loss': 0.37327996706962585}\n",
      "loss tensor(0.3655, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35490720739364623, 'epoch': 100, 'icl_indistribution_loss': 0.886607253074646, 'icl_outdistribution_loss': 0.8924447603225708, 'iwl_indistribution_loss': 0.36333466744422915, 'iwl_outdistribution_loss': 0.3783648657798767}\n",
      "loss tensor(0.3529, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.355549942668279, 'epoch': 101, 'icl_indistribution_loss': 0.8797310061454773, 'icl_outdistribution_loss': 0.9052333784103394, 'iwl_indistribution_loss': 0.3452945394515991, 'iwl_outdistribution_loss': 0.37424132776260377}\n",
      "loss tensor(0.3439, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35562677810986837, 'epoch': 102, 'icl_indistribution_loss': 0.900861056804657, 'icl_outdistribution_loss': 0.8806338691711426, 'iwl_indistribution_loss': 0.35502698230743407, 'iwl_outdistribution_loss': 0.3757987127304077}\n",
      "loss tensor(0.3641, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3549846017519633, 'epoch': 103, 'icl_indistribution_loss': 0.8813512597084046, 'icl_outdistribution_loss': 0.8880950636863708, 'iwl_indistribution_loss': 0.35186679649353025, 'iwl_outdistribution_loss': 0.37208271884918215}\n",
      "loss tensor(0.3615, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35311009426116946, 'epoch': 104, 'icl_indistribution_loss': 0.875407856464386, 'icl_outdistribution_loss': 0.9199603519439697, 'iwl_indistribution_loss': 0.35897629022598265, 'iwl_outdistribution_loss': 0.3852939848899841}\n",
      "loss tensor(0.3318, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35392225597699484, 'epoch': 105, 'icl_indistribution_loss': 0.8722724709510803, 'icl_outdistribution_loss': 0.9032649221420288, 'iwl_indistribution_loss': 0.35619173645973207, 'iwl_outdistribution_loss': 0.3769110991954803}\n",
      "loss tensor(0.3691, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35314952190717064, 'epoch': 106, 'icl_indistribution_loss': 0.8652317137718201, 'icl_outdistribution_loss': 0.8891080355644226, 'iwl_indistribution_loss': 0.3516673979759216, 'iwl_outdistribution_loss': 0.3734365215301514}\n",
      "loss tensor(0.3492, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3523929218610128, 'epoch': 107, 'icl_indistribution_loss': 0.9036301169395446, 'icl_outdistribution_loss': 0.9160108013153077, 'iwl_indistribution_loss': 0.35408868837356566, 'iwl_outdistribution_loss': 0.37030461740493775}\n",
      "loss tensor(0.3463, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35383177655537923, 'epoch': 108, 'icl_indistribution_loss': 0.8718083138465882, 'icl_outdistribution_loss': 0.9001502199172974, 'iwl_indistribution_loss': 0.35108793473243716, 'iwl_outdistribution_loss': 0.37736790108680723}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(0.3687, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3532969978650411, 'epoch': 109, 'icl_indistribution_loss': 0.8530936069488525, 'icl_outdistribution_loss': 0.8786989693641662, 'iwl_indistribution_loss': 0.3555927267074585, 'iwl_outdistribution_loss': 0.378535751581192}\n",
      "loss tensor(0.3545, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35392953033447266, 'epoch': 110, 'icl_indistribution_loss': 0.8725702114105225, 'icl_outdistribution_loss': 0.8819053835868835, 'iwl_indistribution_loss': 0.35624313402175906, 'iwl_outdistribution_loss': 0.3766545424461365}\n",
      "loss tensor(0.3510, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3523118282318115, 'epoch': 111, 'icl_indistribution_loss': 0.8728259744644165, 'icl_outdistribution_loss': 0.9154380269050598, 'iwl_indistribution_loss': 0.35774056053161624, 'iwl_outdistribution_loss': 0.36675177597999575}\n",
      "loss tensor(0.3471, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35240943682988485, 'epoch': 112, 'icl_indistribution_loss': 0.839285500049591, 'icl_outdistribution_loss': 0.8858395466804504, 'iwl_indistribution_loss': 0.3558769054412842, 'iwl_outdistribution_loss': 0.3730970087051392}\n",
      "loss tensor(0.3483, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3525639614105225, 'epoch': 113, 'icl_indistribution_loss': 0.8783703866004944, 'icl_outdistribution_loss': 0.9105685358047485, 'iwl_indistribution_loss': 0.359119143486023, 'iwl_outdistribution_loss': 0.3660146644115448}\n",
      "loss tensor(0.3655, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35249162762959796, 'epoch': 114, 'icl_indistribution_loss': 0.8799435906410217, 'icl_outdistribution_loss': 0.9116216855049133, 'iwl_indistribution_loss': 0.35335181665420534, 'iwl_outdistribution_loss': 0.3648571512699127}\n",
      "loss tensor(0.3582, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3519132743835449, 'epoch': 115, 'icl_indistribution_loss': 0.8686753721237183, 'icl_outdistribution_loss': 0.8963297362327576, 'iwl_indistribution_loss': 0.3493568968772888, 'iwl_outdistribution_loss': 0.37260521483421327}\n",
      "loss tensor(0.3346, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35114706865946455, 'epoch': 116, 'icl_indistribution_loss': 0.8802591905593872, 'icl_outdistribution_loss': 0.8985512962341309, 'iwl_indistribution_loss': 0.35002259826660154, 'iwl_outdistribution_loss': 0.3676629285812378}\n",
      "loss tensor(0.3572, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.351066705083847, 'epoch': 117, 'icl_indistribution_loss': 0.8807316784858703, 'icl_outdistribution_loss': 0.9161082472801209, 'iwl_indistribution_loss': 0.35895988941192625, 'iwl_outdistribution_loss': 0.3748332848548889}\n",
      "loss tensor(0.3496, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3520026924451192, 'epoch': 118, 'icl_indistribution_loss': 0.8739703111648559, 'icl_outdistribution_loss': 0.8976464810371398, 'iwl_indistribution_loss': 0.35968002963066104, 'iwl_outdistribution_loss': 0.37487437891960146}\n",
      "loss tensor(0.3338, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35211411425272626, 'epoch': 119, 'icl_indistribution_loss': 0.8711008973121643, 'icl_outdistribution_loss': 0.9054047031402588, 'iwl_indistribution_loss': 0.353135817527771, 'iwl_outdistribution_loss': 0.37618797063827514}\n",
      "loss tensor(0.3539, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35189714562098184, 'epoch': 120, 'icl_indistribution_loss': 0.8703437843322754, 'icl_outdistribution_loss': 0.8758066239356994, 'iwl_indistribution_loss': 0.3488860647678375, 'iwl_outdistribution_loss': 0.3786220908164978}\n",
      "loss tensor(0.3596, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3506830080986023, 'epoch': 121, 'icl_indistribution_loss': 0.8618296294212341, 'icl_outdistribution_loss': 0.8917195167541504, 'iwl_indistribution_loss': 0.34994419288635253, 'iwl_outdistribution_loss': 0.38093797373771665}\n",
      "loss tensor(0.3338, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34893082644144696, 'epoch': 122, 'icl_indistribution_loss': 0.8847057690620422, 'icl_outdistribution_loss': 0.9050852718353272, 'iwl_indistribution_loss': 0.3468654065132141, 'iwl_outdistribution_loss': 0.3721611113548279}\n",
      "loss tensor(0.3479, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34965410318374635, 'epoch': 123, 'icl_indistribution_loss': 0.8675548572540284, 'icl_outdistribution_loss': 0.8937065062522889, 'iwl_indistribution_loss': 0.34949921584129334, 'iwl_outdistribution_loss': 0.371368780374527}\n",
      "loss tensor(0.3665, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3509600170771281, 'epoch': 124, 'icl_indistribution_loss': 0.8563757605552673, 'icl_outdistribution_loss': 0.8829903702735901, 'iwl_indistribution_loss': 0.3524301338195801, 'iwl_outdistribution_loss': 0.3754523437023163}\n",
      "loss tensor(0.3456, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35042203981081643, 'epoch': 125, 'icl_indistribution_loss': 0.8780982217788696, 'icl_outdistribution_loss': 0.8947340273857116, 'iwl_indistribution_loss': 0.3507243745326996, 'iwl_outdistribution_loss': 0.37271232080459593}\n",
      "loss tensor(0.3696, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35056353619893393, 'epoch': 126, 'icl_indistribution_loss': 0.8978500113487243, 'icl_outdistribution_loss': 0.9002968654632568, 'iwl_indistribution_loss': 0.3504246244430542, 'iwl_outdistribution_loss': 0.3760000042915344}\n",
      "loss tensor(0.3762, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3500950065930684, 'epoch': 127, 'icl_indistribution_loss': 0.8764801597595215, 'icl_outdistribution_loss': 0.8943806324005127, 'iwl_indistribution_loss': 0.34759856843948367, 'iwl_outdistribution_loss': 0.36950344157218934}\n",
      "loss tensor(0.3373, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.349417165072759, 'epoch': 128, 'icl_indistribution_loss': 0.8556949043273926, 'icl_outdistribution_loss': 0.9076668992042541, 'iwl_indistribution_loss': 0.35741153717041013, 'iwl_outdistribution_loss': 0.3690816946029663}\n",
      "loss tensor(0.3684, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35040323214530944, 'epoch': 129, 'icl_indistribution_loss': 0.8997309122085572, 'icl_outdistribution_loss': 0.8727720375061035, 'iwl_indistribution_loss': 0.34894533777236936, 'iwl_outdistribution_loss': 0.36933061814308166}\n",
      "loss tensor(0.3496, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35024877567291257, 'epoch': 130, 'icl_indistribution_loss': 0.9005342593193054, 'icl_outdistribution_loss': 0.8972042393684387, 'iwl_indistribution_loss': 0.3567019975185394, 'iwl_outdistribution_loss': 0.3663269157409668}\n",
      "loss tensor(0.3555, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35016077423095704, 'epoch': 131, 'icl_indistribution_loss': 0.8962549920082092, 'icl_outdistribution_loss': 0.9076026310920715, 'iwl_indistribution_loss': 0.3530442342758179, 'iwl_outdistribution_loss': 0.3651876373291016}\n",
      "loss tensor(0.3339, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.349034015750885, 'epoch': 132, 'icl_indistribution_loss': 0.8681430869102478, 'icl_outdistribution_loss': 0.922421929359436, 'iwl_indistribution_loss': 0.34648639559745786, 'iwl_outdistribution_loss': 0.37659277629852295}\n",
      "loss tensor(0.3516, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34919980624516805, 'epoch': 133, 'icl_indistribution_loss': 0.8723989109992981, 'icl_outdistribution_loss': 0.9142031211853028, 'iwl_indistribution_loss': 0.35078977060317995, 'iwl_outdistribution_loss': 0.37012796211242677}\n",
      "loss tensor(0.3326, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3490456095059713, 'epoch': 134, 'icl_indistribution_loss': 0.8824407911300659, 'icl_outdistribution_loss': 0.905583514213562, 'iwl_indistribution_loss': 0.3523264811038971, 'iwl_outdistribution_loss': 0.36611273646354675}\n",
      "loss tensor(0.3294, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3486040438652039, 'epoch': 135, 'icl_indistribution_loss': 0.873729100227356, 'icl_outdistribution_loss': 0.8894578804969787, 'iwl_indistribution_loss': 0.3483916959762573, 'iwl_outdistribution_loss': 0.37164431071281434}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(0.3397, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34875047403971354, 'epoch': 136, 'icl_indistribution_loss': 0.8788593144416809, 'icl_outdistribution_loss': 0.9151891541481018, 'iwl_indistribution_loss': 0.3473614411354065, 'iwl_outdistribution_loss': 0.3767488601207733}\n",
      "loss tensor(0.3726, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34928162837028504, 'epoch': 137, 'icl_indistribution_loss': 0.8648478021621704, 'icl_outdistribution_loss': 0.8942816710472107, 'iwl_indistribution_loss': 0.3499638493061066, 'iwl_outdistribution_loss': 0.3788919336795807}\n",
      "loss tensor(0.3354, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3491550887584686, 'epoch': 138, 'icl_indistribution_loss': 0.8973742995262146, 'icl_outdistribution_loss': 0.8911947183609009, 'iwl_indistribution_loss': 0.3454861536026001, 'iwl_outdistribution_loss': 0.37594841098785403}\n",
      "loss tensor(0.3505, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3491538293838501, 'epoch': 139, 'icl_indistribution_loss': 0.8922868862152099, 'icl_outdistribution_loss': 0.8808040280342102, 'iwl_indistribution_loss': 0.3596286525726318, 'iwl_outdistribution_loss': 0.36295444774627683}\n",
      "loss tensor(0.3681, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3486577633221944, 'epoch': 140, 'icl_indistribution_loss': 0.8754568753242493, 'icl_outdistribution_loss': 0.8804179368019104, 'iwl_indistribution_loss': 0.3541472260951996, 'iwl_outdistribution_loss': 0.3727811725139618}\n",
      "loss tensor(0.3503, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3484297842025757, 'epoch': 141, 'icl_indistribution_loss': 0.8807479104995728, 'icl_outdistribution_loss': 0.9009816541671752, 'iwl_indistribution_loss': 0.3493556344509125, 'iwl_outdistribution_loss': 0.36904259157180785}\n",
      "loss tensor(0.3587, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34826958672205605, 'epoch': 142, 'icl_indistribution_loss': 0.8961420931816101, 'icl_outdistribution_loss': 0.9287530403137207, 'iwl_indistribution_loss': 0.3461136817932129, 'iwl_outdistribution_loss': 0.367286580324173}\n",
      "loss tensor(0.3397, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34801348638534546, 'epoch': 143, 'icl_indistribution_loss': 0.8633074145317078, 'icl_outdistribution_loss': 0.8794686555862427, 'iwl_indistribution_loss': 0.3495476925373077, 'iwl_outdistribution_loss': 0.3801939284801483}\n",
      "loss tensor(0.3593, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3492411670207977, 'epoch': 144, 'icl_indistribution_loss': 0.8717950415611267, 'icl_outdistribution_loss': 0.9025569162368774, 'iwl_indistribution_loss': 0.34470265340805056, 'iwl_outdistribution_loss': 0.37436824560165405}\n",
      "loss tensor(0.3581, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3481824326992035, 'epoch': 145, 'icl_indistribution_loss': 0.8836730699539185, 'icl_outdistribution_loss': 0.9118235673904419, 'iwl_indistribution_loss': 0.34350805139541624, 'iwl_outdistribution_loss': 0.3685619933605194}\n",
      "loss tensor(0.3465, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34850559051831564, 'epoch': 146, 'icl_indistribution_loss': 0.8918255753517151, 'icl_outdistribution_loss': 0.9053445043563842, 'iwl_indistribution_loss': 0.34887642312049866, 'iwl_outdistribution_loss': 0.3658354940414429}\n",
      "loss tensor(0.3601, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34878520352045694, 'epoch': 147, 'icl_indistribution_loss': 0.860058358669281, 'icl_outdistribution_loss': 0.875760094165802, 'iwl_indistribution_loss': 0.34372795605659484, 'iwl_outdistribution_loss': 0.3621231918334961}\n",
      "loss tensor(0.3501, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34901229378382365, 'epoch': 148, 'icl_indistribution_loss': 0.8736346635818482, 'icl_outdistribution_loss': 0.8677881193161011, 'iwl_indistribution_loss': 0.34537129282951357, 'iwl_outdistribution_loss': 0.3687699749469757}\n",
      "loss tensor(0.3467, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34786014839808144, 'epoch': 149, 'icl_indistribution_loss': 0.8634712624549866, 'icl_outdistribution_loss': 0.9003448724746704, 'iwl_indistribution_loss': 0.3497630195617676, 'iwl_outdistribution_loss': 0.3768284456729889}\n",
      "loss tensor(0.3435, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3484931641896566, 'epoch': 150, 'icl_indistribution_loss': 0.8723143467903137, 'icl_outdistribution_loss': 0.9074486255645752, 'iwl_indistribution_loss': 0.3448206939697266, 'iwl_outdistribution_loss': 0.37162958550453185}\n",
      "loss tensor(0.3492, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34790564374923705, 'epoch': 151, 'icl_indistribution_loss': 0.8890437264442443, 'icl_outdistribution_loss': 0.8969067478179932, 'iwl_indistribution_loss': 0.354428129196167, 'iwl_outdistribution_loss': 0.3698272955417633}\n",
      "loss tensor(0.3507, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34849392714500427, 'epoch': 152, 'icl_indistribution_loss': 0.8741961259841919, 'icl_outdistribution_loss': 0.8990804867744446, 'iwl_indistribution_loss': 0.34982275843620303, 'iwl_outdistribution_loss': 0.3709161684513092}\n",
      "loss tensor(0.3461, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34785357718467713, 'epoch': 153, 'icl_indistribution_loss': 0.8595243816375733, 'icl_outdistribution_loss': 0.8896498990058899, 'iwl_indistribution_loss': 0.34889771151542665, 'iwl_outdistribution_loss': 0.3640552535057068}\n",
      "loss tensor(0.3610, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34821588589350383, 'epoch': 154, 'icl_indistribution_loss': 0.8679510102272033, 'icl_outdistribution_loss': 0.8623512148857116, 'iwl_indistribution_loss': 0.3492014932632446, 'iwl_outdistribution_loss': 0.37094522547721864}\n",
      "loss tensor(0.3465, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34782632973988853, 'epoch': 155, 'icl_indistribution_loss': 0.8988232169151306, 'icl_outdistribution_loss': 0.9033821778297424, 'iwl_indistribution_loss': 0.3618708140850067, 'iwl_outdistribution_loss': 0.385314528465271}\n",
      "loss tensor(0.3345, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3472462306340535, 'epoch': 156, 'icl_indistribution_loss': 0.8663317313194275, 'icl_outdistribution_loss': 0.905131495475769, 'iwl_indistribution_loss': 0.3511750781536102, 'iwl_outdistribution_loss': 0.376665741443634}\n",
      "loss tensor(0.3490, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3467730896313985, 'epoch': 157, 'icl_indistribution_loss': 0.8644798636436463, 'icl_outdistribution_loss': 0.9007055106163024, 'iwl_indistribution_loss': 0.35342586994171143, 'iwl_outdistribution_loss': 0.3612639226913452}\n",
      "loss tensor(0.3468, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34768181721369423, 'epoch': 158, 'icl_indistribution_loss': 0.8708615441322327, 'icl_outdistribution_loss': 0.90931920337677, 'iwl_indistribution_loss': 0.3482601456642151, 'iwl_outdistribution_loss': 0.3716645369529724}\n",
      "loss tensor(0.3451, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3466496561686198, 'epoch': 159, 'icl_indistribution_loss': 0.8639867439270019, 'icl_outdistribution_loss': 0.9086162738800049, 'iwl_indistribution_loss': 0.34348204588890074, 'iwl_outdistribution_loss': 0.3750210659503937}\n",
      "loss tensor(0.3473, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3484166663169861, 'epoch': 160, 'icl_indistribution_loss': 0.8608330821990967, 'icl_outdistribution_loss': 0.8976674561500549, 'iwl_indistribution_loss': 0.35078246879577635, 'iwl_outdistribution_loss': 0.3705764133930206}\n",
      "loss tensor(0.3388, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34690556732813516, 'epoch': 161, 'icl_indistribution_loss': 0.8925880131721496, 'icl_outdistribution_loss': 0.9091828255653381, 'iwl_indistribution_loss': 0.3517012205123901, 'iwl_outdistribution_loss': 0.36570088386535643}\n",
      "loss tensor(0.3337, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3482357919216156, 'epoch': 162, 'icl_indistribution_loss': 0.8787593064308167, 'icl_outdistribution_loss': 0.9126663112640381, 'iwl_indistribution_loss': 0.35228357005119326, 'iwl_outdistribution_loss': 0.37500636839866636}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(0.3537, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34683166494369505, 'epoch': 163, 'icl_indistribution_loss': 0.909982458114624, 'icl_outdistribution_loss': 0.8790371198654174, 'iwl_indistribution_loss': 0.3494947950839996, 'iwl_outdistribution_loss': 0.3562524094581604}\n",
      "loss tensor(0.3594, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3472113432566325, 'epoch': 164, 'icl_indistribution_loss': 0.8806422600746154, 'icl_outdistribution_loss': 0.8878154120445252, 'iwl_indistribution_loss': 0.3470101547241211, 'iwl_outdistribution_loss': 0.3619368896484375}\n",
      "loss tensor(0.3598, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.346969175084432, 'epoch': 165, 'icl_indistribution_loss': 0.866724627494812, 'icl_outdistribution_loss': 0.8919836521148682, 'iwl_indistribution_loss': 0.34598433566093445, 'iwl_outdistribution_loss': 0.37446723246574404}\n",
      "loss tensor(0.3592, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34702872831026715, 'epoch': 166, 'icl_indistribution_loss': 0.8759878334999085, 'icl_outdistribution_loss': 0.8868720526695252, 'iwl_indistribution_loss': 0.3497959508895874, 'iwl_outdistribution_loss': 0.3611945922374725}\n",
      "loss tensor(0.3601, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3469959897041321, 'epoch': 167, 'icl_indistribution_loss': 0.8880223965644837, 'icl_outdistribution_loss': 0.8848974165916443, 'iwl_indistribution_loss': 0.35599749493598937, 'iwl_outdistribution_loss': 0.3674276909828186}\n",
      "loss tensor(0.3475, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3474807305812836, 'epoch': 168, 'icl_indistribution_loss': 0.8748492918014527, 'icl_outdistribution_loss': 0.8821480231285095, 'iwl_indistribution_loss': 0.3395965349674225, 'iwl_outdistribution_loss': 0.3654087145328522}\n",
      "loss tensor(0.3539, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3473025968074799, 'epoch': 169, 'icl_indistribution_loss': 0.8949999341964722, 'icl_outdistribution_loss': 0.9124925479888916, 'iwl_indistribution_loss': 0.35180021047592164, 'iwl_outdistribution_loss': 0.37059287762641907}\n",
      "loss tensor(0.3476, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3471867643515269, 'epoch': 170, 'icl_indistribution_loss': 0.8714500608444213, 'icl_outdistribution_loss': 0.8880721983909607, 'iwl_indistribution_loss': 0.34371060991287233, 'iwl_outdistribution_loss': 0.36618197536468505}\n",
      "loss tensor(0.3580, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3464718540509542, 'epoch': 171, 'icl_indistribution_loss': 0.8790976834297181, 'icl_outdistribution_loss': 0.8968694014549256, 'iwl_indistribution_loss': 0.34843121218681333, 'iwl_outdistribution_loss': 0.3675215187072754}\n",
      "loss tensor(0.3452, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34682576263745624, 'epoch': 172, 'icl_indistribution_loss': 0.8779462132453918, 'icl_outdistribution_loss': 0.8790767102241516, 'iwl_indistribution_loss': 0.3461018354892731, 'iwl_outdistribution_loss': 0.3665351128578186}\n",
      "loss tensor(0.3453, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34566470839182534, 'epoch': 173, 'icl_indistribution_loss': 0.8736710238456726, 'icl_outdistribution_loss': 0.8954882564544677, 'iwl_indistribution_loss': 0.3494595665931702, 'iwl_outdistribution_loss': 0.3638402874469757}\n",
      "loss tensor(0.3352, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34710272900263467, 'epoch': 174, 'icl_indistribution_loss': 0.8877646946907043, 'icl_outdistribution_loss': 0.9034926776885986, 'iwl_indistribution_loss': 0.3534778771400452, 'iwl_outdistribution_loss': 0.36958476328849793}\n",
      "loss tensor(0.3477, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34658200062115985, 'epoch': 175, 'icl_indistribution_loss': 0.8426005692481995, 'icl_outdistribution_loss': 0.8802520761489868, 'iwl_indistribution_loss': 0.3441865937709808, 'iwl_outdistribution_loss': 0.36847432351112364}\n",
      "loss tensor(0.3272, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34641015497843425, 'epoch': 176, 'icl_indistribution_loss': 0.8851304750442505, 'icl_outdistribution_loss': 0.8894804267883301, 'iwl_indistribution_loss': 0.34144834780693056, 'iwl_outdistribution_loss': 0.36642515802383424}\n",
      "loss tensor(0.3329, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3459830676078796, 'epoch': 177, 'icl_indistribution_loss': 0.86663356590271, 'icl_outdistribution_loss': 0.946749773979187, 'iwl_indistribution_loss': 0.34212453579902646, 'iwl_outdistribution_loss': 0.3624662113189697}\n",
      "loss tensor(0.3550, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3473932885487874, 'epoch': 178, 'icl_indistribution_loss': 0.8602167711257934, 'icl_outdistribution_loss': 0.885127564907074, 'iwl_indistribution_loss': 0.3422685208320618, 'iwl_outdistribution_loss': 0.36522751426696776}\n",
      "loss tensor(0.3380, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3476304229100545, 'epoch': 179, 'icl_indistribution_loss': 0.8512715964317322, 'icl_outdistribution_loss': 0.8769916749000549, 'iwl_indistribution_loss': 0.34178996777534487, 'iwl_outdistribution_loss': 0.3701546275615692}\n",
      "loss tensor(0.3374, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34726341492335, 'epoch': 180, 'icl_indistribution_loss': 0.8857819557189941, 'icl_outdistribution_loss': 0.9104271411895752, 'iwl_indistribution_loss': 0.3478450753688812, 'iwl_outdistribution_loss': 0.3700652620792389}\n",
      "loss tensor(0.3403, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3463233956019084, 'epoch': 181, 'icl_indistribution_loss': 0.8743104100227356, 'icl_outdistribution_loss': 0.901749617099762, 'iwl_indistribution_loss': 0.34846744227409365, 'iwl_outdistribution_loss': 0.35840448760986326}\n",
      "loss tensor(0.3611, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34700780658721925, 'epoch': 182, 'icl_indistribution_loss': 0.8816130080223084, 'icl_outdistribution_loss': 0.8947224230766296, 'iwl_indistribution_loss': 0.3412237946987152, 'iwl_outdistribution_loss': 0.3727697882652283}\n",
      "loss tensor(0.3669, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34571274282137554, 'epoch': 183, 'icl_indistribution_loss': 0.8772606463432312, 'icl_outdistribution_loss': 0.87651957321167, 'iwl_indistribution_loss': 0.3475663824081421, 'iwl_outdistribution_loss': 0.374542596578598}\n",
      "loss tensor(0.3337, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3466704256216685, 'epoch': 184, 'icl_indistribution_loss': 0.8554325971603394, 'icl_outdistribution_loss': 0.888352023601532, 'iwl_indistribution_loss': 0.3441780500411987, 'iwl_outdistribution_loss': 0.37102699708938597}\n",
      "loss tensor(0.3421, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34710754130681354, 'epoch': 185, 'icl_indistribution_loss': 0.8724560303688049, 'icl_outdistribution_loss': 0.907024745464325, 'iwl_indistribution_loss': 0.33849238777160645, 'iwl_outdistribution_loss': 0.3636645972728729}\n",
      "loss tensor(0.3482, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3462353716850281, 'epoch': 186, 'icl_indistribution_loss': 0.890244562625885, 'icl_outdistribution_loss': 0.8899898467063904, 'iwl_indistribution_loss': 0.3481470856666565, 'iwl_outdistribution_loss': 0.36427223062515257}\n",
      "loss tensor(0.3488, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34646899960835775, 'epoch': 187, 'icl_indistribution_loss': 0.9076738786697388, 'icl_outdistribution_loss': 0.9209182391166687, 'iwl_indistribution_loss': 0.34464468264579773, 'iwl_outdistribution_loss': 0.36252133655548097}\n",
      "loss tensor(0.3599, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3461283591270447, 'epoch': 188, 'icl_indistribution_loss': 0.8838932404518127, 'icl_outdistribution_loss': 0.8964613099098205, 'iwl_indistribution_loss': 0.3455489664077759, 'iwl_outdistribution_loss': 0.3677244820594788}\n",
      "loss tensor(0.3731, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34672153571446734, 'epoch': 189, 'icl_indistribution_loss': 0.8697439403533935, 'icl_outdistribution_loss': 0.9175250706672669, 'iwl_indistribution_loss': 0.341189817905426, 'iwl_outdistribution_loss': 0.3627735803127289}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(0.3334, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.346908412138621, 'epoch': 190, 'icl_indistribution_loss': 0.86175333070755, 'icl_outdistribution_loss': 0.8948555688858032, 'iwl_indistribution_loss': 0.3438070592880249, 'iwl_outdistribution_loss': 0.36619336581230166}\n",
      "loss tensor(0.3390, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34657426880200704, 'epoch': 191, 'icl_indistribution_loss': 0.8736184859275817, 'icl_outdistribution_loss': 0.92083589220047, 'iwl_indistribution_loss': 0.35220761370658876, 'iwl_outdistribution_loss': 0.36602503299713135}\n",
      "loss tensor(0.3433, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3458853611628214, 'epoch': 192, 'icl_indistribution_loss': 0.8737509427070618, 'icl_outdistribution_loss': 0.9173771696090698, 'iwl_indistribution_loss': 0.3463476691246033, 'iwl_outdistribution_loss': 0.36295228719711303}\n",
      "loss tensor(0.3258, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34663177893956504, 'epoch': 193, 'icl_indistribution_loss': 0.893290584564209, 'icl_outdistribution_loss': 0.8858923420906067, 'iwl_indistribution_loss': 0.3524605450630188, 'iwl_outdistribution_loss': 0.3687290508747101}\n",
      "loss tensor(0.3748, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3453412900606791, 'epoch': 194, 'icl_indistribution_loss': 0.8512870688438415, 'icl_outdistribution_loss': 0.9022401165962219, 'iwl_indistribution_loss': 0.3425074796676636, 'iwl_outdistribution_loss': 0.36490441727638245}\n",
      "loss tensor(0.3621, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3464056092739105, 'epoch': 195, 'icl_indistribution_loss': 0.8871853694915771, 'icl_outdistribution_loss': 0.878771348953247, 'iwl_indistribution_loss': 0.34862155628204344, 'iwl_outdistribution_loss': 0.3580665187835693}\n",
      "loss tensor(0.3596, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34556010489463806, 'epoch': 196, 'icl_indistribution_loss': 0.8686728572845459, 'icl_outdistribution_loss': 0.8999731016159057, 'iwl_indistribution_loss': 0.3460474421977997, 'iwl_outdistribution_loss': 0.36215554642677306}\n",
      "loss tensor(0.3576, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3454925541559855, 'epoch': 197, 'icl_indistribution_loss': 0.8960869770050048, 'icl_outdistribution_loss': 0.9122179551124573, 'iwl_indistribution_loss': 0.34041724872589113, 'iwl_outdistribution_loss': 0.36809903335571287}\n",
      "loss tensor(0.3390, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34479909461339314, 'epoch': 198, 'icl_indistribution_loss': 0.877158625125885, 'icl_outdistribution_loss': 0.9034585733413696, 'iwl_indistribution_loss': 0.346467621088028, 'iwl_outdistribution_loss': 0.37408523297309876}\n",
      "loss tensor(0.3443, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.345224556239446, 'epoch': 199, 'icl_indistribution_loss': 0.8645133104324341, 'icl_outdistribution_loss': 0.9088424973487854, 'iwl_indistribution_loss': 0.3449721817970276, 'iwl_outdistribution_loss': 0.37664059734344485}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# import matplotlib.pyplot as plt\n",
    "exp_name = f\"./cache/{args.wandb_group_name}_{args.fileprefix}_{time.time()}.pkl\"\n",
    "for epoch in range(args.epochs):\n",
    "    # icl_indistribution_losses = validate_gradient_descent(epoch, icl_test_loader, model, args, criterion, device, coarse_graining=\"standard\")\n",
    "    # icl_outdistribution_losses = validate_gradient_descent(epoch, icl_test_loader, model, args, criterion, device, coarse_graining=args.coarse_graining)\n",
    "    # iwl_indistribution_losses = validate_gradient_descent(epoch, iwl_test_loader, model, args, criterion, device, coarse_graining=\"standard\")\n",
    "    # iwl_outdistribution_losses = validate_gradient_descent(epoch, iwl_test_loader, model, args, criterion, device, coarse_graining=args.coarse_graining)\n",
    "    \n",
    "    model.train() # switch to train mode\n",
    "    losses = utils.AverageMeter('Loss', ':.4e')\n",
    "    ridge_losses = utils.AverageMeter('Ridge Loss', ':.4e')\n",
    "    top1 = utils.AverageMeter('Acc@1', ':6.2f')\n",
    "\n",
    " \n",
    "    for i, (seq, target, _) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        seq, target = seq.to(device), target.to(device)\n",
    "        # print (\"seq\", seq.shape, \"target\", target.shape)\n",
    "        output = model(seq, target) \n",
    "        # print (\"seq\", seq.shape, \"target\", target, \"output\", output )\n",
    "        preds = output[:, ::2, :] # shape: (B, L, 1)\n",
    "        loss = criterion(preds, target)\n",
    "        \n",
    "        # batch_first_seq, batch_first_target = seq[0, :-1, :], target[0, :-1, 0]\n",
    "        # print (\"batch_first_seq\", batch_first_seq.shape, \"batch_first_target\", batch_first_target.shape)\n",
    "        # ridge = utils.Ridge(alpha=1e-9,fit_intercept=True) \n",
    "        # ridge.fit(batch_first_seq, batch_first_target)\n",
    "        # val_loss = criterion(ridge.predict(seq[0, [-1], :]), target[0, -1, 0])\n",
    "        # print (\"loss\", loss)\n",
    "        # ridge_losses.update(val_loss.item(), 1) \n",
    "        # compute ridge loss on first sequence\n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.update(loss.item(), target.size(0)) \n",
    "        # acc1 = utils.accuracy(output, (seq_target), topk=[1])\n",
    "        # print (\"output\", output.shape, output[0], seq_target[0], loss, acc1, model.temperature)\n",
    "        # top1.update(acc1[0], target.size(0))\n",
    "        # acc1 = torch.mean(((output.squeeze(1) * (seq_target*2-1)) > 0).float()).item()\n",
    "        # top1.update(acc1, target.size(0))\n",
    "        # step scheduler\n",
    "        scheduler.step()\n",
    "    print (\"loss\" , loss, \"preds\", preds.shape, \"target\", target.shape)\n",
    "    \n",
    "\n",
    "    # save metrics\n",
    "    # print(\"output\",  torch.argsort(output, dim=-1), \"target\", target )\n",
    "    # print(\"Current average loss\", losses.avg, top1.avg, \"epoch\", epoch) \n",
    "    # seen_val_losses, seen_val_top1 = validate_gradient_descent(icl_loader, seen_projs_permutations_loader, model, args, criterion, device)\n",
    "    \n",
    "    # Compute unseen val loss\n",
    "    # unseen_val_losses, unseen_val_top1 = validate_gradient_descent(icl_loader, seen_projs_permutations_loader, model, args, criterion, device)\n",
    "    logs = {\n",
    "            \"train_loss\": losses.avg,\n",
    "            \"epoch\": epoch,\n",
    "            \"lr\": optimizer.param_groups[0]['lr'],\n",
    "            # \"icl_indistribution_loss\": icl_indistribution_losses.avg,\n",
    "            # \"icl_outdistribution_loss\": icl_outdistribution_losses.avg,\n",
    "            # \"iwl_indistribution_loss\": iwl_indistribution_losses.avg,\n",
    "            # \"iwl_outdistribution_loss\": iwl_outdistribution_losses.avg,\n",
    "        }\n",
    "    # for _ in range(args.len_context):\n",
    "    #     logs[f\"icl_indistribution_loss_{_}\"] = icl_indistribution_losses[_].avg\n",
    "    #     logs[f\"icl_outdistribution_loss_{_}\"] = icl_outdistribution_losses[_].avg\n",
    "    #     logs[f\"iwl_indistribution_loss_{_}\"] = iwl_indistribution_losses[_].avg\n",
    "    #     logs[f\"iwl_outdistribution_loss_{_}\"] = iwl_outdistribution_losses[_].avg\n",
    "    \n",
    "    # print(logs) \n",
    "    if args.wandb_log:\n",
    "        wandb.log(logs)\n",
    "    else:\n",
    "        record[\"logs\"].append(logs)\n",
    "    \n",
    " \n",
    "    # save phi_xt_list_epoch \n",
    "    \n",
    "    \n",
    "    if epoch % 10 == 0 and args.wandb_log != True:\n",
    "        record[\"model\"] = copy.deepcopy(model.state_dict())  \n",
    "        with open(exp_name, \"wb\") as f:\n",
    "            pickle.dump(record, f)\n",
    "        # print (record[\"model\"])\n",
    "record[\"model\"] = copy.deepcopy(model.state_dict())  \n",
    "if args.wandb_log != True:\n",
    "    with open(exp_name, \"wb\") as f:\n",
    "        pickle.dump(record, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (l2l)",
   "language": "python",
   "name": "l2l"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
