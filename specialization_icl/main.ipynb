{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "from enum import Enum\n",
    "import importlib\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim.lr_scheduler import StepLR, OneCycleLR\n",
    "from torch.utils.data import Subset\n",
    "import attention\n",
    "# import webdataset as wds\n",
    "\n",
    "import datetime\n",
    "import utils\n",
    "import numpy as np\n",
    "import math\n",
    "import einops\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import wandb \n",
    "import sys \n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--data ./cache --fileprefix transformer1layer  --SLURM_ARRAY_TASK_ID 5 --batch-size 128 --optimizer SGD --lr 1e-2 --wd 1e-10  --epochs 200 --arch gpt --num_hidden_features 256 --num_layers 1 --len_context 16 --K 100 --D_sum 8 --D_visible_frac 3 --sigma_xi 0.5 --coarse_graining abstop --no-wandb_log --wandb_project renormalization --wandb_group_name t\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "LOCAL RANK  0\n",
      "args:\n",
      " {'data': './cache', 'cache': './cache', 'wandb_log': False, 'wandb_project': 'renormalization', 'wandb_group_name': 't', 'seed': 9784336, 'epochs': 200, 'batch_size': 128, 'workers': 4, 'optimizer': 'SGD', 'lr': 0.01, 'momentum': 0.9, 'weight_decay': 1e-10, 'arch': 'gpt', 'num_hidden_features': 256, 'num_layers': 1, 'len_context': 16, 'SLURM_ARRAY_TASK_ID': 5, 'no_cuda': False, 'D_sum': 8, 'D_visible_frac': 3.0, 'K': 100, 'coarse_graining': 'abstop', 'sigma_xi': 0.5, 'fileprefix': 'transformer1layer', 'D_visible': 3}\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='GMM L2L Training with Sequence Model')\n",
    "parser.add_argument('--data', metavar='DIR', nargs='?', default='./data',\n",
    "                    help='path to dataset (default: imagenet)')\n",
    "parser.add_argument('--cache', default='./cache',\n",
    "                    help='path to cached files (e.g. for previous random weights)')\n",
    "parser.add_argument(\n",
    "    \"--wandb_log\",action=argparse.BooleanOptionalAction,default=False,\n",
    "    help=\"whether to log to wandb\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--wandb_project\",type=str,default=\"stability\",\n",
    "    help=\"wandb project name\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--wandb_group_name\",type=str,default=\"stability\",\n",
    "    help=\"wandb project name\",\n",
    ")\n",
    "parser.add_argument('--seed', default=None, type=int,\n",
    "                    help='seed for initializing training.')\n",
    "parser.add_argument('--epochs', default=90, type=int,  \n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('-b', '--batch-size', default=64, type=int,\n",
    "                    metavar='N',\n",
    "                    help='mini-batch size (default: 256), this is the total '\n",
    "                         'batch size of all GPUs on the current node when '\n",
    "                         'using Data Parallel or Distributed Data Parallel')                         \n",
    "parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 4)')\n",
    "parser.add_argument('--optimizer', default='SGD', type=str, \n",
    "                    choices = ['SGD', 'Adam'],\n",
    "                    help='optimizer')\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.1, type=float,\n",
    "                    metavar='LR', help='initial learning rate', dest='lr')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
    "                    help='momentum')\n",
    "parser.add_argument('--wd', '--weight-decay', default=1e-5, type=float,\n",
    "                    metavar='W', help='weight decay (default: 1e-4)',\n",
    "                    dest='weight_decay')\n",
    "parser.add_argument('--arch', '-a', metavar='ARCH', default='mlp',\n",
    "                    help='model architecture (default: mlp)')\n",
    "parser.add_argument('--gpt_bias', default=\"True\", type=str,\n",
    "                    help='whether to include bias in GPT')\n",
    "parser.add_argument('--num_hidden_features', default=1, type=int,\n",
    "                    help='num_hidden_features')\n",
    "parser.add_argument('--num_layers', default=1, type=int,\n",
    "                    help='num_layers in transformer')\n",
    "parser.add_argument('--len_context', default=1, type=int,\n",
    "                    help='number of in-context images in sequence')\n",
    "parser.add_argument('--SLURM_ARRAY_TASK_ID', default=1, type=int,\n",
    "                    help='SLURM_ARRAY_TASK_ID')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                        help='disables CUDA training')  \n",
    "parser.add_argument('--D_sum', default=1000, type=int, help='number of visible+ hidden features')\n",
    "parser.add_argument('--D_visible_frac', default=1.0, type=float, help='fraction of features visible') \n",
    "parser.add_argument('--K', default=1, type=int, \n",
    "                    help='number of tasks')\n",
    "parser.add_argument('--coarse_graining', default=\"abstop\", type=str,\n",
    "                    help='coarse graining method')\n",
    "parser.add_argument('--sigma_xi', default=1.0, type=float, help='noise level')\n",
    "parser.add_argument(\n",
    "            '--fileprefix', \n",
    "            default=\"\",\n",
    "            type=str, \n",
    "            action='store') \n",
    "    \n",
    "\n",
    "# if running this interactively, can specify jupyter_args here for argparser to use\n",
    "if utils.is_interactive():\n",
    "    arch = \"pytorch_transformer\"\n",
    "    # arch = \"transformer\"\n",
    "    jupyter_args = f\"--data ./cache --fileprefix transformer1layer  --SLURM_ARRAY_TASK_ID 5 --batch-size 128 --optimizer SGD --lr 1e-2 --wd 1e-10  --epochs 200 --arch gpt --num_hidden_features 256 --num_layers 1 --len_context 16 --K 100 --D_sum 8 --D_visible_frac 3 --sigma_xi 0.5 --coarse_graining abstop --no-wandb_log --wandb_project renormalization --wandb_group_name t\"\n",
    "    \n",
    "    print(jupyter_args)\n",
    "    jupyter_args = jupyter_args.split()\n",
    "    \n",
    "    from IPython.display import clear_output # function to clear print outputs in cell\n",
    "    %load_ext autoreload \n",
    "    # this allows you to change functions in models.py or utils.py and have this notebook automatically update with your revisions\n",
    "    %autoreload 2 \n",
    "\n",
    "if utils.is_interactive():\n",
    "    args = parser.parse_args(jupyter_args)\n",
    "else:\n",
    "    args = parser.parse_args()\n",
    "\n",
    "args.D_visible = int(args.D_visible_frac) # just using D=8 max(int(args.D_visible_frac * args.D_sum),1)\n",
    "# assert args.K % args.L == 0, \"K must be divisible by L\"\n",
    "if args.seed is None:\n",
    "    args.seed = np.random.randint(0, 10000000)\n",
    "\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed_all(args.seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "  \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Local Rank for distributed training\n",
    "local_rank = os.getenv('RANK')\n",
    "if local_rank is None: \n",
    "    local_rank = 0\n",
    "else:\n",
    "    local_rank = int(local_rank)\n",
    "print(\"LOCAL RANK \", local_rank)\n",
    "print(\"args:\\n\",vars(args))\n",
    "# setup weights and biases (optional)\n",
    "if local_rank==0 and args.wandb_log: # only use main process for wandb logging\n",
    "    print(f\"wandb {args.wandb_project} run\")\n",
    "    wandb.login(host='https://stability.wandb.io') # need to configure wandb environment beforehand\n",
    "    wandb_model_name = f\"{args.fileprefix}_K_{args.K}_D_{args.D_sum}_L_{args.len_context}_hidden_{args.num_hidden_features}_coarse_{args.coarse_graining}\"\n",
    "    wandb_config = vars(args)\n",
    "    \n",
    "    print(\"wandb_id:\",wandb_model_name)\n",
    "    wandb.init(\n",
    "        project=args.wandb_project,\n",
    "        name=wandb_model_name,\n",
    "        config=wandb_config,\n",
    "        resume=\"allow\",\n",
    "        group=args.wandb_group_name\n",
    "    )\n",
    "    wandb.config.local_file_dir = wandb.run.dir \n",
    "else:\n",
    "    record = {\n",
    "        \"args\": vars(args),\n",
    "        \"logs\": []\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequence(torch.utils.data.Dataset):\n",
    "    def __init__(self, K, D,  \n",
    "                 len_context = 1,\n",
    "                 scale=0.5,\n",
    "                len_data = 60000, skip_generating_betas=False):\n",
    "\n",
    "        # if K < 40000:\n",
    "        self.len_context = len_context\n",
    "        self.D = D\n",
    "    \n",
    "        # x = rng.standard_normal((K, D)) * (1.0 / np.sqrt(D)) # shape: (K, D) \n",
    "        self.scale = scale\n",
    "        if skip_generating_betas == False:\n",
    "            true_betas = torch.randn((K, D)) * scale #* (1.0 / np.sqrt(D)) # shape: (K, D)\n",
    "            self.true_betas = true_betas\n",
    "        self.K = K \n",
    "        self.D = D\n",
    "        self.len_data = len_data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len_data\n",
    "\n",
    "    def __getitem__(self, task: int):\n",
    "        task_ind = torch.randint(0, self.K, (1,)).item()\n",
    "        beta_incontext = self.true_betas[task_ind].unsqueeze(1) # shape: (D, 1)\n",
    "        x = torch.randn((self.len_context, self.D)) * self.scale  # shape: (self.len_context, D) * (1.0 / np.sqrt(self.D))\n",
    "        noise = torch.randn((self.len_context, 1)) * args.sigma_xi\n",
    "        y = torch.matmul(x, beta_incontext) + noise\n",
    "\n",
    "        # concat x and y \n",
    "        samples = x#torch.cat([x, y], axis = 1) # shape: (self.len_context, D+1)\n",
    "        # ytest = samples[-1, -1].clone() \n",
    "        # samples[-1, -1] = 0.0 # remove ytest from samples \n",
    "         \n",
    "          \n",
    "        return samples.type(torch.float32), y.type(torch.float32), beta_incontext.type(torch.float32)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 202880\n"
     ]
    }
   ],
   "source": [
    "# importlib.reload(gpt)\n",
    "import gpt\n",
    "criterion = nn.MSELoss().to(device)\n",
    "# define the model, optimizer, and scheduler, and criterion\n",
    "if args.arch == \"causal_transformer_embed\":\n",
    "    nheads = 1 # np.clip(args.num_hidden_features // 8, 1, 8)\n",
    "    model = attention.MultiLayerTransformer(x_dim=args.D_sum,                   \n",
    "                                  mlp_dim=args.num_hidden_features, \n",
    "                                  num_layers = args.num_layers\n",
    "                                  ).to(device)\n",
    "if args.arch == \"gpt\":\n",
    "    import gpt \n",
    "    config = gpt.GPTConfig(\n",
    "        block_size = args.len_context,\n",
    "        input_size = args.D_sum,\n",
    "        n_embd=args.num_hidden_features,\n",
    "        n_layer=args.num_layers,\n",
    "        bias = args.gpt_bias == \"True\"\n",
    "    )\n",
    "    model = gpt.GPT(config, criterion).to(device)\n",
    "\n",
    "if args.optimizer == 'SGD': \n",
    "    optimizer = torch.optim.SGD(model.parameters(),  \n",
    "                            lr=args.lr, \n",
    "                            weight_decay=args.weight_decay\n",
    "                            )\n",
    "elif args.optimizer == 'Adam':\n",
    "    optimizer = torch.optim.Adam(model.parameters(),  \n",
    "                            lr=args.lr, \n",
    "                            weight_decay=args.weight_decay\n",
    "                            )\n",
    "else:\n",
    "    raise ValueError(\"optimizer not recognized\")\n",
    "iters_per_epoch = 1000\n",
    "# scheduler = StepLR(optimizer, step_size=50, gamma=0.7)\n",
    "scheduler = OneCycleLR(optimizer, max_lr=args.lr, \n",
    "                       total_steps=args.epochs * iters_per_epoch, \n",
    "                       pct_start=0.5,\n",
    "                       steps_per_epoch=iters_per_epoch, epochs=args.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the dataset\n",
    "train_kwargs = {'batch_size': args.batch_size}\n",
    "test_kwargs = {'batch_size': args.batch_size}\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    cuda_kwargs = {'num_workers': args.workers,\n",
    "                    \"shuffle\": True,\n",
    "                    'pin_memory': True}\n",
    "    train_kwargs.update(cuda_kwargs)\n",
    "    test_kwargs.update(cuda_kwargs)\n",
    "train_dataset = Sequence(K=args.K, D=args.D_sum, len_context=args.len_context, len_data = args.batch_size * iters_per_epoch)\n",
    "# iwl_dataset = Sequence(K=args.K, D=args.D_sum, len_context=args.len_context, len_data = 1000)\n",
    "# iwl_dataset.true_betas = train_dataset.true_betas\n",
    "icl_test_dataset = Sequence(K=1000, D=args.D_sum, len_context=args.len_context, len_data = 1000)\n",
    "\n",
    "iwl_test_dataset = Sequence(K=args.K, D=args.D_sum, len_context=args.len_context, len_data = 1000, skip_generating_betas = True)\n",
    "iwl_test_dataset.true_betas = train_dataset.true_betas\n",
    "\n",
    "train_sampler = None\n",
    "val_sampler = None \n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                            sampler=train_sampler, \n",
    "                                            **train_kwargs) \n",
    "icl_test_loader = torch.utils.data.DataLoader(icl_test_dataset,\n",
    "                                            sampler=val_sampler,\n",
    "                                            **test_kwargs)  \n",
    "iwl_test_loader = torch.utils.data.DataLoader(iwl_test_dataset,\n",
    "                                            sampler=val_sampler,\n",
    "                                            **test_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_gradient_descent(epoch, val_loader, model, args, criterion, device, coarse_graining=\"standard\"):\n",
    "    # seq_lens = list(range(1, args.len_context+1, 5)) \n",
    "   \n",
    "    test_losses = [utils.AverageMeter('Loss', ':.4e') for _ in range(args.len_context)]\n",
    "    \n",
    "    model.eval() # switch to eval mode\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (seq, target, _true_beta) in enumerate(val_loader):\n",
    "            seq, target, _true_beta = seq.to(device), target.to(device), _true_beta.to(device)\n",
    "            B, N, D = seq.size()\n",
    "            if coarse_graining == \"absbot\":\n",
    "                # true_beta: shape (B, D)\n",
    "                true_beta = _true_beta.squeeze(2)\n",
    "                argsort_beta_visible = torch.argsort(torch.abs(true_beta), dim=-1)[:, :args.D_visible] # sort each row of true_beta by absolute value, shape (B, D_visible)\n",
    "                test_beta_visible = torch.gather(true_beta, dim=1, index=argsort_beta_visible) # shape (B, D_visible)\n",
    "                sigma_test_xi = torch.pow(args.sigma_xi ** 2 + torch.matmul(true_beta.unsqueeze(1), true_beta.unsqueeze(2)).squeeze(2).squeeze(1) \\\n",
    "                                        - torch.matmul(test_beta_visible.unsqueeze(1), test_beta_visible.unsqueeze(2)).squeeze(2).squeeze(1), 0.5)\n",
    "                x_test_visible = torch.gather(seq[:, -1, :].squeeze(1), dim=1, index=argsort_beta_visible) # shape (B, D_visible)\n",
    "                new_target = torch.matmul(x_test_visible.unsqueeze(1), test_beta_visible.unsqueeze(2)).squeeze(2) \n",
    "                new_target = new_target.squeeze(1)\n",
    "                new_target += torch.randn(new_target.size(0), device=device) * sigma_test_xi # shape (B, 1) \n",
    "                target[:, -1, 0] = new_target\n",
    "                \n",
    "            elif coarse_graining == \"abstop\":\n",
    "                true_beta = _true_beta.squeeze(2) # shape (B, D)\n",
    "                # print (\"true_beta\", true_beta.shape)\n",
    "                argsort_beta_visible = torch.argsort(torch.abs(true_beta), dim=-1)[:, -args.D_visible:] # sort each row of true_beta by absolute value, shape (B, D_visible)\n",
    "                # test_beta_visible = true_beta[argsort_beta_visible] # take top D_visible betas, shape (B, D_visible) \n",
    "                test_beta_visible = torch.gather(true_beta, dim=1, index=argsort_beta_visible) # shape (B, D_visible)\n",
    "                # print  (\"-args.D_visible\", -args.D_visible, \"argsort_beta_visible\", argsort_beta_visible.shape, \"test_beta_visible\", test_beta_visible.shape)\n",
    "                sigma_test_xi = torch.pow(args.sigma_xi ** 2 + torch.matmul(true_beta.unsqueeze(1), true_beta.unsqueeze(2)) \\\n",
    "                                        - torch.matmul(test_beta_visible.unsqueeze(1), test_beta_visible.unsqueeze(2)), 0.5).squeeze(2).squeeze(1) # shape (B)\n",
    "                # x_test_visible = seq[:, -1, :-1].squeeze(1)[argsort_beta_visible] # shape (B, D_visible)\n",
    "                x_test_visible = torch.gather(seq[:, -1, :].squeeze(1), dim=1, index=argsort_beta_visible) # shape (B, D_visible) \n",
    "                \n",
    "                # target = x_test_visible  @ test_beta_visible + np.random.randn(N_test) * sigma_test_xi\n",
    "                new_target = torch.matmul(x_test_visible.unsqueeze(1), test_beta_visible.unsqueeze(2)).squeeze(2) \n",
    "                new_target = new_target.squeeze(1)\n",
    "                new_target += torch.randn(new_target.size(0), device=device) * sigma_test_xi # shape (B, 1) \n",
    "                # print (\"new_target\", new_target, \"sigma_test_xi\", sigma_test_xi )\n",
    "                target[:, -1, 0] = new_target\n",
    "\n",
    "                \n",
    "            elif coarse_graining == \"standard\":\n",
    "                pass\n",
    "            seq, target = seq.to(device), target.to(device)\n",
    "            # print (\"seq\", seq.shape, \"target\", target.shape)\n",
    "            output = model(seq, target) \n",
    "            # print (\"seq\", seq.shape, \"target\", target.shape, \"output\", output.shape )\n",
    "            preds = output[:, 0::2, :]\n",
    "            \n",
    "            loss = (preds - target).pow(2).squeeze(-1).mean(dim=1) \n",
    "            # print (\"test preds\", preds.shape, \"test target\", target.shape, \"test loss\", loss.shape)\n",
    "            [test_losses[_].update(loss[_].item(), target.size(0)) for _ in range(N)]\n",
    "            # acc1 = utils.accuracy(output, seq_target, topk=[1])\n",
    "            # test_top1[seq_len].update(acc1[0], target.size(0))\n",
    "            # acc1 = torch.mean(((output.squeeze(1) * (seq_target*2-1)) > 0).float()).item()\n",
    "            # test_top1[seq_len].update(acc1, target.size(0))\n",
    "\n",
    "    return test_losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(0.6612, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.6410686661402385, 'epoch': 0, 'icl_indistribution_loss': 0.7887951202392578, 'icl_outdistribution_loss': 0.8135775637626648, 'iwl_indistribution_loss': 0.7497784976959229, 'iwl_outdistribution_loss': 0.7690922451019288}\n",
      "loss tensor(0.6223, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.6366833840052287, 'epoch': 1, 'icl_indistribution_loss': 0.8158242402076721, 'icl_outdistribution_loss': 0.8702371153831482, 'iwl_indistribution_loss': 0.6429867844581604, 'iwl_outdistribution_loss': 0.6558379397392273}\n",
      "loss tensor(0.6375, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.6370165213267008, 'epoch': 2, 'icl_indistribution_loss': 0.8623828115463257, 'icl_outdistribution_loss': 0.879096981048584, 'iwl_indistribution_loss': 0.649561092376709, 'iwl_outdistribution_loss': 0.6558184995651245}\n",
      "loss tensor(0.6531, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.6376108024597168, 'epoch': 3, 'icl_indistribution_loss': 0.8482468962669373, 'icl_outdistribution_loss': 0.8714955005645751, 'iwl_indistribution_loss': 0.6320598044395447, 'iwl_outdistribution_loss': 0.6529285740852356}\n",
      "loss tensor(0.6013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.6359676260948182, 'epoch': 4, 'icl_indistribution_loss': 0.8424761629104615, 'icl_outdistribution_loss': 0.8360203437805176, 'iwl_indistribution_loss': 0.6349305753707886, 'iwl_outdistribution_loss': 0.6473992333412171}\n",
      "loss tensor(0.6003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.635849758720398, 'epoch': 5, 'icl_indistribution_loss': 0.8334214205741882, 'icl_outdistribution_loss': 0.8670865683555603, 'iwl_indistribution_loss': 0.633486487865448, 'iwl_outdistribution_loss': 0.6489988412857056}\n",
      "loss tensor(0.6543, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.6348802095095316, 'epoch': 6, 'icl_indistribution_loss': 0.8267709860801696, 'icl_outdistribution_loss': 0.8662468366622925, 'iwl_indistribution_loss': 0.6288256349563599, 'iwl_outdistribution_loss': 0.6477975163459778}\n",
      "loss tensor(0.6772, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.6360774869918824, 'epoch': 7, 'icl_indistribution_loss': 0.838953378200531, 'icl_outdistribution_loss': 0.8503444147109985, 'iwl_indistribution_loss': 0.6381931853294373, 'iwl_outdistribution_loss': 0.641967869758606}\n",
      "loss tensor(0.6114, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.6373993120829264, 'epoch': 8, 'icl_indistribution_loss': 0.8375634398460389, 'icl_outdistribution_loss': 0.8605996041297913, 'iwl_indistribution_loss': 0.6359687423706055, 'iwl_outdistribution_loss': 0.6527207980155945}\n",
      "loss tensor(0.6518, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.6378787264823914, 'epoch': 9, 'icl_indistribution_loss': 0.8332234930992126, 'icl_outdistribution_loss': 0.869069052696228, 'iwl_indistribution_loss': 0.6415249676704406, 'iwl_outdistribution_loss': 0.6583036732673645}\n",
      "loss tensor(0.6603, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.6368554553031921, 'epoch': 10, 'icl_indistribution_loss': 0.8431539082527161, 'icl_outdistribution_loss': 0.8593065543174744, 'iwl_indistribution_loss': 0.6472359409332276, 'iwl_outdistribution_loss': 0.6483433966636658}\n",
      "loss tensor(0.6185, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.6353668248812357, 'epoch': 11, 'icl_indistribution_loss': 0.8626873230934143, 'icl_outdistribution_loss': 0.8370506448745727, 'iwl_indistribution_loss': 0.6229755206108093, 'iwl_outdistribution_loss': 0.6512517714500428}\n",
      "loss tensor(0.6094, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.6330670917828878, 'epoch': 12, 'icl_indistribution_loss': 0.8196439995765686, 'icl_outdistribution_loss': 0.8459447865486145, 'iwl_indistribution_loss': 0.6298884425163269, 'iwl_outdistribution_loss': 0.6573931803703308}\n",
      "loss tensor(0.6321, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.6316752840995788, 'epoch': 13, 'icl_indistribution_loss': 0.8222306623458863, 'icl_outdistribution_loss': 0.8825545177459717, 'iwl_indistribution_loss': 0.6399888782501221, 'iwl_outdistribution_loss': 0.6537957539558411}\n",
      "loss tensor(0.6318, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.6223752902348836, 'epoch': 14, 'icl_indistribution_loss': 0.8480581722259521, 'icl_outdistribution_loss': 0.865851915359497, 'iwl_indistribution_loss': 0.6306999850273133, 'iwl_outdistribution_loss': 0.656456874370575}\n",
      "loss tensor(0.6485, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.611500510819753, 'epoch': 15, 'icl_indistribution_loss': 0.8298555393218994, 'icl_outdistribution_loss': 0.8618619856834412, 'iwl_indistribution_loss': 0.6090929255485534, 'iwl_outdistribution_loss': 0.6400464253425598}\n",
      "loss tensor(0.6216, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.5979120250066121, 'epoch': 16, 'icl_indistribution_loss': 0.8526217274665833, 'icl_outdistribution_loss': 0.870583598613739, 'iwl_indistribution_loss': 0.5940976843833924, 'iwl_outdistribution_loss': 0.6194521594047546}\n",
      "loss tensor(0.6162, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.5862049221674601, 'epoch': 17, 'icl_indistribution_loss': 0.89264324426651, 'icl_outdistribution_loss': 0.9070388503074646, 'iwl_indistribution_loss': 0.6528135557174682, 'iwl_outdistribution_loss': 0.6788130040168763}\n",
      "loss tensor(0.5239, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.571146295483907, 'epoch': 18, 'icl_indistribution_loss': 0.8283529925346375, 'icl_outdistribution_loss': 0.8546281766891479, 'iwl_indistribution_loss': 0.583130588054657, 'iwl_outdistribution_loss': 0.5932134809494019}\n",
      "loss tensor(0.5452, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.5597991819063822, 'epoch': 19, 'icl_indistribution_loss': 0.8960866055488587, 'icl_outdistribution_loss': 0.9030300378799438, 'iwl_indistribution_loss': 0.5737896780967713, 'iwl_outdistribution_loss': 0.5859269518852234}\n",
      "loss tensor(0.5377, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.549509055519104, 'epoch': 20, 'icl_indistribution_loss': 0.8492085781097413, 'icl_outdistribution_loss': 0.8942217669486999, 'iwl_indistribution_loss': 0.5445464997291565, 'iwl_outdistribution_loss': 0.5541753873825074}\n",
      "loss tensor(0.5803, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.5390328545888265, 'epoch': 21, 'icl_indistribution_loss': 0.8544088006019592, 'icl_outdistribution_loss': 0.9170986146926879, 'iwl_indistribution_loss': 0.5486989440917969, 'iwl_outdistribution_loss': 0.5743392634391785}\n",
      "loss tensor(0.5054, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.5294167903264364, 'epoch': 22, 'icl_indistribution_loss': 0.8550631670951844, 'icl_outdistribution_loss': 0.8688618726730347, 'iwl_indistribution_loss': 0.5310774245262146, 'iwl_outdistribution_loss': 0.5558229198455811}\n",
      "loss tensor(0.5179, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.5202862778981526, 'epoch': 23, 'icl_indistribution_loss': 0.8921776471138001, 'icl_outdistribution_loss': 0.9324118556976319, 'iwl_indistribution_loss': 0.5227765703201294, 'iwl_outdistribution_loss': 0.549427429676056}\n",
      "loss tensor(0.4947, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.5108500878969828, 'epoch': 24, 'icl_indistribution_loss': 0.8455593309402466, 'icl_outdistribution_loss': 0.8875672950744629, 'iwl_indistribution_loss': 0.5027957758903503, 'iwl_outdistribution_loss': 0.5172738838195801}\n",
      "loss tensor(0.5034, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.5044655928293864, 'epoch': 25, 'icl_indistribution_loss': 0.8917446618080139, 'icl_outdistribution_loss': 0.8935797290802002, 'iwl_indistribution_loss': 0.5150059251785278, 'iwl_outdistribution_loss': 0.5255926904678345}\n",
      "loss tensor(0.4681, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.49853172171910604, 'epoch': 26, 'icl_indistribution_loss': 0.8941632204055786, 'icl_outdistribution_loss': 0.9046489572525025, 'iwl_indistribution_loss': 0.4893356964588165, 'iwl_outdistribution_loss': 0.5232297410964966}\n",
      "loss tensor(0.4752, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4938326729774475, 'epoch': 27, 'icl_indistribution_loss': 0.8819784750938415, 'icl_outdistribution_loss': 0.8884584593772888, 'iwl_indistribution_loss': 0.48581218433380124, 'iwl_outdistribution_loss': 0.5053470902442933}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(0.5328, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.48809765113194786, 'epoch': 28, 'icl_indistribution_loss': 0.9034700899124145, 'icl_outdistribution_loss': 0.9349809069633483, 'iwl_indistribution_loss': 0.5325425281524658, 'iwl_outdistribution_loss': 0.5466581292152405}\n",
      "loss tensor(0.4838, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.48301053703625996, 'epoch': 29, 'icl_indistribution_loss': 0.845403573513031, 'icl_outdistribution_loss': 0.8730980005264283, 'iwl_indistribution_loss': 0.4925995652675629, 'iwl_outdistribution_loss': 0.5096753468513489}\n",
      "loss tensor(0.4397, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4780987974802653, 'epoch': 30, 'icl_indistribution_loss': 0.8850189366340637, 'icl_outdistribution_loss': 0.9009322776794434, 'iwl_indistribution_loss': 0.49386332035064695, 'iwl_outdistribution_loss': 0.5065914468765259}\n",
      "loss tensor(0.4616, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4742248488903046, 'epoch': 31, 'icl_indistribution_loss': 0.883356626033783, 'icl_outdistribution_loss': 0.8971921372413635, 'iwl_indistribution_loss': 0.4688175530433655, 'iwl_outdistribution_loss': 0.4932630352973938}\n",
      "loss tensor(0.5044, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.46979132067362467, 'epoch': 32, 'icl_indistribution_loss': 0.8754536371231079, 'icl_outdistribution_loss': 0.9322467145919799, 'iwl_indistribution_loss': 0.4617271900177002, 'iwl_outdistribution_loss': 0.49212007713317873}\n",
      "loss tensor(0.4535, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4665555282274882, 'epoch': 33, 'icl_indistribution_loss': 0.9019989137649536, 'icl_outdistribution_loss': 0.8999789299964904, 'iwl_indistribution_loss': 0.49973308825492857, 'iwl_outdistribution_loss': 0.5238489027023315}\n",
      "loss tensor(0.4557, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.46357989160219826, 'epoch': 34, 'icl_indistribution_loss': 0.899497654914856, 'icl_outdistribution_loss': 0.9161970567703247, 'iwl_indistribution_loss': 0.47686971139907836, 'iwl_outdistribution_loss': 0.49523590350151064}\n",
      "loss tensor(0.4371, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4517348120530446, 'epoch': 35, 'icl_indistribution_loss': 0.8859574151039123, 'icl_outdistribution_loss': 0.9307261238098145, 'iwl_indistribution_loss': 0.4616482105255127, 'iwl_outdistribution_loss': 0.4839864947795868}\n",
      "loss tensor(0.4325, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.44306989844640093, 'epoch': 36, 'icl_indistribution_loss': 0.8709395937919616, 'icl_outdistribution_loss': 0.9160401120185852, 'iwl_indistribution_loss': 0.44096034836769105, 'iwl_outdistribution_loss': 0.4599072275161743}\n",
      "loss tensor(0.4090, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.43787672166824343, 'epoch': 37, 'icl_indistribution_loss': 0.9017648515701294, 'icl_outdistribution_loss': 0.8924591794013977, 'iwl_indistribution_loss': 0.43051981234550474, 'iwl_outdistribution_loss': 0.4522318184375763}\n",
      "loss tensor(0.4509, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4325595927238464, 'epoch': 38, 'icl_indistribution_loss': 0.8740349593162536, 'icl_outdistribution_loss': 0.8761799130439758, 'iwl_indistribution_loss': 0.4353517544269562, 'iwl_outdistribution_loss': 0.45010825181007386}\n",
      "loss tensor(0.4233, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4279076603571574, 'epoch': 39, 'icl_indistribution_loss': 0.8662719860076904, 'icl_outdistribution_loss': 0.9049300670623779, 'iwl_indistribution_loss': 0.4319370551109314, 'iwl_outdistribution_loss': 0.459823028087616}\n",
      "loss tensor(0.4087, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4267424386978149, 'epoch': 40, 'icl_indistribution_loss': 0.8873403654098511, 'icl_outdistribution_loss': 0.888937882900238, 'iwl_indistribution_loss': 0.42566723871231077, 'iwl_outdistribution_loss': 0.44666770362854}\n",
      "loss tensor(0.4433, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.42207288780212404, 'epoch': 41, 'icl_indistribution_loss': 0.8971675209999085, 'icl_outdistribution_loss': 0.9273104839324952, 'iwl_indistribution_loss': 0.41722545337677003, 'iwl_outdistribution_loss': 0.43327622056007387}\n",
      "loss tensor(0.4033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.42390137456258137, 'epoch': 42, 'icl_indistribution_loss': 0.9328789758682251, 'icl_outdistribution_loss': 0.9254019937515259, 'iwl_indistribution_loss': 0.44575015902519227, 'iwl_outdistribution_loss': 0.46341686964035034}\n",
      "loss tensor(0.4095, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.419787149810791, 'epoch': 43, 'icl_indistribution_loss': 0.8897529382705689, 'icl_outdistribution_loss': 0.9142604150772095, 'iwl_indistribution_loss': 0.42145036077499387, 'iwl_outdistribution_loss': 0.4463589072227478}\n",
      "loss tensor(0.4271, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4170294238090515, 'epoch': 44, 'icl_indistribution_loss': 0.9025973997116089, 'icl_outdistribution_loss': 0.9363495759963989, 'iwl_indistribution_loss': 0.41567362141609193, 'iwl_outdistribution_loss': 0.42712974214553834}\n",
      "loss tensor(0.4100, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.41602896941502887, 'epoch': 45, 'icl_indistribution_loss': 0.8550912761688232, 'icl_outdistribution_loss': 0.9137825183868408, 'iwl_indistribution_loss': 0.4183292360305786, 'iwl_outdistribution_loss': 0.43332333636283876}\n",
      "loss tensor(0.3992, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.41248629150390625, 'epoch': 46, 'icl_indistribution_loss': 0.886096197605133, 'icl_outdistribution_loss': 0.9008645195960998, 'iwl_indistribution_loss': 0.40659443855285643, 'iwl_outdistribution_loss': 0.4316867468357086}\n",
      "loss tensor(0.4276, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4119373806317647, 'epoch': 47, 'icl_indistribution_loss': 0.8987892994880676, 'icl_outdistribution_loss': 0.9104074330329895, 'iwl_indistribution_loss': 0.41021070528030396, 'iwl_outdistribution_loss': 0.435123562335968}\n",
      "loss tensor(0.4319, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.41088220202128095, 'epoch': 48, 'icl_indistribution_loss': 0.9063315324783325, 'icl_outdistribution_loss': 0.9012644691467285, 'iwl_indistribution_loss': 0.4068052270412445, 'iwl_outdistribution_loss': 0.43517646145820615}\n",
      "loss tensor(0.4088, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.40947205449740093, 'epoch': 49, 'icl_indistribution_loss': 0.887286596775055, 'icl_outdistribution_loss': 0.9343154339790344, 'iwl_indistribution_loss': 0.4112603671550751, 'iwl_outdistribution_loss': 0.4325282862186432}\n",
      "loss tensor(0.4134, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4082547475973765, 'epoch': 50, 'icl_indistribution_loss': 0.8875047492980958, 'icl_outdistribution_loss': 0.9045470385551453, 'iwl_indistribution_loss': 0.4019326465129852, 'iwl_outdistribution_loss': 0.42516635298728944}\n",
      "loss tensor(0.3980, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4071596742630005, 'epoch': 51, 'icl_indistribution_loss': 0.8718735065460205, 'icl_outdistribution_loss': 0.9158755173683166, 'iwl_indistribution_loss': 0.4122282576560974, 'iwl_outdistribution_loss': 0.43254701685905456}\n",
      "loss tensor(0.4143, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.40560855805079143, 'epoch': 52, 'icl_indistribution_loss': 0.9322603945732116, 'icl_outdistribution_loss': 0.9178587245941162, 'iwl_indistribution_loss': 0.40260185074806215, 'iwl_outdistribution_loss': 0.41605372858047485}\n",
      "loss tensor(0.4056, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4045066745122274, 'epoch': 53, 'icl_indistribution_loss': 0.8514368629455566, 'icl_outdistribution_loss': 0.884122646331787, 'iwl_indistribution_loss': 0.4007513418197632, 'iwl_outdistribution_loss': 0.41618084216117857}\n",
      "loss tensor(0.3797, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4040122812271118, 'epoch': 54, 'icl_indistribution_loss': 0.9071478910446167, 'icl_outdistribution_loss': 0.9156136894226075, 'iwl_indistribution_loss': 0.40693145895004273, 'iwl_outdistribution_loss': 0.4187498288154602}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(0.4153, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4025430416901906, 'epoch': 55, 'icl_indistribution_loss': 0.8946547656059265, 'icl_outdistribution_loss': 0.9100913825035095, 'iwl_indistribution_loss': 0.40138553142547606, 'iwl_outdistribution_loss': 0.4201035923957825}\n",
      "loss tensor(0.4144, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4008309841791789, 'epoch': 56, 'icl_indistribution_loss': 0.8822420110702515, 'icl_outdistribution_loss': 0.9042879462242126, 'iwl_indistribution_loss': 0.4086839456558228, 'iwl_outdistribution_loss': 0.4261040678024292}\n",
      "loss tensor(0.4140, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4004134126186371, 'epoch': 57, 'icl_indistribution_loss': 0.9174967432022094, 'icl_outdistribution_loss': 0.9236121401786804, 'iwl_indistribution_loss': 0.4087437469959259, 'iwl_outdistribution_loss': 0.42503209328651426}\n",
      "loss tensor(0.3960, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.4006136758804321, 'epoch': 58, 'icl_indistribution_loss': 0.9092087950706482, 'icl_outdistribution_loss': 0.9141683058738709, 'iwl_indistribution_loss': 0.40308401322364806, 'iwl_outdistribution_loss': 0.41813692593574525}\n",
      "loss tensor(0.4231, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3998515732606252, 'epoch': 59, 'icl_indistribution_loss': 0.8776785621643066, 'icl_outdistribution_loss': 0.8920525479316711, 'iwl_indistribution_loss': 0.39590883898735046, 'iwl_outdistribution_loss': 0.4181801445484161}\n",
      "loss tensor(0.4087, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3993030167897542, 'epoch': 60, 'icl_indistribution_loss': 0.884775086402893, 'icl_outdistribution_loss': 0.9108368978500366, 'iwl_indistribution_loss': 0.40155337285995485, 'iwl_outdistribution_loss': 0.4228126041889191}\n",
      "loss tensor(0.3838, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3974921068191528, 'epoch': 61, 'icl_indistribution_loss': 0.8776725010871888, 'icl_outdistribution_loss': 0.9280418219566345, 'iwl_indistribution_loss': 0.4040942668914795, 'iwl_outdistribution_loss': 0.426801278591156}\n",
      "loss tensor(0.3905, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3964649014472961, 'epoch': 62, 'icl_indistribution_loss': 0.888074321269989, 'icl_outdistribution_loss': 0.9155724120140075, 'iwl_indistribution_loss': 0.3974434101581574, 'iwl_outdistribution_loss': 0.41577345967292784}\n",
      "loss tensor(0.3756, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3957279005686442, 'epoch': 63, 'icl_indistribution_loss': 0.9035772380828857, 'icl_outdistribution_loss': 0.8804091053009033, 'iwl_indistribution_loss': 0.3928840696811676, 'iwl_outdistribution_loss': 0.4151440682411194}\n",
      "loss tensor(0.3976, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.39601983485221864, 'epoch': 64, 'icl_indistribution_loss': 0.9061177477836609, 'icl_outdistribution_loss': 0.9086756768226624, 'iwl_indistribution_loss': 0.39736479640007016, 'iwl_outdistribution_loss': 0.41405809116363523}\n",
      "loss tensor(0.3667, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3941283619880676, 'epoch': 65, 'icl_indistribution_loss': 0.9070055804252625, 'icl_outdistribution_loss': 0.9177710771560669, 'iwl_indistribution_loss': 0.40779332756996156, 'iwl_outdistribution_loss': 0.42596031665802003}\n",
      "loss tensor(0.4055, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.39274811288515726, 'epoch': 66, 'icl_indistribution_loss': 0.8818164796829223, 'icl_outdistribution_loss': 0.8988805437088012, 'iwl_indistribution_loss': 0.4031012234687805, 'iwl_outdistribution_loss': 0.4167476947307587}\n",
      "loss tensor(0.3717, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3892575899283091, 'epoch': 67, 'icl_indistribution_loss': 0.8961709232330323, 'icl_outdistribution_loss': 0.912265209197998, 'iwl_indistribution_loss': 0.3907049996852875, 'iwl_outdistribution_loss': 0.3995946826934814}\n",
      "loss tensor(0.3883, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3845751265525818, 'epoch': 68, 'icl_indistribution_loss': 0.8692645115852355, 'icl_outdistribution_loss': 0.8802849431037902, 'iwl_indistribution_loss': 0.379603435754776, 'iwl_outdistribution_loss': 0.39660277247428893}\n",
      "loss tensor(0.3750, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3815997436841329, 'epoch': 69, 'icl_indistribution_loss': 0.888161319732666, 'icl_outdistribution_loss': 0.8934588379859925, 'iwl_indistribution_loss': 0.38957247376441956, 'iwl_outdistribution_loss': 0.40453036165237427}\n",
      "loss tensor(0.4048, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3792008220831553, 'epoch': 70, 'icl_indistribution_loss': 0.8648501954078675, 'icl_outdistribution_loss': 0.9072794880867004, 'iwl_indistribution_loss': 0.37302803158760073, 'iwl_outdistribution_loss': 0.39829065823554993}\n",
      "loss tensor(0.3707, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.37535988337198894, 'epoch': 71, 'icl_indistribution_loss': 0.8514131894111633, 'icl_outdistribution_loss': 0.881465169429779, 'iwl_indistribution_loss': 0.38521397948265074, 'iwl_outdistribution_loss': 0.40700013184547423}\n",
      "loss tensor(0.3433, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.37526588230133057, 'epoch': 72, 'icl_indistribution_loss': 0.8612380857467652, 'icl_outdistribution_loss': 0.8883500261306763, 'iwl_indistribution_loss': 0.3679630279541016, 'iwl_outdistribution_loss': 0.3870988199710846}\n",
      "loss tensor(0.3484, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3738384458065033, 'epoch': 73, 'icl_indistribution_loss': 0.8788771376609802, 'icl_outdistribution_loss': 0.87093483543396, 'iwl_indistribution_loss': 0.3731009051799774, 'iwl_outdistribution_loss': 0.38679954218864443}\n",
      "loss tensor(0.3523, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.37206934040387474, 'epoch': 74, 'icl_indistribution_loss': 0.8650865845680237, 'icl_outdistribution_loss': 0.8964965229034424, 'iwl_indistribution_loss': 0.37994167852401733, 'iwl_outdistribution_loss': 0.4060572838783264}\n",
      "loss tensor(0.3654, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.37008939146995545, 'epoch': 75, 'icl_indistribution_loss': 0.8906368117332458, 'icl_outdistribution_loss': 0.9125104584693908, 'iwl_indistribution_loss': 0.3688389256000519, 'iwl_outdistribution_loss': 0.39761613082885744}\n",
      "loss tensor(0.4203, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3692810858090719, 'epoch': 76, 'icl_indistribution_loss': 0.8586977343559266, 'icl_outdistribution_loss': 0.8624376964569092, 'iwl_indistribution_loss': 0.364911922454834, 'iwl_outdistribution_loss': 0.3916954324245453}\n",
      "loss tensor(0.3670, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.36759426794052125, 'epoch': 77, 'icl_indistribution_loss': 0.8882525210380554, 'icl_outdistribution_loss': 0.8961853775978088, 'iwl_indistribution_loss': 0.374674551486969, 'iwl_outdistribution_loss': 0.39630469131469725}\n",
      "loss tensor(0.3543, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.36689162060419717, 'epoch': 78, 'icl_indistribution_loss': 0.8946952724456787, 'icl_outdistribution_loss': 0.9303617372512817, 'iwl_indistribution_loss': 0.38029322075843813, 'iwl_outdistribution_loss': 0.3888606824874878}\n",
      "loss tensor(0.3519, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.36581033789316814, 'epoch': 79, 'icl_indistribution_loss': 0.8618398623466492, 'icl_outdistribution_loss': 0.8860542001724243, 'iwl_indistribution_loss': 0.37211122155189513, 'iwl_outdistribution_loss': 0.39478313708305357}\n",
      "loss tensor(0.3775, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3646543521563212, 'epoch': 80, 'icl_indistribution_loss': 0.8848570942878723, 'icl_outdistribution_loss': 0.8952543773651123, 'iwl_indistribution_loss': 0.37028278231620787, 'iwl_outdistribution_loss': 0.3930381212234497}\n",
      "loss tensor(0.3781, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3645292304674784, 'epoch': 81, 'icl_indistribution_loss': 0.8667955212593078, 'icl_outdistribution_loss': 0.8860919165611267, 'iwl_indistribution_loss': 0.36311291003227236, 'iwl_outdistribution_loss': 0.3765360116958618}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(0.3737, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.36395984466870623, 'epoch': 82, 'icl_indistribution_loss': 0.8725483131408691, 'icl_outdistribution_loss': 0.8980012989044189, 'iwl_indistribution_loss': 0.36500910425186156, 'iwl_outdistribution_loss': 0.3847146270275116}\n",
      "loss tensor(0.3719, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.36356106437047325, 'epoch': 83, 'icl_indistribution_loss': 0.8819392113685608, 'icl_outdistribution_loss': 0.9165067319869995, 'iwl_indistribution_loss': 0.3621859290599823, 'iwl_outdistribution_loss': 0.39158475303649903}\n",
      "loss tensor(0.3680, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.36385566517512, 'epoch': 84, 'icl_indistribution_loss': 0.8752757344245911, 'icl_outdistribution_loss': 0.9116448774337769, 'iwl_indistribution_loss': 0.35648180890083314, 'iwl_outdistribution_loss': 0.3755884873867035}\n",
      "loss tensor(0.3554, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.36269873943328856, 'epoch': 85, 'icl_indistribution_loss': 0.8946717796325684, 'icl_outdistribution_loss': 0.8756468000411988, 'iwl_indistribution_loss': 0.35694341111183164, 'iwl_outdistribution_loss': 0.3797533881664276}\n",
      "loss tensor(0.3689, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.36202848631540935, 'epoch': 86, 'icl_indistribution_loss': 0.876816222190857, 'icl_outdistribution_loss': 0.9001541752815246, 'iwl_indistribution_loss': 0.362348185300827, 'iwl_outdistribution_loss': 0.38298598217964175}\n",
      "loss tensor(0.3368, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3627481688340505, 'epoch': 87, 'icl_indistribution_loss': 0.8507961506843567, 'icl_outdistribution_loss': 0.8874710397720337, 'iwl_indistribution_loss': 0.3704887094497681, 'iwl_outdistribution_loss': 0.3864412925243378}\n",
      "loss tensor(0.3521, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3613483485857646, 'epoch': 88, 'icl_indistribution_loss': 0.840713411808014, 'icl_outdistribution_loss': 0.904703754901886, 'iwl_indistribution_loss': 0.3584129993915558, 'iwl_outdistribution_loss': 0.376135892868042}\n",
      "loss tensor(0.3570, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3614671484788259, 'epoch': 89, 'icl_indistribution_loss': 0.8932392964363098, 'icl_outdistribution_loss': 0.8920911641120911, 'iwl_indistribution_loss': 0.36420216608047484, 'iwl_outdistribution_loss': 0.37601502394676206}\n",
      "loss tensor(0.3807, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3597203371842702, 'epoch': 90, 'icl_indistribution_loss': 0.8820786452293397, 'icl_outdistribution_loss': 0.8679620327949524, 'iwl_indistribution_loss': 0.35864560103416443, 'iwl_outdistribution_loss': 0.38058056926727296}\n",
      "loss tensor(0.3502, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3599823272864024, 'epoch': 91, 'icl_indistribution_loss': 0.8872090239524841, 'icl_outdistribution_loss': 0.8971757063865662, 'iwl_indistribution_loss': 0.35172415447235106, 'iwl_outdistribution_loss': 0.3795550889968872}\n",
      "loss tensor(0.3762, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35975977748235066, 'epoch': 92, 'icl_indistribution_loss': 0.8854940071105957, 'icl_outdistribution_loss': 0.8903275346755981, 'iwl_indistribution_loss': 0.36072689270973207, 'iwl_outdistribution_loss': 0.37896812438964844}\n",
      "loss tensor(0.3743, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3587125387986501, 'epoch': 93, 'icl_indistribution_loss': 0.8713897681236267, 'icl_outdistribution_loss': 0.875768807888031, 'iwl_indistribution_loss': 0.36165618419647216, 'iwl_outdistribution_loss': 0.38024641847610474}\n",
      "loss tensor(0.3761, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35782104632059736, 'epoch': 94, 'icl_indistribution_loss': 0.8823817157745362, 'icl_outdistribution_loss': 0.8767783417701721, 'iwl_indistribution_loss': 0.36531507658958434, 'iwl_outdistribution_loss': 0.3825261163711548}\n",
      "loss tensor(0.3354, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35730703897476196, 'epoch': 95, 'icl_indistribution_loss': 0.8803899998664856, 'icl_outdistribution_loss': 0.9341748552322388, 'iwl_indistribution_loss': 0.3550008306503296, 'iwl_outdistribution_loss': 0.3840095863342285}\n",
      "loss tensor(0.3592, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3573409767945607, 'epoch': 96, 'icl_indistribution_loss': 0.8714654927253723, 'icl_outdistribution_loss': 0.8916057367324829, 'iwl_indistribution_loss': 0.3611571171283722, 'iwl_outdistribution_loss': 0.3756839349269867}\n",
      "loss tensor(0.3693, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3578738156795502, 'epoch': 97, 'icl_indistribution_loss': 0.9120300774574279, 'icl_outdistribution_loss': 0.8778668689727783, 'iwl_indistribution_loss': 0.3529093716144562, 'iwl_outdistribution_loss': 0.38837307476997374}\n",
      "loss tensor(0.3446, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35709116191864015, 'epoch': 98, 'icl_indistribution_loss': 0.9046174654960633, 'icl_outdistribution_loss': 0.9105451231002808, 'iwl_indistribution_loss': 0.36062176036834714, 'iwl_outdistribution_loss': 0.38560862946510316}\n",
      "loss tensor(0.3540, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35528170879681903, 'epoch': 99, 'icl_indistribution_loss': 0.8671974511146545, 'icl_outdistribution_loss': 0.8874446907043457, 'iwl_indistribution_loss': 0.34683895897865297, 'iwl_outdistribution_loss': 0.37327996706962585}\n",
      "loss tensor(0.3655, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35490720739364623, 'epoch': 100, 'icl_indistribution_loss': 0.886607253074646, 'icl_outdistribution_loss': 0.8924447603225708, 'iwl_indistribution_loss': 0.36333466744422915, 'iwl_outdistribution_loss': 0.3783648657798767}\n",
      "loss tensor(0.3529, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.355549942668279, 'epoch': 101, 'icl_indistribution_loss': 0.8797310061454773, 'icl_outdistribution_loss': 0.9052333784103394, 'iwl_indistribution_loss': 0.3452945394515991, 'iwl_outdistribution_loss': 0.37424132776260377}\n",
      "loss tensor(0.3439, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35562677810986837, 'epoch': 102, 'icl_indistribution_loss': 0.900861056804657, 'icl_outdistribution_loss': 0.8806338691711426, 'iwl_indistribution_loss': 0.35502698230743407, 'iwl_outdistribution_loss': 0.3757987127304077}\n",
      "loss tensor(0.3641, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3549846017519633, 'epoch': 103, 'icl_indistribution_loss': 0.8813512597084046, 'icl_outdistribution_loss': 0.8880950636863708, 'iwl_indistribution_loss': 0.35186679649353025, 'iwl_outdistribution_loss': 0.37208271884918215}\n",
      "loss tensor(0.3615, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35311009426116946, 'epoch': 104, 'icl_indistribution_loss': 0.875407856464386, 'icl_outdistribution_loss': 0.9199603519439697, 'iwl_indistribution_loss': 0.35897629022598265, 'iwl_outdistribution_loss': 0.3852939848899841}\n",
      "loss tensor(0.3318, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35392225597699484, 'epoch': 105, 'icl_indistribution_loss': 0.8722724709510803, 'icl_outdistribution_loss': 0.9032649221420288, 'iwl_indistribution_loss': 0.35619173645973207, 'iwl_outdistribution_loss': 0.3769110991954803}\n",
      "loss tensor(0.3691, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35314952190717064, 'epoch': 106, 'icl_indistribution_loss': 0.8652317137718201, 'icl_outdistribution_loss': 0.8891080355644226, 'iwl_indistribution_loss': 0.3516673979759216, 'iwl_outdistribution_loss': 0.3734365215301514}\n",
      "loss tensor(0.3492, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3523929218610128, 'epoch': 107, 'icl_indistribution_loss': 0.9036301169395446, 'icl_outdistribution_loss': 0.9160108013153077, 'iwl_indistribution_loss': 0.35408868837356566, 'iwl_outdistribution_loss': 0.37030461740493775}\n",
      "loss tensor(0.3463, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35383177655537923, 'epoch': 108, 'icl_indistribution_loss': 0.8718083138465882, 'icl_outdistribution_loss': 0.9001502199172974, 'iwl_indistribution_loss': 0.35108793473243716, 'iwl_outdistribution_loss': 0.37736790108680723}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(0.3687, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3532969978650411, 'epoch': 109, 'icl_indistribution_loss': 0.8530936069488525, 'icl_outdistribution_loss': 0.8786989693641662, 'iwl_indistribution_loss': 0.3555927267074585, 'iwl_outdistribution_loss': 0.378535751581192}\n",
      "loss tensor(0.3545, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35392953033447266, 'epoch': 110, 'icl_indistribution_loss': 0.8725702114105225, 'icl_outdistribution_loss': 0.8819053835868835, 'iwl_indistribution_loss': 0.35624313402175906, 'iwl_outdistribution_loss': 0.3766545424461365}\n",
      "loss tensor(0.3510, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3523118282318115, 'epoch': 111, 'icl_indistribution_loss': 0.8728259744644165, 'icl_outdistribution_loss': 0.9154380269050598, 'iwl_indistribution_loss': 0.35774056053161624, 'iwl_outdistribution_loss': 0.36675177597999575}\n",
      "loss tensor(0.3471, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35240943682988485, 'epoch': 112, 'icl_indistribution_loss': 0.839285500049591, 'icl_outdistribution_loss': 0.8858395466804504, 'iwl_indistribution_loss': 0.3558769054412842, 'iwl_outdistribution_loss': 0.3730970087051392}\n",
      "loss tensor(0.3483, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3525639614105225, 'epoch': 113, 'icl_indistribution_loss': 0.8783703866004944, 'icl_outdistribution_loss': 0.9105685358047485, 'iwl_indistribution_loss': 0.359119143486023, 'iwl_outdistribution_loss': 0.3660146644115448}\n",
      "loss tensor(0.3655, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35249162762959796, 'epoch': 114, 'icl_indistribution_loss': 0.8799435906410217, 'icl_outdistribution_loss': 0.9116216855049133, 'iwl_indistribution_loss': 0.35335181665420534, 'iwl_outdistribution_loss': 0.3648571512699127}\n",
      "loss tensor(0.3582, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3519132743835449, 'epoch': 115, 'icl_indistribution_loss': 0.8686753721237183, 'icl_outdistribution_loss': 0.8963297362327576, 'iwl_indistribution_loss': 0.3493568968772888, 'iwl_outdistribution_loss': 0.37260521483421327}\n",
      "loss tensor(0.3346, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35114706865946455, 'epoch': 116, 'icl_indistribution_loss': 0.8802591905593872, 'icl_outdistribution_loss': 0.8985512962341309, 'iwl_indistribution_loss': 0.35002259826660154, 'iwl_outdistribution_loss': 0.3676629285812378}\n",
      "loss tensor(0.3572, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.351066705083847, 'epoch': 117, 'icl_indistribution_loss': 0.8807316784858703, 'icl_outdistribution_loss': 0.9161082472801209, 'iwl_indistribution_loss': 0.35895988941192625, 'iwl_outdistribution_loss': 0.3748332848548889}\n",
      "loss tensor(0.3496, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3520026924451192, 'epoch': 118, 'icl_indistribution_loss': 0.8739703111648559, 'icl_outdistribution_loss': 0.8976464810371398, 'iwl_indistribution_loss': 0.35968002963066104, 'iwl_outdistribution_loss': 0.37487437891960146}\n",
      "loss tensor(0.3338, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35211411425272626, 'epoch': 119, 'icl_indistribution_loss': 0.8711008973121643, 'icl_outdistribution_loss': 0.9054047031402588, 'iwl_indistribution_loss': 0.353135817527771, 'iwl_outdistribution_loss': 0.37618797063827514}\n",
      "loss tensor(0.3539, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35189714562098184, 'epoch': 120, 'icl_indistribution_loss': 0.8703437843322754, 'icl_outdistribution_loss': 0.8758066239356994, 'iwl_indistribution_loss': 0.3488860647678375, 'iwl_outdistribution_loss': 0.3786220908164978}\n",
      "loss tensor(0.3596, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3506830080986023, 'epoch': 121, 'icl_indistribution_loss': 0.8618296294212341, 'icl_outdistribution_loss': 0.8917195167541504, 'iwl_indistribution_loss': 0.34994419288635253, 'iwl_outdistribution_loss': 0.38093797373771665}\n",
      "loss tensor(0.3338, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34893082644144696, 'epoch': 122, 'icl_indistribution_loss': 0.8847057690620422, 'icl_outdistribution_loss': 0.9050852718353272, 'iwl_indistribution_loss': 0.3468654065132141, 'iwl_outdistribution_loss': 0.3721611113548279}\n",
      "loss tensor(0.3479, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34965410318374635, 'epoch': 123, 'icl_indistribution_loss': 0.8675548572540284, 'icl_outdistribution_loss': 0.8937065062522889, 'iwl_indistribution_loss': 0.34949921584129334, 'iwl_outdistribution_loss': 0.371368780374527}\n",
      "loss tensor(0.3665, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3509600170771281, 'epoch': 124, 'icl_indistribution_loss': 0.8563757605552673, 'icl_outdistribution_loss': 0.8829903702735901, 'iwl_indistribution_loss': 0.3524301338195801, 'iwl_outdistribution_loss': 0.3754523437023163}\n",
      "loss tensor(0.3456, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35042203981081643, 'epoch': 125, 'icl_indistribution_loss': 0.8780982217788696, 'icl_outdistribution_loss': 0.8947340273857116, 'iwl_indistribution_loss': 0.3507243745326996, 'iwl_outdistribution_loss': 0.37271232080459593}\n",
      "loss tensor(0.3696, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35056353619893393, 'epoch': 126, 'icl_indistribution_loss': 0.8978500113487243, 'icl_outdistribution_loss': 0.9002968654632568, 'iwl_indistribution_loss': 0.3504246244430542, 'iwl_outdistribution_loss': 0.3760000042915344}\n",
      "loss tensor(0.3762, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3500950065930684, 'epoch': 127, 'icl_indistribution_loss': 0.8764801597595215, 'icl_outdistribution_loss': 0.8943806324005127, 'iwl_indistribution_loss': 0.34759856843948367, 'iwl_outdistribution_loss': 0.36950344157218934}\n",
      "loss tensor(0.3373, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.349417165072759, 'epoch': 128, 'icl_indistribution_loss': 0.8556949043273926, 'icl_outdistribution_loss': 0.9076668992042541, 'iwl_indistribution_loss': 0.35741153717041013, 'iwl_outdistribution_loss': 0.3690816946029663}\n",
      "loss tensor(0.3684, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35040323214530944, 'epoch': 129, 'icl_indistribution_loss': 0.8997309122085572, 'icl_outdistribution_loss': 0.8727720375061035, 'iwl_indistribution_loss': 0.34894533777236936, 'iwl_outdistribution_loss': 0.36933061814308166}\n",
      "loss tensor(0.3496, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35024877567291257, 'epoch': 130, 'icl_indistribution_loss': 0.9005342593193054, 'icl_outdistribution_loss': 0.8972042393684387, 'iwl_indistribution_loss': 0.3567019975185394, 'iwl_outdistribution_loss': 0.3663269157409668}\n",
      "loss tensor(0.3555, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.35016077423095704, 'epoch': 131, 'icl_indistribution_loss': 0.8962549920082092, 'icl_outdistribution_loss': 0.9076026310920715, 'iwl_indistribution_loss': 0.3530442342758179, 'iwl_outdistribution_loss': 0.3651876373291016}\n",
      "loss tensor(0.3339, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.349034015750885, 'epoch': 132, 'icl_indistribution_loss': 0.8681430869102478, 'icl_outdistribution_loss': 0.922421929359436, 'iwl_indistribution_loss': 0.34648639559745786, 'iwl_outdistribution_loss': 0.37659277629852295}\n",
      "loss tensor(0.3516, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34919980624516805, 'epoch': 133, 'icl_indistribution_loss': 0.8723989109992981, 'icl_outdistribution_loss': 0.9142031211853028, 'iwl_indistribution_loss': 0.35078977060317995, 'iwl_outdistribution_loss': 0.37012796211242677}\n",
      "loss tensor(0.3326, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3490456095059713, 'epoch': 134, 'icl_indistribution_loss': 0.8824407911300659, 'icl_outdistribution_loss': 0.905583514213562, 'iwl_indistribution_loss': 0.3523264811038971, 'iwl_outdistribution_loss': 0.36611273646354675}\n",
      "loss tensor(0.3294, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3486040438652039, 'epoch': 135, 'icl_indistribution_loss': 0.873729100227356, 'icl_outdistribution_loss': 0.8894578804969787, 'iwl_indistribution_loss': 0.3483916959762573, 'iwl_outdistribution_loss': 0.37164431071281434}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(0.3397, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34875047403971354, 'epoch': 136, 'icl_indistribution_loss': 0.8788593144416809, 'icl_outdistribution_loss': 0.9151891541481018, 'iwl_indistribution_loss': 0.3473614411354065, 'iwl_outdistribution_loss': 0.3767488601207733}\n",
      "loss tensor(0.3726, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34928162837028504, 'epoch': 137, 'icl_indistribution_loss': 0.8648478021621704, 'icl_outdistribution_loss': 0.8942816710472107, 'iwl_indistribution_loss': 0.3499638493061066, 'iwl_outdistribution_loss': 0.3788919336795807}\n",
      "loss tensor(0.3354, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3491550887584686, 'epoch': 138, 'icl_indistribution_loss': 0.8973742995262146, 'icl_outdistribution_loss': 0.8911947183609009, 'iwl_indistribution_loss': 0.3454861536026001, 'iwl_outdistribution_loss': 0.37594841098785403}\n",
      "loss tensor(0.3505, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3491538293838501, 'epoch': 139, 'icl_indistribution_loss': 0.8922868862152099, 'icl_outdistribution_loss': 0.8808040280342102, 'iwl_indistribution_loss': 0.3596286525726318, 'iwl_outdistribution_loss': 0.36295444774627683}\n",
      "loss tensor(0.3681, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3486577633221944, 'epoch': 140, 'icl_indistribution_loss': 0.8754568753242493, 'icl_outdistribution_loss': 0.8804179368019104, 'iwl_indistribution_loss': 0.3541472260951996, 'iwl_outdistribution_loss': 0.3727811725139618}\n",
      "loss tensor(0.3503, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3484297842025757, 'epoch': 141, 'icl_indistribution_loss': 0.8807479104995728, 'icl_outdistribution_loss': 0.9009816541671752, 'iwl_indistribution_loss': 0.3493556344509125, 'iwl_outdistribution_loss': 0.36904259157180785}\n",
      "loss tensor(0.3587, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34826958672205605, 'epoch': 142, 'icl_indistribution_loss': 0.8961420931816101, 'icl_outdistribution_loss': 0.9287530403137207, 'iwl_indistribution_loss': 0.3461136817932129, 'iwl_outdistribution_loss': 0.367286580324173}\n",
      "loss tensor(0.3397, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34801348638534546, 'epoch': 143, 'icl_indistribution_loss': 0.8633074145317078, 'icl_outdistribution_loss': 0.8794686555862427, 'iwl_indistribution_loss': 0.3495476925373077, 'iwl_outdistribution_loss': 0.3801939284801483}\n",
      "loss tensor(0.3593, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3492411670207977, 'epoch': 144, 'icl_indistribution_loss': 0.8717950415611267, 'icl_outdistribution_loss': 0.9025569162368774, 'iwl_indistribution_loss': 0.34470265340805056, 'iwl_outdistribution_loss': 0.37436824560165405}\n",
      "loss tensor(0.3581, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3481824326992035, 'epoch': 145, 'icl_indistribution_loss': 0.8836730699539185, 'icl_outdistribution_loss': 0.9118235673904419, 'iwl_indistribution_loss': 0.34350805139541624, 'iwl_outdistribution_loss': 0.3685619933605194}\n",
      "loss tensor(0.3465, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34850559051831564, 'epoch': 146, 'icl_indistribution_loss': 0.8918255753517151, 'icl_outdistribution_loss': 0.9053445043563842, 'iwl_indistribution_loss': 0.34887642312049866, 'iwl_outdistribution_loss': 0.3658354940414429}\n",
      "loss tensor(0.3601, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34878520352045694, 'epoch': 147, 'icl_indistribution_loss': 0.860058358669281, 'icl_outdistribution_loss': 0.875760094165802, 'iwl_indistribution_loss': 0.34372795605659484, 'iwl_outdistribution_loss': 0.3621231918334961}\n",
      "loss tensor(0.3501, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34901229378382365, 'epoch': 148, 'icl_indistribution_loss': 0.8736346635818482, 'icl_outdistribution_loss': 0.8677881193161011, 'iwl_indistribution_loss': 0.34537129282951357, 'iwl_outdistribution_loss': 0.3687699749469757}\n",
      "loss tensor(0.3467, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34786014839808144, 'epoch': 149, 'icl_indistribution_loss': 0.8634712624549866, 'icl_outdistribution_loss': 0.9003448724746704, 'iwl_indistribution_loss': 0.3497630195617676, 'iwl_outdistribution_loss': 0.3768284456729889}\n",
      "loss tensor(0.3435, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3484931641896566, 'epoch': 150, 'icl_indistribution_loss': 0.8723143467903137, 'icl_outdistribution_loss': 0.9074486255645752, 'iwl_indistribution_loss': 0.3448206939697266, 'iwl_outdistribution_loss': 0.37162958550453185}\n",
      "loss tensor(0.3492, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34790564374923705, 'epoch': 151, 'icl_indistribution_loss': 0.8890437264442443, 'icl_outdistribution_loss': 0.8969067478179932, 'iwl_indistribution_loss': 0.354428129196167, 'iwl_outdistribution_loss': 0.3698272955417633}\n",
      "loss tensor(0.3507, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34849392714500427, 'epoch': 152, 'icl_indistribution_loss': 0.8741961259841919, 'icl_outdistribution_loss': 0.8990804867744446, 'iwl_indistribution_loss': 0.34982275843620303, 'iwl_outdistribution_loss': 0.3709161684513092}\n",
      "loss tensor(0.3461, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34785357718467713, 'epoch': 153, 'icl_indistribution_loss': 0.8595243816375733, 'icl_outdistribution_loss': 0.8896498990058899, 'iwl_indistribution_loss': 0.34889771151542665, 'iwl_outdistribution_loss': 0.3640552535057068}\n",
      "loss tensor(0.3610, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34821588589350383, 'epoch': 154, 'icl_indistribution_loss': 0.8679510102272033, 'icl_outdistribution_loss': 0.8623512148857116, 'iwl_indistribution_loss': 0.3492014932632446, 'iwl_outdistribution_loss': 0.37094522547721864}\n",
      "loss tensor(0.3465, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34782632973988853, 'epoch': 155, 'icl_indistribution_loss': 0.8988232169151306, 'icl_outdistribution_loss': 0.9033821778297424, 'iwl_indistribution_loss': 0.3618708140850067, 'iwl_outdistribution_loss': 0.385314528465271}\n",
      "loss tensor(0.3345, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3472462306340535, 'epoch': 156, 'icl_indistribution_loss': 0.8663317313194275, 'icl_outdistribution_loss': 0.905131495475769, 'iwl_indistribution_loss': 0.3511750781536102, 'iwl_outdistribution_loss': 0.376665741443634}\n",
      "loss tensor(0.3490, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3467730896313985, 'epoch': 157, 'icl_indistribution_loss': 0.8644798636436463, 'icl_outdistribution_loss': 0.9007055106163024, 'iwl_indistribution_loss': 0.35342586994171143, 'iwl_outdistribution_loss': 0.3612639226913452}\n",
      "loss tensor(0.3468, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34768181721369423, 'epoch': 158, 'icl_indistribution_loss': 0.8708615441322327, 'icl_outdistribution_loss': 0.90931920337677, 'iwl_indistribution_loss': 0.3482601456642151, 'iwl_outdistribution_loss': 0.3716645369529724}\n",
      "loss tensor(0.3451, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3466496561686198, 'epoch': 159, 'icl_indistribution_loss': 0.8639867439270019, 'icl_outdistribution_loss': 0.9086162738800049, 'iwl_indistribution_loss': 0.34348204588890074, 'iwl_outdistribution_loss': 0.3750210659503937}\n",
      "loss tensor(0.3473, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3484166663169861, 'epoch': 160, 'icl_indistribution_loss': 0.8608330821990967, 'icl_outdistribution_loss': 0.8976674561500549, 'iwl_indistribution_loss': 0.35078246879577635, 'iwl_outdistribution_loss': 0.3705764133930206}\n",
      "loss tensor(0.3388, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34690556732813516, 'epoch': 161, 'icl_indistribution_loss': 0.8925880131721496, 'icl_outdistribution_loss': 0.9091828255653381, 'iwl_indistribution_loss': 0.3517012205123901, 'iwl_outdistribution_loss': 0.36570088386535643}\n",
      "loss tensor(0.3337, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3482357919216156, 'epoch': 162, 'icl_indistribution_loss': 0.8787593064308167, 'icl_outdistribution_loss': 0.9126663112640381, 'iwl_indistribution_loss': 0.35228357005119326, 'iwl_outdistribution_loss': 0.37500636839866636}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(0.3537, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34683166494369505, 'epoch': 163, 'icl_indistribution_loss': 0.909982458114624, 'icl_outdistribution_loss': 0.8790371198654174, 'iwl_indistribution_loss': 0.3494947950839996, 'iwl_outdistribution_loss': 0.3562524094581604}\n",
      "loss tensor(0.3594, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3472113432566325, 'epoch': 164, 'icl_indistribution_loss': 0.8806422600746154, 'icl_outdistribution_loss': 0.8878154120445252, 'iwl_indistribution_loss': 0.3470101547241211, 'iwl_outdistribution_loss': 0.3619368896484375}\n",
      "loss tensor(0.3598, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.346969175084432, 'epoch': 165, 'icl_indistribution_loss': 0.866724627494812, 'icl_outdistribution_loss': 0.8919836521148682, 'iwl_indistribution_loss': 0.34598433566093445, 'iwl_outdistribution_loss': 0.37446723246574404}\n",
      "loss tensor(0.3592, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34702872831026715, 'epoch': 166, 'icl_indistribution_loss': 0.8759878334999085, 'icl_outdistribution_loss': 0.8868720526695252, 'iwl_indistribution_loss': 0.3497959508895874, 'iwl_outdistribution_loss': 0.3611945922374725}\n",
      "loss tensor(0.3601, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3469959897041321, 'epoch': 167, 'icl_indistribution_loss': 0.8880223965644837, 'icl_outdistribution_loss': 0.8848974165916443, 'iwl_indistribution_loss': 0.35599749493598937, 'iwl_outdistribution_loss': 0.3674276909828186}\n",
      "loss tensor(0.3475, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3474807305812836, 'epoch': 168, 'icl_indistribution_loss': 0.8748492918014527, 'icl_outdistribution_loss': 0.8821480231285095, 'iwl_indistribution_loss': 0.3395965349674225, 'iwl_outdistribution_loss': 0.3654087145328522}\n",
      "loss tensor(0.3539, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3473025968074799, 'epoch': 169, 'icl_indistribution_loss': 0.8949999341964722, 'icl_outdistribution_loss': 0.9124925479888916, 'iwl_indistribution_loss': 0.35180021047592164, 'iwl_outdistribution_loss': 0.37059287762641907}\n",
      "loss tensor(0.3476, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3471867643515269, 'epoch': 170, 'icl_indistribution_loss': 0.8714500608444213, 'icl_outdistribution_loss': 0.8880721983909607, 'iwl_indistribution_loss': 0.34371060991287233, 'iwl_outdistribution_loss': 0.36618197536468505}\n",
      "loss tensor(0.3580, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3464718540509542, 'epoch': 171, 'icl_indistribution_loss': 0.8790976834297181, 'icl_outdistribution_loss': 0.8968694014549256, 'iwl_indistribution_loss': 0.34843121218681333, 'iwl_outdistribution_loss': 0.3675215187072754}\n",
      "loss tensor(0.3452, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34682576263745624, 'epoch': 172, 'icl_indistribution_loss': 0.8779462132453918, 'icl_outdistribution_loss': 0.8790767102241516, 'iwl_indistribution_loss': 0.3461018354892731, 'iwl_outdistribution_loss': 0.3665351128578186}\n",
      "loss tensor(0.3453, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34566470839182534, 'epoch': 173, 'icl_indistribution_loss': 0.8736710238456726, 'icl_outdistribution_loss': 0.8954882564544677, 'iwl_indistribution_loss': 0.3494595665931702, 'iwl_outdistribution_loss': 0.3638402874469757}\n",
      "loss tensor(0.3352, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34710272900263467, 'epoch': 174, 'icl_indistribution_loss': 0.8877646946907043, 'icl_outdistribution_loss': 0.9034926776885986, 'iwl_indistribution_loss': 0.3534778771400452, 'iwl_outdistribution_loss': 0.36958476328849793}\n",
      "loss tensor(0.3477, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34658200062115985, 'epoch': 175, 'icl_indistribution_loss': 0.8426005692481995, 'icl_outdistribution_loss': 0.8802520761489868, 'iwl_indistribution_loss': 0.3441865937709808, 'iwl_outdistribution_loss': 0.36847432351112364}\n",
      "loss tensor(0.3272, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34641015497843425, 'epoch': 176, 'icl_indistribution_loss': 0.8851304750442505, 'icl_outdistribution_loss': 0.8894804267883301, 'iwl_indistribution_loss': 0.34144834780693056, 'iwl_outdistribution_loss': 0.36642515802383424}\n",
      "loss tensor(0.3329, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3459830676078796, 'epoch': 177, 'icl_indistribution_loss': 0.86663356590271, 'icl_outdistribution_loss': 0.946749773979187, 'iwl_indistribution_loss': 0.34212453579902646, 'iwl_outdistribution_loss': 0.3624662113189697}\n",
      "loss tensor(0.3550, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3473932885487874, 'epoch': 178, 'icl_indistribution_loss': 0.8602167711257934, 'icl_outdistribution_loss': 0.885127564907074, 'iwl_indistribution_loss': 0.3422685208320618, 'iwl_outdistribution_loss': 0.36522751426696776}\n",
      "loss tensor(0.3380, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3476304229100545, 'epoch': 179, 'icl_indistribution_loss': 0.8512715964317322, 'icl_outdistribution_loss': 0.8769916749000549, 'iwl_indistribution_loss': 0.34178996777534487, 'iwl_outdistribution_loss': 0.3701546275615692}\n",
      "loss tensor(0.3374, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34726341492335, 'epoch': 180, 'icl_indistribution_loss': 0.8857819557189941, 'icl_outdistribution_loss': 0.9104271411895752, 'iwl_indistribution_loss': 0.3478450753688812, 'iwl_outdistribution_loss': 0.3700652620792389}\n",
      "loss tensor(0.3403, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3463233956019084, 'epoch': 181, 'icl_indistribution_loss': 0.8743104100227356, 'icl_outdistribution_loss': 0.901749617099762, 'iwl_indistribution_loss': 0.34846744227409365, 'iwl_outdistribution_loss': 0.35840448760986326}\n",
      "loss tensor(0.3611, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34700780658721925, 'epoch': 182, 'icl_indistribution_loss': 0.8816130080223084, 'icl_outdistribution_loss': 0.8947224230766296, 'iwl_indistribution_loss': 0.3412237946987152, 'iwl_outdistribution_loss': 0.3727697882652283}\n",
      "loss tensor(0.3669, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34571274282137554, 'epoch': 183, 'icl_indistribution_loss': 0.8772606463432312, 'icl_outdistribution_loss': 0.87651957321167, 'iwl_indistribution_loss': 0.3475663824081421, 'iwl_outdistribution_loss': 0.374542596578598}\n",
      "loss tensor(0.3337, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3466704256216685, 'epoch': 184, 'icl_indistribution_loss': 0.8554325971603394, 'icl_outdistribution_loss': 0.888352023601532, 'iwl_indistribution_loss': 0.3441780500411987, 'iwl_outdistribution_loss': 0.37102699708938597}\n",
      "loss tensor(0.3421, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34710754130681354, 'epoch': 185, 'icl_indistribution_loss': 0.8724560303688049, 'icl_outdistribution_loss': 0.907024745464325, 'iwl_indistribution_loss': 0.33849238777160645, 'iwl_outdistribution_loss': 0.3636645972728729}\n",
      "loss tensor(0.3482, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3462353716850281, 'epoch': 186, 'icl_indistribution_loss': 0.890244562625885, 'icl_outdistribution_loss': 0.8899898467063904, 'iwl_indistribution_loss': 0.3481470856666565, 'iwl_outdistribution_loss': 0.36427223062515257}\n",
      "loss tensor(0.3488, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34646899960835775, 'epoch': 187, 'icl_indistribution_loss': 0.9076738786697388, 'icl_outdistribution_loss': 0.9209182391166687, 'iwl_indistribution_loss': 0.34464468264579773, 'iwl_outdistribution_loss': 0.36252133655548097}\n",
      "loss tensor(0.3599, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3461283591270447, 'epoch': 188, 'icl_indistribution_loss': 0.8838932404518127, 'icl_outdistribution_loss': 0.8964613099098205, 'iwl_indistribution_loss': 0.3455489664077759, 'iwl_outdistribution_loss': 0.3677244820594788}\n",
      "loss tensor(0.3731, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34672153571446734, 'epoch': 189, 'icl_indistribution_loss': 0.8697439403533935, 'icl_outdistribution_loss': 0.9175250706672669, 'iwl_indistribution_loss': 0.341189817905426, 'iwl_outdistribution_loss': 0.3627735803127289}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(0.3334, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.346908412138621, 'epoch': 190, 'icl_indistribution_loss': 0.86175333070755, 'icl_outdistribution_loss': 0.8948555688858032, 'iwl_indistribution_loss': 0.3438070592880249, 'iwl_outdistribution_loss': 0.36619336581230166}\n",
      "loss tensor(0.3390, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34657426880200704, 'epoch': 191, 'icl_indistribution_loss': 0.8736184859275817, 'icl_outdistribution_loss': 0.92083589220047, 'iwl_indistribution_loss': 0.35220761370658876, 'iwl_outdistribution_loss': 0.36602503299713135}\n",
      "loss tensor(0.3433, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3458853611628214, 'epoch': 192, 'icl_indistribution_loss': 0.8737509427070618, 'icl_outdistribution_loss': 0.9173771696090698, 'iwl_indistribution_loss': 0.3463476691246033, 'iwl_outdistribution_loss': 0.36295228719711303}\n",
      "loss tensor(0.3258, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34663177893956504, 'epoch': 193, 'icl_indistribution_loss': 0.893290584564209, 'icl_outdistribution_loss': 0.8858923420906067, 'iwl_indistribution_loss': 0.3524605450630188, 'iwl_outdistribution_loss': 0.3687290508747101}\n",
      "loss tensor(0.3748, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3453412900606791, 'epoch': 194, 'icl_indistribution_loss': 0.8512870688438415, 'icl_outdistribution_loss': 0.9022401165962219, 'iwl_indistribution_loss': 0.3425074796676636, 'iwl_outdistribution_loss': 0.36490441727638245}\n",
      "loss tensor(0.3621, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3464056092739105, 'epoch': 195, 'icl_indistribution_loss': 0.8871853694915771, 'icl_outdistribution_loss': 0.878771348953247, 'iwl_indistribution_loss': 0.34862155628204344, 'iwl_outdistribution_loss': 0.3580665187835693}\n",
      "loss tensor(0.3596, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34556010489463806, 'epoch': 196, 'icl_indistribution_loss': 0.8686728572845459, 'icl_outdistribution_loss': 0.8999731016159057, 'iwl_indistribution_loss': 0.3460474421977997, 'iwl_outdistribution_loss': 0.36215554642677306}\n",
      "loss tensor(0.3576, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.3454925541559855, 'epoch': 197, 'icl_indistribution_loss': 0.8960869770050048, 'icl_outdistribution_loss': 0.9122179551124573, 'iwl_indistribution_loss': 0.34041724872589113, 'iwl_outdistribution_loss': 0.36809903335571287}\n",
      "loss tensor(0.3390, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.34479909461339314, 'epoch': 198, 'icl_indistribution_loss': 0.877158625125885, 'icl_outdistribution_loss': 0.9034585733413696, 'iwl_indistribution_loss': 0.346467621088028, 'iwl_outdistribution_loss': 0.37408523297309876}\n",
      "loss tensor(0.3443, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "{'train_loss': 0.345224556239446, 'epoch': 199, 'icl_indistribution_loss': 0.8645133104324341, 'icl_outdistribution_loss': 0.9088424973487854, 'iwl_indistribution_loss': 0.3449721817970276, 'iwl_outdistribution_loss': 0.37664059734344485}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# import matplotlib.pyplot as plt\n",
    "exp_name = f\"./cache/{args.wandb_group_name}_{args.fileprefix}_K_{args.K}_D_{args.D_sum}_L_{args.len_context}_hidden_{args.num_hidden_features}_coarse_{args.coarse_graining}_{time.time()}.pkl\"\n",
    "for epoch in range(args.epochs):\n",
    "    icl_indistribution_losses = validate_gradient_descent(epoch, icl_test_loader, model, args, criterion, device, coarse_graining=\"standard\")\n",
    "    icl_outdistribution_losses = validate_gradient_descent(epoch, icl_test_loader, model, args, criterion, device, coarse_graining=args.coarse_graining)\n",
    "    iwl_indistribution_losses = validate_gradient_descent(epoch, iwl_test_loader, model, args, criterion, device, coarse_graining=\"standard\")\n",
    "    iwl_outdistribution_losses = validate_gradient_descent(epoch, iwl_test_loader, model, args, criterion, device, coarse_graining=args.coarse_graining)\n",
    "    \n",
    "    model.train() # switch to train mode\n",
    "    losses = utils.AverageMeter('Loss', ':.4e')\n",
    "    ridge_losses = utils.AverageMeter('Ridge Loss', ':.4e')\n",
    "    top1 = utils.AverageMeter('Acc@1', ':6.2f')\n",
    "\n",
    " \n",
    "    for i, (seq, target, _) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        seq, target = seq.to(device), target.to(device)\n",
    "        # print (\"seq\", seq.shape, \"target\", target.shape)\n",
    "        output = model(seq, target) \n",
    "        # print (\"seq\", seq.shape, \"target\", target.shape, \"output\", output.shape )\n",
    "        preds = output[:, 0::2, :] # shape: (B, L, 1)\n",
    "        loss = criterion(preds, target)\n",
    "        \n",
    "        # batch_first_seq, batch_first_target = seq[0, :-1, :], target[0, :-1, 0]\n",
    "        # print (\"batch_first_seq\", batch_first_seq.shape, \"batch_first_target\", batch_first_target.shape)\n",
    "        # ridge = utils.Ridge(alpha=1e-9,fit_intercept=True) \n",
    "        # ridge.fit(batch_first_seq, batch_first_target)\n",
    "        # val_loss = criterion(ridge.predict(seq[0, [-1], :]), target[0, -1, 0])\n",
    "        # print (\"loss\", loss, \"ridge loss\", val_loss, \"pred\", ridge.predict(seq[0, [-1], :]).shape)\n",
    "        # ridge_losses.update(val_loss.item(), 1) \n",
    "        # compute ridge loss on first sequence\n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.update(loss.item(), target.size(0)) \n",
    "        # acc1 = utils.accuracy(output, (seq_target), topk=[1])\n",
    "        # print (\"output\", output.shape, output[0], seq_target[0], loss, acc1, model.temperature)\n",
    "        # top1.update(acc1[0], target.size(0))\n",
    "        # acc1 = torch.mean(((output.squeeze(1) * (seq_target*2-1)) > 0).float()).item()\n",
    "        # top1.update(acc1, target.size(0))\n",
    "        # step scheduler\n",
    "        scheduler.step()\n",
    "    print (\"loss\" , loss, \"preds\", preds.shape, \"target\", target.shape)\n",
    "    \n",
    "\n",
    "    # save metrics\n",
    "    # print(\"output\",  torch.argsort(output, dim=-1), \"target\", target )\n",
    "    # print(\"Current average loss\", losses.avg, top1.avg, \"epoch\", epoch) \n",
    "    # seen_val_losses, seen_val_top1 = validate_gradient_descent(icl_loader, seen_projs_permutations_loader, model, args, criterion, device)\n",
    "    \n",
    "    # Compute unseen val loss\n",
    "    # unseen_val_losses, unseen_val_top1 = validate_gradient_descent(icl_loader, seen_projs_permutations_loader, model, args, criterion, device)\n",
    "    logs = {\n",
    "            \"train_loss\": losses.avg,\n",
    "            \"epoch\": epoch,\n",
    "            \"lr\": optimizer.param_groups[0]['lr'],\n",
    "            # \"icl_indistribution_loss\": icl_indistribution_losses.avg,\n",
    "            # \"icl_outdistribution_loss\": icl_outdistribution_losses.avg,\n",
    "            # \"iwl_indistribution_loss\": iwl_indistribution_losses.avg,\n",
    "            # \"iwl_outdistribution_loss\": iwl_outdistribution_losses.avg,\n",
    "        }\n",
    "    for _ in range(args.len_context):\n",
    "        logs[f\"icl_indistribution_loss_{_}\"] = icl_indistribution_losses[_].avg\n",
    "        logs[f\"icl_outdistribution_loss_{_}\"] = icl_outdistribution_losses[_].avg\n",
    "        logs[f\"iwl_indistribution_loss_{_}\"] = iwl_indistribution_losses[_].avg\n",
    "        logs[f\"iwl_outdistribution_loss_{_}\"] = iwl_outdistribution_losses[_].avg\n",
    "    \n",
    "    # print(logs) \n",
    "    if args.wandb_log:\n",
    "        wandb.log(logs)\n",
    "    else:\n",
    "        record[\"logs\"].append(logs)\n",
    "    \n",
    " \n",
    "    # save phi_xt_list_epoch \n",
    "\n",
    "    if epoch % 10 == 0 and args.wandb_log != True:\n",
    "        with open(exp_name, \"wb\") as f:\n",
    "            pickle.dump(record, f)\n",
    "  \n",
    "if args.wandb_log != True:\n",
    "    with open(exp_name, \"wb\") as f:\n",
    "        pickle.dump(record, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (l2l)",
   "language": "python",
   "name": "l2l"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
