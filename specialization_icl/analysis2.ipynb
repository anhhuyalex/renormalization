{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "from enum import Enum\n",
    "import importlib\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim.lr_scheduler import StepLR, OneCycleLR\n",
    "from torch.utils.data import Subset\n",
    "import attention\n",
    "# import webdataset as wds\n",
    "\n",
    "import datetime\n",
    "import utils\n",
    "import numpy as np\n",
    "import math\n",
    "import einops\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import wandb \n",
    "import sys \n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='GMM L2L Training with Sequence Model')\n",
    "parser.add_argument('--data', metavar='DIR', nargs='?', default='./data',\n",
    "                    help='path to dataset (default: imagenet)')\n",
    "parser.add_argument('--cache', default='./cache',\n",
    "                    help='path to cached files (e.g. for previous random weights)')\n",
    "parser.add_argument(\n",
    "    \"--wandb_log\",action=argparse.BooleanOptionalAction,default=False,\n",
    "    help=\"whether to log to wandb\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--wandb_project\",type=str,default=\"stability\",\n",
    "    help=\"wandb project name\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--wandb_group_name\",type=str,default=\"stability\",\n",
    "    help=\"wandb project name\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--resume\",type=str,default=None,\n",
    "    help=\"analyze a previous run\"\n",
    ")\n",
    "parser.add_argument('--seed', default=None, type=int,\n",
    "                    help='seed for initializing training.')\n",
    "parser.add_argument('--epochs', default=90, type=int,  \n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('-b', '--batch-size', default=64, type=int,\n",
    "                    metavar='N',\n",
    "                    help='mini-batch size (default: 256), this is the total '\n",
    "                         'batch size of all GPUs on the current node when '\n",
    "                         'using Data Parallel or Distributed Data Parallel')                         \n",
    "parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 4)')\n",
    "parser.add_argument('--optimizer', default='SGD', type=str, \n",
    "                    choices = ['SGD', 'Adam'],\n",
    "                    help='optimizer')\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.1, type=float,\n",
    "                    metavar='LR', help='initial learning rate', dest='lr')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
    "                    help='momentum')\n",
    "parser.add_argument('--wd', '--weight-decay', default=1e-5, type=float,\n",
    "                    metavar='W', help='weight decay (default: 1e-4)',\n",
    "                    dest='weight_decay')\n",
    "parser.add_argument('--arch', '-a', metavar='ARCH', default='mlp',\n",
    "                    help='model architecture (default: mlp)')\n",
    "parser.add_argument('--gpt_bias', default=\"True\", type=str,\n",
    "                    help='whether to include bias in GPT')\n",
    "parser.add_argument('--num_hidden_features', default=1, type=int,\n",
    "                    help='num_hidden_features')\n",
    "parser.add_argument('--num_layers', default=1, type=int,\n",
    "                    help='num_layers in transformer')\n",
    "parser.add_argument('--len_context', default=1, type=int,\n",
    "                    help='number of in-context images in sequence')\n",
    "parser.add_argument('--SLURM_ARRAY_TASK_ID', default=1, type=int,\n",
    "                    help='SLURM_ARRAY_TASK_ID')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                        help='disables CUDA training')  \n",
    "parser.add_argument('--D_sum', default=1000, type=int, help='number of visible+ hidden features')\n",
    "parser.add_argument('--D_visible_frac', default=1.0, type=float, help='fraction of features visible') \n",
    "parser.add_argument('--K', default=1, type=int, \n",
    "                    help='number of tasks')\n",
    "parser.add_argument('--input_covariance', default=\"False\", type=str,\n",
    "                    help='input covariance matrix')\n",
    "parser.add_argument('--coarse_graining', default=\"abstop\", type=str,\n",
    "                    help='coarse graining method')\n",
    "parser.add_argument('--sigma_xi', default=1.0, type=float, help='noise level')\n",
    "parser.add_argument('--rho_minus', default=0.5, type=float, help='rho_minus, spectral weights')\n",
    "parser.add_argument(\n",
    "            '--fileprefix', \n",
    "            default=\"\",\n",
    "            type=str, \n",
    "            action='store') \n",
    "\n",
    "\n",
    "# if running this interactively, can specify jupyter_args here for argparser to use\n",
    "if utils.is_interactive():\n",
    "    arch = \"pytorch_transformer\"\n",
    "    # arch = \"transformer\"\n",
    "    gpt_bias=\"True\"\n",
    "    lr=1e-4\n",
    "    optimizer=\"Adam\"\n",
    "    epochs=500\n",
    "    D_visible_frac=0\n",
    "    len_context=200\n",
    "    jupyter_args = f\"--data ./cache --fileprefix no_layernorm_input_opt_${optimizer}_lr_${lr}_gpt_bias_${gpt_bias}_epochs_${epochs}_visible_${D_visible_frac}  --SLURM_ARRAY_TASK_ID 0 --batch-size 256 --optimizer {optimizer} --lr {lr} --wd 0.0  --epochs {epochs} --arch gpt --gpt_bias {gpt_bias} --num_hidden_features 128 --num_layers 8 --len_context {len_context} --K 1048576 --D_sum 32 --D_visible_frac {D_visible_frac} --sigma_xi 0.5 --coarse_graining abstop --no-wandb_log --wandb_project renormalization --wandb_group_name linreg_nov13_specgen_bias_Dsum_32\"\n",
    "    \n",
    "    print(jupyter_args)\n",
    "    jupyter_args = jupyter_args.split()\n",
    "    \n",
    "    from IPython.display import clear_output # function to clear print outputs in cell\n",
    "    %load_ext autoreload \n",
    "    # this allows you to change functions in models.py or utils.py and have this notebook automatically update with your revisions\n",
    "    %autoreload 2 \n",
    "\n",
    "if utils.is_interactive():\n",
    "    args = parser.parse_args(jupyter_args)\n",
    "else:\n",
    "    args = parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp. settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.fileprefix == \"jan17_2pm\":\n",
    "    resumes = [\n",
    "            \"./cache/linreg_nov19_specgen_bias_Dsum__scheduler_None_K_1024_no_layernorm_input_opt_Adam_lr_1e-4_gpt_bias_True_epochs_500_visible_32_K_1024_D_64_L_100_hidden_128_coarse_abstop_1732079333.0764203.pkl\",\n",
    "            \"./cache/linreg_nov19_specgen_bias_Dsum__scheduler_None_K_1048576_no_layernorm_input_opt_Adam_lr_1e-4_gpt_bias_True_epochs_500_visible_32_K_1048576_D_64_L_100_hidden_128_coarse_abstop_1732079442.9435685.pkl\",\n",
    "            # \"./cache/linreg_nov19_specgen_bias_Dsum__scheduler_None_K_32768_no_layernorm_input_opt_Adam_lr_1e-4_gpt_bias_True_epochs_500_visible_32_K_32768_D_64_L_100_hidden_128_coarse_abstop_1732079299.9278684.pkl\",\n",
    "            # \"./cache/linreg_nov19_specgen_bias_Dsum__scheduler_None_K_32_no_layernorm_input_opt_Adam_lr_1e-4_gpt_bias_True_epochs_500_visible_32_K_32_D_64_L_100_hidden_128_coarse_abstop_1732079383.3274248.pkl\"\n",
    "            ]\n",
    "    args.resume = resumes[args.SLURM_ARRAY_TASK_ID % len(resumes)]\n",
    "    coarse_grainings = [ \"abstop\",\"shrink_norm\", \"aniso_highvariance_shrink_k\", \"aniso_lowvariance_shrink_k\", \"aniso_highvariance_vary_cos\", \"aniso_lowvariance_vary_cos\"] \n",
    "    args.coarse_graining = coarse_grainings[args.SLURM_ARRAY_TASK_ID // len(resumes)] \n",
    "    # args.coarse_graining = \"vary_cos_alignment\"\n",
    "    if args.coarse_graining in [\"abstop\",\"shrink_norm\", \"vary_cos_alignment\"]:\n",
    "        args.input_covariance = \"False\"\n",
    "    else: \n",
    "        args.input_covariance = \"anisotropic\"\n",
    "         \n",
    "    # args.coarse_graining = \"aniso_highvariance_vary_cos\"\n",
    "    # args.coarse_graining = \"aniso_highvariance_shrink_k\"\n",
    "    \n",
    "    # args.resume = \"./cache/linreg_nov19_specgen_bias_Dsum__scheduler_None_K_1048576_no_layernorm_input_opt_Adam_lr_1e-4_gpt_bias_True_epochs_500_visible_32_K_1048576_D_64_L_100_hidden_128_coarse_abstop_1732079442.9435685.pkl\"\n",
    "elif args.fileprefix == \"jan23_2pm\":\n",
    "    resumes = [\n",
    "            \"./cache/linreg_nov19_specgen_bias_Dsum__scheduler_None_K_1024_no_layernorm_input_opt_Adam_lr_1e-4_gpt_bias_True_epochs_500_visible_32_K_1024_D_64_L_100_hidden_128_coarse_abstop_1732079333.0764203.pkl\",\n",
    "            \"./cache/linreg_nov19_specgen_bias_Dsum__scheduler_None_K_1048576_no_layernorm_input_opt_Adam_lr_1e-4_gpt_bias_True_epochs_500_visible_32_K_1048576_D_64_L_100_hidden_128_coarse_abstop_1732079442.9435685.pkl\",\n",
    "            ]\n",
    "    args.resume = resumes[args.SLURM_ARRAY_TASK_ID % len(resumes)]\n",
    "    args.coarse_graining = \"vary_cos_alignment\"\n",
    "print (\"resume\",args.resume, \"coarse_graining\",args.coarse_graining)\n",
    "# assert args.K % args.L == 0, \"K must be divisible by L\" \n",
    "\n",
    "if args.resume:\n",
    "    r = utils.load_file_pickle(args.resume)\n",
    "    \n",
    "    print(f\"Resuming from {args.resume}\")\n",
    "    print (r.keys())\n",
    "    args.sigma_xi = r[\"args\"][\"sigma_xi\"]\n",
    "args.seed = r[\"args\"][\"seed\"]\n",
    "\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed_all(args.seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "  \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Local Rank for distributed training\n",
    "local_rank = os.getenv('RANK')\n",
    "if local_rank is None: \n",
    "    local_rank = 0\n",
    "else:\n",
    "    local_rank = int(local_rank)\n",
    "print(\"LOCAL RANK \", local_rank)\n",
    "print(\"args:\\n\",vars(args))\n",
    "# setup weights and biases (optional)\n",
    "if local_rank==0 and args.wandb_log: # only use main process for wandb logging\n",
    "    print(f\"wandb {args.wandb_project} run\")\n",
    "    wandb.login(host='https://stability.wandb.io') # need to configure wandb environment beforehand\n",
    "    wandb_model_name = f\"{args.fileprefix}_K_{args.K}_D_{args.D_sum}_L_{args.len_context}_hidden_{args.num_hidden_features}_coarse_{args.coarse_graining}\"\n",
    "    wandb_config = vars(args)\n",
    "    \n",
    "    print(\"wandb_id:\",wandb_model_name)\n",
    "    wandb.init(\n",
    "        project=args.wandb_project,\n",
    "        name=wandb_model_name,\n",
    "        config=wandb_config,\n",
    "        resume=\"allow\",\n",
    "        group=args.wandb_group_name\n",
    "    )\n",
    "    wandb.config.local_file_dir = wandb.run.dir \n",
    "else:\n",
    "    record = {\n",
    "        \"args\": vars(args),\n",
    "        \"logs\": []\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequence(torch.utils.data.Dataset):\n",
    "    def __init__(self, K, D,  \n",
    "                 len_context = 1,\n",
    "                 scale=0.5,\n",
    "                len_data = 60000, skip_generating_betas=False,\n",
    "                input_covariance = None):\n",
    "\n",
    "        # if K < 40000:\n",
    "        self.len_context = len_context\n",
    "        self.D = D\n",
    "    \n",
    "        # x = rng.standard_normal((K, D)) * (1.0 / np.sqrt(D)) # shape: (K, D) \n",
    "        self.scale = scale\n",
    "        if skip_generating_betas == False:\n",
    "            true_betas = torch.randn((K, D)) * scale #* (1.0 / np.sqrt(D)) # shape: (K, D)\n",
    "            self.true_betas = true_betas \n",
    "         \n",
    "        self.K = K \n",
    "        self.D = D\n",
    "        self.len_data = len_data\n",
    "        self.input_covariance_L = torch.linalg.cholesky(input_covariance) if input_covariance is not None else None\n",
    "        self.input_covariance = input_covariance.to(device) if input_covariance is not None else None\n",
    "    def __len__(self):\n",
    "        return self.len_data\n",
    "\n",
    "    def __getitem__(self, task: int):\n",
    "        task_ind = torch.randint(0, self.K, (1,)).item()\n",
    "        beta_incontext = self.true_betas[task_ind].unsqueeze(1) # shape: (D, 1)\n",
    "        if self.input_covariance_L is None:\n",
    "            x = torch.randn((self.len_context, self.D)) * self.scale  # shape: (self.len_context, D) * (1.0 / np.sqrt(self.D))\n",
    "        else: \n",
    "            x = torch.randn((self.len_context, self.D))\n",
    "            x = torch.matmul(x, self.input_covariance_L.T) \n",
    "            \n",
    "        noise = torch.randn((self.len_context, 1)) * args.sigma_xi\n",
    "        y = torch.matmul(x, beta_incontext) + noise\n",
    "\n",
    "        # concat x and y \n",
    "        samples = x#torch.cat([x, y], axis = 1) # shape: (self.len_context, D+1)\n",
    "        # ytest = samples[-1, -1].clone() \n",
    "        # samples[-1, -1] = 0.0 # remove ytest from samples \n",
    "        return samples.type(torch.float32), y.type(torch.float32), beta_incontext.type(torch.float32)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importlib.reload(gpt)\n",
    "import gpt\n",
    "criterion = nn.MSELoss().to(device)\n",
    "# define the model, optimizer, and scheduler, and criterion\n",
    "if args.arch == \"causal_transformer_embed\":\n",
    "    nheads = 1 # np.clip(args.num_hidden_features // 8, 1, 8)\n",
    "    model = attention.MultiLayerTransformer(x_dim=args.D_sum,                   \n",
    "                                  mlp_dim=args.num_hidden_features, \n",
    "                                  num_layers = args.num_layers\n",
    "                                  ).to(device)\n",
    "if args.arch == \"gpt\":\n",
    "    import gpt \n",
    "    config = gpt.GPTConfig(\n",
    "        block_size = r[\"args\"][\"len_context\"],\n",
    "        input_size = r[\"args\"][\"D_sum\"],\n",
    "        n_embd=r[\"args\"][\"num_hidden_features\"],\n",
    "        n_layer=r[\"args\"][\"num_layers\"],\n",
    "        bias = r[\"args\"][\"gpt_bias\"] == \"True\"\n",
    "    )\n",
    "    model = gpt.GPT(config, criterion).to(device)\n",
    "\n",
    "if args.optimizer == 'SGD': \n",
    "    optimizer = torch.optim.SGD(model.parameters(),  \n",
    "                            lr=args.lr, \n",
    "                            weight_decay=args.weight_decay\n",
    "                            )\n",
    "    \n",
    "elif args.optimizer == 'Adam':\n",
    "    optimizer = torch.optim.Adam(model.parameters(),  \n",
    "                            lr=args.lr, \n",
    "                            weight_decay=args.weight_decay\n",
    "                            )\n",
    "else:\n",
    "    raise ValueError(\"optimizer not recognized\")\n",
    "iters_per_epoch = 1000\n",
    "# scheduler = StepLR(optimizer, step_size=50, gamma=0.7)\n",
    "scheduler = OneCycleLR(optimizer, max_lr=args.lr, \n",
    "                       total_steps=args.epochs * iters_per_epoch, \n",
    "                       pct_start=0.5,\n",
    "                       steps_per_epoch=iters_per_epoch, epochs=args.epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot([i[\"lr\"] for i in r[\"logs\"]])\n",
    "# plt.xlabel(\"epoch\")\n",
    "# plt.ylabel(\"learning rate\")\n",
    "# plt.savefig(f\"./analysis/lr_{args.resume.split('/')[-1]}.png\")\n",
    "# plt.show()\n",
    "# plt.plot([i[\"iwl_indistribution_loss_99\"] for i in r[\"logs\"]])\n",
    "# plt.xlabel(\"epoch\")\n",
    "# plt.ylabel(\"in-distribution loss\")\n",
    "# plt.savefig(f\"./analysis/in_distribution_loss_{args.resume.split('/')[-1]}.png\")\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders (args, len_context, D_sum):\n",
    "    # define the dataset\n",
    "    train_kwargs = {'batch_size': args.batch_size}\n",
    "    test_kwargs = {'batch_size': args.batch_size}\n",
    "    use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        cuda_kwargs = {'num_workers': args.workers,\n",
    "                        \"shuffle\": True,\n",
    "                        'pin_memory': True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "    train_dataset = Sequence(K=args.K, D=D_sum, len_context=len_context, len_data = args.batch_size * iters_per_epoch,\n",
    "                            scale =1.0, input_covariance = None)\n",
    "                            \n",
    "    if args.input_covariance == \"anisotropic\":\n",
    "        # A covariance matrix with eigenvalues only at s₋ and s₊\n",
    "        sminus = 0.1\n",
    "        splus = 1.0\n",
    "        # The proportion of eigenvalues at s₋ should be ρ₋\n",
    "        rho_minus = args.rho_minus\n",
    "        # The proportion of eigenvalues at s₊ should be 1-ρ₋\n",
    "        input_covariance = torch.eye(D_sum)\n",
    "        \n",
    "        # Calculate number of eigenvalues for each mode\n",
    "        # D_sum = 64\n",
    "        num_minus = int(D_sum * rho_minus)\n",
    "        num_plus = D_sum - num_minus\n",
    "        \n",
    "        # Create diagonal matrix of eigenvalues\n",
    "        eigenvalues = np.concatenate([\n",
    "            np.ones(num_plus) * splus,\n",
    "            np.ones(num_minus) * sminus\n",
    "        ])\n",
    "        \n",
    "        # Generate random orthogonal matrix\n",
    "        # Q = np.linalg.qr(np.random.randn(D_sum, D_sum))[0]\n",
    "        \n",
    "        # Construct covariance matrix \n",
    "        # input_covariance = torch.tensor(Q @ np.diag(eigenvalues) @ Q.T, dtype=torch.float32) \n",
    "        input_covariance = torch.tensor(np.diag(eigenvalues), dtype=torch.float32) \n",
    "        \n",
    "    else:\n",
    "        input_covariance = None\n",
    "        \n",
    "    \n",
    "    # iwl_dataset = Sequence(K=args.K, D=args.D_sum, len_context=args.len_context, len_data = 1000)\n",
    "    # iwl_dataset.true_betas = train_dataset.true_betas\n",
    "    icl_test_dataset = Sequence(K=1000, D=D_sum, len_context=len_context, len_data = 2000,\n",
    "                                scale = 1.0, input_covariance = input_covariance)\n",
    "\n",
    "    iwl_test_dataset = Sequence(K=args.K, D=D_sum, len_context=len_context, len_data = 2000, skip_generating_betas = True,\n",
    "                                scale = 1.0, input_covariance = input_covariance)\n",
    "    iwl_test_dataset.true_betas = train_dataset.true_betas\n",
    "\n",
    "    train_sampler = None\n",
    "    val_sampler = None \n",
    "    # train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "    #                                             sampler=train_sampler, \n",
    "    #                                             **train_kwargs) \n",
    "    icl_test_loader = torch.utils.data.DataLoader(icl_test_dataset,\n",
    "                                                sampler=val_sampler,\n",
    "                                                **test_kwargs)  \n",
    "    iwl_test_loader = torch.utils.data.DataLoader(iwl_test_dataset,\n",
    "                                                sampler=val_sampler,\n",
    "                                                **test_kwargs) \n",
    "    return icl_test_loader, iwl_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ridge_preds(seq, target, xtest, lam=1e-5):\n",
    "    seqT = seq.permute(0, 2, 1) # batch_size x D x len_context\n",
    "    ridge_matrix = torch.matmul(seqT, seq) # batch_size x D x D\n",
    "    ridge_matrix += torch.eye(ridge_matrix.size(1), device=ridge_matrix.device) * lam\n",
    "    seqT_Y = torch.matmul(seqT, target) # batch_size x D x 1\n",
    "    w_ridge = torch.linalg.solve(ridge_matrix, seqT_Y) # batch_size x D x 1\n",
    "    preds = torch.matmul(xtest, w_ridge).squeeze(-1) # batch_size x 1 x 1\n",
    "    return preds \n",
    "\n",
    "def get_ridge_preds_seq(seq, target):\n",
    "    B, N, D = seq.size() \n",
    "    preds = []\n",
    "    for _i in range(1, N):\n",
    "        preds.append(get_ridge_preds(seq[:, :_i, :], target[:, :_i, :], seq[:, _i: _i + 1, :]))\n",
    "    return torch.stack(preds, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate OOD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "        \n",
    "def validate_gradient_descent(val_loader, model, args, D_visible, len_context, criterion, device, coarse_graining=\"standard\"):\n",
    "    # seq_lens = list(range(1, args.len_context+1, 5)) \n",
    "   \n",
    "    test_losses = [utils.AverageMeter('Loss', ':.4e') for _ in range(len_context)]\n",
    "    \n",
    "    model.eval() # switch to eval mode\n",
    "    eps = 1e-5\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (seq, target, _true_beta) in enumerate(val_loader):\n",
    "            seq, target, _true_beta = seq.to(device), target.to(device), _true_beta.to(device)\n",
    "        \n",
    "            B, N, D = seq.size()\n",
    "            if coarse_graining == \"absbot\":\n",
    "                # true_beta: shape (B, D)\n",
    "                true_beta = _true_beta.squeeze(2)\n",
    "                argsort_beta_visible = torch.argsort(torch.abs(true_beta), dim=-1)[:, :D_visible] # sort each row of true_beta by absolute value, shape (B, D_visible)\n",
    "                test_beta_visible = torch.gather(true_beta, dim=1, index=argsort_beta_visible) # shape (B, D_visible)\n",
    "                x_test_visible = torch.gather(seq[:, -1, :].squeeze(1), dim=1, index=argsort_beta_visible) # shape (B, D_visible) \n",
    "                \n",
    "                new_target = torch.matmul(x_test_visible.unsqueeze(1), test_beta_visible.unsqueeze(2)).squeeze(2) \n",
    "                new_target = new_target.squeeze(1)\n",
    "                # if args.sigma_xi > 1e-5:\n",
    "                    # print  (\"-D_visible\", -D_visible, \"argsort_beta_visible\", argsort_beta_visible.shape, \"test_beta_visible\", test_beta_visible.shape)\n",
    "                sigma_test_xi = torch.pow(args.sigma_xi ** 2 + torch.matmul(true_beta.unsqueeze(1), true_beta.unsqueeze(2)) \\\n",
    "                                        - torch.matmul(test_beta_visible.unsqueeze(1), test_beta_visible.unsqueeze(2))+eps, 0.5).squeeze(2).squeeze(1) # shape (B)\n",
    "                # print (\"sigma_test_xi\", sigma_test_xi)\n",
    "                new_target += torch.randn(new_target.size(0), device=device) * sigma_test_xi # shape (B, 1) \n",
    "                target[:, -1, 0] = new_target\n",
    "                \n",
    "            elif coarse_graining == \"abstop\":\n",
    "                true_beta = _true_beta.squeeze(2) # shape (B, D)\n",
    "                # print (\"true_beta\", true_beta.shape)\n",
    "                argsort_beta_visible = torch.argsort(torch.abs(true_beta), dim=-1)[:, -D_visible:] # sort each row of true_beta by absolute value, shape (B, D_visible)\n",
    "                # test_beta_visible = true_beta[argsort_beta_visible] # take top D_visible betas, shape (B, D_visible) \n",
    "                test_beta_visible = torch.gather(true_beta, dim=1, index=argsort_beta_visible) # shape (B, D_visible)\n",
    "                x_test_visible = torch.gather(seq[:, -1, :].squeeze(1), dim=1, index=argsort_beta_visible) # shape (B, D_visible) \n",
    "                \n",
    "                # target = x_test_visible  @ test_beta_visible + np.random.randn(N_test) * sigma_test_xi\n",
    "                new_target = torch.matmul(x_test_visible.unsqueeze(1), test_beta_visible.unsqueeze(2)).squeeze(2) \n",
    "                new_target = new_target.squeeze(1)\n",
    "                # if args.sigma_xi > 1e-5:\n",
    "                    # print  (\"-D_visible\", -D_visible, \"argsort_beta_visible\", argsort_beta_visible.shape, \"test_beta_visible\", test_beta_visible.shape)\n",
    "                # sigma_test_xi = torch.pow(args.sigma_xi ** 2 + torch.matmul(true_beta.unsqueeze(1), true_beta.unsqueeze(2)) \\\n",
    "                                        # - torch.matmul(test_beta_visible.unsqueeze(1), test_beta_visible.unsqueeze(2))+eps, 0.5).squeeze(2).squeeze(1) # shape (B)\n",
    "                # print (\"sigma_test_xi\", sigma_test_xi)\n",
    "                # new_target += torch.randn(new_target.size(0), device=device) * sigma_test_xi # shape (B, 1) \n",
    "                # print (\"new_target\", new_target, \"sigma_test_xi\", sigma_test_xi )\n",
    "                target[:, -1, 0] = new_target\n",
    "                \n",
    "            elif coarse_graining == \"shrink_norm\": \n",
    "                true_beta = _true_beta.squeeze(2) \n",
    "                x_test_visible = seq[:, -1, :].squeeze(1)\n",
    "                # test beta is beta but with smaller norm\n",
    "                test_beta_visible = true_beta * (D_visible / D) # shape (B, D) \n",
    "                # print (\"test_beta_visible\", test_beta_visible.unsqueeze(1).shape, \"x_test_visible\", x_test_visible.unsqueeze(2).shape)\n",
    "                new_target = torch.matmul(x_test_visible.unsqueeze(1), test_beta_visible.unsqueeze(2)).squeeze(2) \n",
    "                # print (\"new_target\", new_target.shape, \"args.sigma_xi\", args.sigma_xi)\n",
    "                new_target += args.sigma_xi * torch.randn_like(new_target, device=device) # shape (B, 1)\n",
    "                new_target = new_target.squeeze(1) \n",
    "                \n",
    "                target[:, -1, 0] = new_target \n",
    "                \n",
    "            elif coarse_graining == \"vary_cos_alignment\": \n",
    "                # get x, target, beta_incontext\n",
    "                x = seq \n",
    "                beta_incontext = torch.ones_like(_true_beta)  \n",
    "                # normalize beta_incontext \n",
    "                beta_incontext = beta_incontext / torch.linalg.norm(beta_incontext, dim=1).unsqueeze(1) * torch.linalg.norm(_true_beta, dim=1).unsqueeze(1)\n",
    "                \n",
    "                # compute target y = x @ beta + noise\n",
    "                target = torch.matmul(x, beta_incontext) \n",
    "                noise = torch.randn_like(target) * args.sigma_xi\n",
    "                target += noise\n",
    "                \n",
    "                # concept shift: vary the cosine of the high variance features and compute new target\n",
    "                num_features_flipped = int(x.shape[-1] * ((D-D_visible) / D)) # if D_visible is small, then every feature is flipped\n",
    "                beta_incontext[:, :num_features_flipped, :] = -beta_incontext[:, :num_features_flipped, :] \n",
    "                new_target = torch.matmul(x[:, -1, :].unsqueeze(1), beta_incontext).squeeze(2).squeeze(1) \n",
    "                # new_target += args.sigma_xi * torch.randn_like(new_target, device=device) # shape (B, 1)\n",
    "                target[:, -1, -1] = new_target \n",
    "                \n",
    "            elif coarse_graining == \"aniso_highvariance_shrink_k\":\n",
    "                # get x, target, beta_incontext\n",
    "                x = seq \n",
    "                high_variance_features_id = int(args.rho_minus * x.shape[-1])\n",
    "                beta_incontext = torch.randn_like(_true_beta) \n",
    "\n",
    "                # balance signal fraction of the low variance features\n",
    "                beta_incontext[:,high_variance_features_id:,:] = beta_incontext[:,high_variance_features_id:,:] * (np.sqrt(10))\n",
    "                # normalize beta_incontext \n",
    "                \n",
    "                beta_incontext = beta_incontext / torch.linalg.norm(beta_incontext, dim=1).unsqueeze(1) * torch.linalg.norm(_true_beta, dim=1).unsqueeze(1)\n",
    "                \n",
    "                # compute target y = x @ beta + noise\n",
    "\n",
    "                print (\"x\", x.shape, \"beta_incontext\", beta_incontext.shape, \"high_variance_features_id\", high_variance_features_id)\n",
    "                target = torch.matmul(x, beta_incontext) \n",
    "                noise = torch.randn_like(target) * args.sigma_xi\n",
    "                target += noise\n",
    "                \n",
    "                # concept shift: shrink the high variance features and compute new target\n",
    "                beta_incontext[:, :high_variance_features_id, :] = beta_incontext[:, :high_variance_features_id, :] * (D_visible / D)\n",
    "                new_target = torch.matmul(x[:, -1, :].unsqueeze(1), beta_incontext).squeeze(2).squeeze(1) \n",
    "                # new_target += args.sigma_xi * torch.randn_like(new_target, device=device) # shape (B, 1)\n",
    "                # print (\"x_test_visible\", x.shape, \"beta_incontext\", beta_incontext.shape, \"y\", target.shape, \"_true_beta norm\",  )\n",
    "                # print (\"target\", target.shape, \"new_target\", new_target.shape)\n",
    "                # print (\"beta_incontext norm\", torch.linalg.norm(beta_incontext, dim=1), \"_true_beta norm\", torch.linalg.norm(_true_beta, dim=1))\n",
    "                # print (\"target\", target.shape, \"new_target\", new_target.shape)\n",
    "                target[:, -1, -1] = new_target \n",
    "                # target[:, -1, 0] = new_target \n",
    "\n",
    "            elif coarse_graining == \"aniso_lowvariance_shrink_k\":\n",
    "                # get x, target, beta_incontext\n",
    "                x = seq \n",
    "                high_variance_features_id = int(args.rho_minus * x.shape[-1])\n",
    "                beta_incontext = torch.randn_like(_true_beta)  \n",
    "                \n",
    "                # balance signal fraction of the low variance features\n",
    "                beta_incontext[:,high_variance_features_id:,:] = beta_incontext[:,high_variance_features_id:,:] * (np.sqrt(10))\n",
    "                # normalize beta_incontext \n",
    "                beta_incontext = beta_incontext / torch.linalg.norm(beta_incontext, dim=1).unsqueeze(1) * torch.linalg.norm(_true_beta, dim=1).unsqueeze(1)\n",
    "                \n",
    "                # compute target y = x @ beta + noise\n",
    "                target = torch.matmul(x, beta_incontext) \n",
    "                noise = torch.randn_like(target) * args.sigma_xi\n",
    "                target += noise\n",
    "                \n",
    "                # concept shift: shrink the low variance features and compute new target\n",
    "                beta_incontext[:, -high_variance_features_id:, :] = beta_incontext[:, -high_variance_features_id:, :] * (D_visible / D)\n",
    "                new_target = torch.matmul(x[:, -1, :].unsqueeze(1), beta_incontext).squeeze(2).squeeze(1) \n",
    "                # new_target += args.sigma_xi * torch.randn_like(new_target, device=device) # shape (B, 1)\n",
    "                target[:, -1, -1] = new_target \n",
    "                # test_beta_visible = copy.deepcopy(_true_beta)\n",
    "                # high_variance_features_id = int(args.rho_minus * test_beta_visible.shape[1])\n",
    "                # test_beta_visible[:, -high_variance_features_id:, :] = test_beta_visible[:, -high_variance_features_id:, :] * (D_visible / D)\n",
    "                # # test_beta_visible = val_loader.dataset.input_covariance.T.unsqueeze(0) @ test_beta_visible\n",
    "                # new_target = torch.matmul(x_test_visible.unsqueeze(1), test_beta_visible).squeeze(2).squeeze(1)\n",
    "                # print (\"target\", target.shape, \"new_target\", new_target.shape)\n",
    "                # target[:, -1, 0] = new_target \n",
    "                \n",
    "                \n",
    "            elif coarse_graining == \"aniso_highvariance_vary_cos\":\n",
    "                # get x, target, beta_incontext\n",
    "                x = seq \n",
    "                high_variance_features_id = int(args.rho_minus * x.shape[-1])\n",
    "                beta_incontext = torch.ones_like(_true_beta)  \n",
    "                \n",
    "                # balance signal fraction of the low variance features\n",
    "                beta_incontext[:,high_variance_features_id:,:] = beta_incontext[:,high_variance_features_id:,:] * (np.sqrt(10))\n",
    "                # normalize beta_incontext \n",
    "                beta_incontext = beta_incontext / torch.linalg.norm(beta_incontext, dim=1).unsqueeze(1) * torch.linalg.norm(_true_beta, dim=1).unsqueeze(1)\n",
    "                \n",
    "                # compute target y = x @ beta + noise\n",
    "                target = torch.matmul(x, beta_incontext) \n",
    "                noise = torch.randn_like(target) * args.sigma_xi\n",
    "                target += noise\n",
    "                \n",
    "                # concept shift: vary the cosine of the high variance features and compute new target\n",
    "                high_variance_features_id = int(high_variance_features_id * ((D-D_visible) / D)) # if D_visible is small, then every feature is flipped\n",
    "                beta_incontext[:, :high_variance_features_id, :] = -beta_incontext[:, :high_variance_features_id, :] \n",
    "                new_target = torch.matmul(x[:, -1, :].unsqueeze(1), beta_incontext).squeeze(2).squeeze(1) \n",
    "                # new_target += args.sigma_xi * torch.randn_like(new_target, device=device) # shape (B, 1)\n",
    "                target[:, -1, -1] = new_target \n",
    "                \n",
    "            elif coarse_graining == \"aniso_lowvariance_vary_cos\":\n",
    "                # get x, target, beta_incontext\n",
    "                x = seq \n",
    "                high_variance_features_id = int(args.rho_minus * x.shape[-1])\n",
    "                beta_incontext = torch.ones_like(_true_beta)  \n",
    "                \n",
    "                # balance signal fraction of the low variance features\n",
    "                beta_incontext[:,high_variance_features_id:,:] = beta_incontext[:,high_variance_features_id:,:] * (np.sqrt(10))\n",
    "                # normalize beta_incontext \n",
    "                beta_incontext = beta_incontext / torch.linalg.norm(beta_incontext, dim=1).unsqueeze(1) * torch.linalg.norm(_true_beta, dim=1).unsqueeze(1)\n",
    "                \n",
    "                # compute target y = x @ beta + noise\n",
    "                target = torch.matmul(x, beta_incontext) \n",
    "                noise = torch.randn_like(target) * args.sigma_xi\n",
    "                target += noise\n",
    "                \n",
    "                # concept shift: vary the cosine of the low variance features and compute new target\n",
    "                flip_features_id = int(high_variance_features_id * ((D-D_visible) / D)) # if D_visible is small, then every feature is flipped\n",
    "                beta_incontext[:, (-high_variance_features_id):(-high_variance_features_id+flip_features_id), :] = -beta_incontext[:, (-high_variance_features_id):(-high_variance_features_id+flip_features_id), :]\n",
    "                new_target = torch.matmul(x[:, -1, :].unsqueeze(1), beta_incontext).squeeze(2).squeeze(1)\n",
    "                # new_target += args.sigma_xi * torch.randn_like(new_target, device=device) # shape (B, 1)\n",
    "                target[:, -1, -1] = new_target \n",
    "                \n",
    "                 \n",
    "            output = model(seq, target) \n",
    "            # print (\"seq\", seq.shape, \"target\", target.shape, \"output\", output.shape )\n",
    "            preds = output[:, ::2, :]\n",
    "            # distance to ridge_preds \n",
    "            # if coarse_graining == \"standard\":\n",
    "            #     ridge_preds = get_ridge_preds_seq(seq, target) # shape: (B, N-1, 1)\n",
    "            #     ridge_loss = (ridge_preds - target[:, 1:, :]).pow(2).mean(dim=0)\n",
    "            #     dist_to_ridge = (preds[:,1:, :] - ridge_preds).pow(2).mean(dim=0)\n",
    "            #     print (\"ridge_loss\", ridge_loss, \"dist_to_ridge\", dist_to_ridge.shape, dist_to_ridge)\n",
    "                \n",
    "            loss = (preds - target).pow(2).squeeze(-1).mean(dim=0) \n",
    "            print (\"test preds\", preds.shape, \"test target\", target.shape, \"test loss\", loss)\n",
    "            \n",
    "            [test_losses[_].update(loss[_].item(), target.size(0)) for _ in range(N)]\n",
    "            # acc1 = utils.accuracy(output, seq_target, topk=[1])\n",
    "            # test_top1[seq_len].update(acc1[0], target.size(0))\n",
    "            # acc1 = torch.mean(((output.squeeze(1) * (seq_target*2-1)) > 0).float()).item()\n",
    "            # test_top1[seq_len].update(acc1, target.size(0))\n",
    "\n",
    "    return test_losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# import matplotlib.pyplot as plt\n",
    "exp_name = f\"./analysis/{args.fileprefix}_coarsegraining_{args.coarse_graining}_{args.resume.split('/')[-1]}\"\n",
    "D_sum=r[\"args\"][\"D_sum\"]\n",
    "for len_context in list(range(1, args.len_context+1, 10))[::-1] + [args.len_context]: \n",
    "    icl_test_loader, iwl_test_loader = get_data_loaders(args, len_context, D_sum)\n",
    "    for D_visible in np.concatenate([np.arange(D_sum-1, 1, -2)]):\n",
    "        \n",
    "        model.load_state_dict(r[\"model\"])\n",
    "        icl_outdistribution_losses = validate_gradient_descent(icl_test_loader, model, args, D_visible, len_context, criterion, device, coarse_graining=args.coarse_graining)\n",
    "        icl_indistribution_losses = validate_gradient_descent(icl_test_loader, model, args, D_visible, len_context, criterion, device, coarse_graining=\"standard\")\n",
    "        \n",
    "        # iwl_indistribution_losses = validate_gradient_descent(iwl_test_loader, model, args, D_visible, len_context, criterion, device, coarse_graining=\"standard\")\n",
    "        # iwl_outdistribution_losses = validate_gradient_descent(iwl_test_loader, model, args, D_visible, len_context, criterion, device, coarse_graining=args.coarse_graining)\n",
    "        \n",
    "        \n",
    "\n",
    "        # save metrics\n",
    "        # print(\"output\",  torch.argsort(output, dim=-1), \"target\", target )\n",
    "        # print(\"Current average loss\", losses.avg, top1.avg, \"epoch\", epoch) \n",
    "        # seen_val_losses, seen_val_top1 = validate_gradient_descent(icl_loader, seen_projs_permutations_loader, model, args, criterion, device)\n",
    "        \n",
    "        # Compute unseen val loss\n",
    "        # unseen_val_losses, unseen_val_top1 = validate_gradient_descent(icl_loader, seen_projs_permutations_loader, model, args, criterion, device)\n",
    "        logs = {\n",
    "                \"len_context\": len_context,\n",
    "                \"D_visible\": D_visible,\n",
    "                # \"icl_indistribution_loss\": icl_indistribution_losses.avg,\n",
    "                # \"icl_outdistribution_loss\": icl_outdistribution_losses.avg,\n",
    "                # \"iwl_indistribution_loss\": iwl_indistribution_losses.avg,\n",
    "                # \"iwl_outdistribution_loss\": iwl_outdistribution_losses.avg,\n",
    "            }\n",
    "        for _ in range(len_context):\n",
    "            logs[f\"icl_indistribution_loss_{_}\"] = icl_indistribution_losses[_].avg\n",
    "            logs[f\"icl_outdistribution_loss_{_}\"] = icl_outdistribution_losses[_].avg\n",
    "            # logs[f\"iwl_indistribution_loss_{_}\"] = iwl_indistribution_losses[_].avg\n",
    "            # logs[f\"iwl_outdistribution_loss_{_}\"] = iwl_outdistribution_losses[_].avg\n",
    "        record[\"logs\"].append(logs)\n",
    "\n",
    "    with open(exp_name, \"wb\") as f:\n",
    "        pickle.dump(record, f)\n",
    "    # # print(logs) \n",
    "    # if args.wandb_log:\n",
    "    #     wandb.log(logs)\n",
    "    # else:\n",
    "    \n",
    "    \n",
    " \n",
    "    \n",
    "    \n",
    "#     if epoch % 10 == 0 and args.wandb_log != True:\n",
    "#         record[\"model\"] = copy.deepcopy(model.state_dict())  \n",
    "#         with open(exp_name, \"wb\") as f:\n",
    "#             pickle.dump(record, f)\n",
    "\n",
    "# if args.wandb_log != True:\n",
    "with open(exp_name, \"wb\") as f:\n",
    "    pickle.dump(record, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (renormalization)",
   "language": "python",
   "name": "renormalization"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
