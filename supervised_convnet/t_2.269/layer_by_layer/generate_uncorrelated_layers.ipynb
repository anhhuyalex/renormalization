{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import x3x3.frozen as frozen\n",
    "\n",
    "data = np.load(\"ising27x27coarsegrained_temp2.269.npy\")\n",
    "\n",
    "# Batch size, channels, height, width\n",
    "\n",
    "# train on 3 x 3\n",
    "class SupervisedConvNet(nn.Module):\n",
    "    def __init__(self, filter_size, square_size, hidden_size, num_hidden_layers, center,\n",
    "                first_activation = \"tanh\", activation_func = \"sigmoid\",\n",
    "                out_channels = 1):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        filter_size ~ size of the convolution kernel (3 x 3)\n",
    "        square size ~ how many strides of convolution in the input\n",
    "        \"\"\"\n",
    "        super(SupervisedConvNet, self).__init__()\n",
    "        self.filter_size = filter_size\n",
    "        self.square_size = square_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.out_channels = out_channels\n",
    "        if first_activation == \"tanh\":\n",
    "            self.first_activation = torch.tanh\n",
    "        elif first_activation == \"relu\":\n",
    "            self.first_activation = torch.nn.LeakyReLU(0.1)\n",
    "        if activation_func == \"sigmoid\":\n",
    "            self.activation_func = torch.sigmoid\n",
    "        elif activation_func == \"relu\":\n",
    "            self.activation_func = torch.nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, out_channels, filter_size, padding=0, stride = filter_size)\n",
    "        # parameters\n",
    "        param = {}\n",
    "        if center == \"keep\":\n",
    "            param['conv2d.weight'] = torch.tensor([[[[1.0, 1.0, 1.0],\n",
    "                      [1.0, 1.0, 1.0],\n",
    "                      [1.0, 1.0, 1.0]]]])/9\n",
    "            param['conv2d.bias'] = torch.tensor([0.0])\n",
    "            self.conv1.bias = torch.nn.Parameter(param['conv2d.bias'], requires_grad=False)\n",
    "        elif center == \"omit\":\n",
    "            param['conv2d.weight'] = torch.tensor([[[[1.0, 1.0, 1.0],\n",
    "                      [1.0, 0.0, 1.0],\n",
    "                      [1.0, 1.0, 1.0]]]])/8\n",
    "            # param['conv2d.bias'] = torch.tensor([0.0])\n",
    "        elif center == \"pre_trained_81x81\":\n",
    "            param['conv2d.weight'] = torch.tensor([[[[-0.0900, -0.0407, -0.0965],\n",
    "          [-0.0413, -0.0011, -0.0363],\n",
    "          [-0.0906, -0.0344, -0.0908]]]])\n",
    "            param['conv2d.bias'] = torch.tensor([-0.0345])\n",
    "            self.conv1.bias = torch.nn.Parameter(param['conv2d.bias'], requires_grad=False)\n",
    "        elif center == \"pre_trained_27x27\":\n",
    "            param['conv2d.weight'] = -torch.tensor([[[[-0.3833, -0.0056, -0.4275],\n",
    "          [-0.0172,  0.1212, -0.0063],\n",
    "          [-0.4010, -0.0461, -0.3762]]]])\n",
    "            param['conv2d.bias'] = -torch.tensor([-0.0690])\n",
    "            self.conv1.bias = torch.nn.Parameter(param['conv2d.bias'], requires_grad=False)\n",
    "        self.conv1.weight = torch.nn.Parameter(param['conv2d.weight'], requires_grad=False)\n",
    "\n",
    "\n",
    "        self.first_linear = nn.Linear(self.out_channels * square_size ** 2, hidden_size)\n",
    "        hidden_layer = [nn.Linear(hidden_size, hidden_size) for _ in range(num_hidden_layers)]\n",
    "        self.linear_hidden = nn.ModuleList(hidden_layer)\n",
    "        self.linear_output = nn.Linear(hidden_size, 1)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_activation(self.conv1(x))#.view(-1, 1, self.out_channels * self.square_size**2)\n",
    "#         x = self.activation_func(self.first_linear(x))\n",
    "#         for linear in self.linear_hidden:\n",
    "#             x = self.activation_func(linear(x))\n",
    "#         x = torch.sigmoid(self.linear_output(x))\n",
    "#         x = x.squeeze(1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def coarse_grain_frozen_conv(correlated_data = data):\n",
    "    run_mode = \"frozen_convolution_pretrained_relu\"\n",
    "    mode = \"run\"\n",
    "    if mode == \"run\":\n",
    "        hidden_size = 10\n",
    "        out_channels = 1\n",
    "        num_hidden_layers = 1\n",
    "\n",
    "\n",
    "        if run_mode == \"frozen_convolution_pretrained_relu\":\n",
    "            \"\"\"\n",
    "            \"\"\"\n",
    "            run_num = 1\n",
    "            filename = f\"frozen_convolution_pretrained_relu_{run_num}.pl\"\n",
    "            out_channels = 1\n",
    "            try:\n",
    "                with open(filename, \"rb\") as handle:\n",
    "                    results = pickle.load(handle)\n",
    "            except:\n",
    "                results = []\n",
    "            results = []\n",
    "            model = SupervisedConvNet(filter_size = 3, square_size = 9, \\\n",
    "                    hidden_size = hidden_size, out_channels = out_channels,\n",
    "                    center = \"pre_trained_27x27\", first_activation = \"tanh\",\n",
    "                    activation_func = \"relu\", num_hidden_layers = num_hidden_layers)\n",
    "            data = torch.tensor(correlated_data).unsqueeze(1).type('torch.FloatTensor')\n",
    "            out = model(data)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = coarse_grain_frozen_conv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.1,  0.1, -0.1,  0.5,  0.3,  0.5,  0.4,  0.5,  0.2,  0.5],\n",
       "       [ 0.4,  0.2, -0.5,  0.5,  0.4,  0.1,  0.5,  0.4,  0.1,  0.5],\n",
       "       [ 0.3,  0.3, -0. ,  0.1,  0.5,  0.4,  0.2,  0.5,  0.5,  0.5],\n",
       "       [-0. ,  0.3,  0. , -0.3,  0.2,  0.5,  0.5,  0.5, -0.1,  0.5],\n",
       "       [ 0.4,  0.4,  0.5,  0. ,  0.5,  0.2,  0.5,  0.5,  0.4,  0.5],\n",
       "       [ 0.3,  0.1,  0.5,  0.3,  0.5,  0.3,  0.2,  0.2,  0.2,  0.3],\n",
       "       [-0. ,  0.5,  0.4,  0.5,  0.5,  0.5,  0.4, -0.1,  0.2,  0.3],\n",
       "       [ 0.3,  0.3,  0.5,  0.5,  0.5,  0.5,  0.3,  0.3,  0.5,  0.5],\n",
       "       [ 0.5,  0.1,  0.5,  0.5,  0.3,  0.5,  0.5,  0.5,  0.5,  0.5],\n",
       "       [ 0.5,  0.3,  0.2,  0.5, -0.3,  0.5,  0.5,  0.4,  0.2,  0.5]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(precision=1)\n",
    "data[0, :10, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5,  0.3,  0.4,  0.6,  0.4,  0.1, -0.3,  0.3,  0.6],\n",
       "         [ 0.5,  0.5,  0.4,  0.5,  0.1,  0.5, -0.4,  0.1,  0.6],\n",
       "         [ 0.5,  0.6,  0.3,  0.6,  0.6,  0.5, -0.5, -0.6,  0.5],\n",
       "         [ 0.4,  0.5,  0.6,  0.5,  0.1, -0.2, -0.2,  0.1,  0.5],\n",
       "         [ 0.6,  0.4,  0.6,  0.6,  0.1, -0.3,  0.3,  0.6,  0.5],\n",
       "         [ 0.6,  0.6,  0.6,  0.6,  0.4,  0.1,  0.6,  0.6,  0.6],\n",
       "         [ 0.3,  0.3,  0.2,  0.5, -0.2, -0.1,  0.4,  0.6,  0.6],\n",
       "         [ 0.6,  0.4,  0.3,  0.4,  0.5,  0.3,  0.5, -0.1,  0.3],\n",
       "         [ 0.6,  0.2,  0.6,  0.6,  0.6,  0.4,  0.0, -0.3,  0.2]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_printoptions(precision=1)\n",
    "out[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1, 9, 9])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.set_printoptions(precision=1)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_uncorrelated_data(data):\n",
    "    # data expects an array of shape [10000, 9, 9]\n",
    "    uncorrelated_data = []\n",
    "    for _ in range(10000):\n",
    "        sample = np.random.randint(0, 10000, (3, 3))\n",
    "        horizontal, vertical = np.random.randint(0, 7, (2, 3, 3))\n",
    "        uncorrelated = []\n",
    "        for i in range(3):\n",
    "            tile = []\n",
    "            for j in range(3):\n",
    "                tile.append(data[sample[i, j], horizontal[i, j]:(horizontal[i, j] + 3), \\\n",
    "                        vertical[i, j]:(vertical[i, j] + 3)])\n",
    "            uncorrelated.append(np.hstack(tile))\n",
    "        uncorrelated_data.append(np.vstack(uncorrelated))\n",
    "\n",
    "    uncorrelated_data = np.array(uncorrelated_data)\n",
    "    return uncorrelated_data\n",
    "\n",
    "uncorrelated_data = generate_uncorrelated_data(out.squeeze(1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.6, -0.6, -0.4,  0.2, -0.5, -0.1,  0.6,  0.5, -0.3],\n",
       "       [-0.5,  0.1, -0.3, -0.2, -0.1, -0.1,  0.7,  0.5,  0.5],\n",
       "       [-0. ,  0.4, -0.2, -0.5, -0.3, -0.3,  0.5,  0.6,  0.6],\n",
       "       [ 0.6,  0.6,  0.5,  0.6,  0.3,  0.1, -0.3,  0.2,  0.3],\n",
       "       [ 0.6,  0.2,  0.2,  0.5,  0.5,  0.3, -0.5, -0.6,  0. ],\n",
       "       [ 0.4, -0.4, -0.3,  0.5,  0.4, -0.4, -0.6, -0.3, -0.5],\n",
       "       [ 0.5, -0.1, -0.1,  0.2, -0.6, -0.2,  0.2, -0.3, -0. ],\n",
       "       [ 0.3, -0.1,  0. ,  0. , -0.4, -0.6, -0.4, -0.5, -0.2],\n",
       "       [ 0.5, -0.3,  0. , -0.3, -0.5, -0.6, -0.5, -0.5, -0.2]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncorrelated_data[5, :10, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save files\n",
    "np.save(\"ising9x9coarsegrained_temp2.269.npy\", out.squeeze(1).numpy())\n",
    "np.save(\"ising9x9coarsegrained_temp2.269_uncorrelated.npy\", uncorrelated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1,  0.5,  0.5,  0.6,  0.6,  0.6,  0.6,  0.6,  0.4],\n",
       "       [ 0.3,  0.3,  0.3,  0.6,  0.6,  0.6,  0.6,  0.5,  0.6],\n",
       "       [ 0.5,  0.6,  0.6,  0.6,  0.5,  0.5,  0.2,  0.2,  0.5],\n",
       "       [ 0.6,  0.5,  0.6,  0.6,  0.6,  0.6,  0.4, -0.1,  0.5],\n",
       "       [ 0.6,  0.5,  0.6,  0.6,  0.5,  0.6,  0.5,  0.1,  0.1],\n",
       "       [ 0.6,  0.6,  0.6,  0.5,  0.4,  0.5,  0.6,  0.2,  0.4],\n",
       "       [ 0.6,  0.5,  0.5,  0.5,  0.6,  0.6,  0.6,  0.5,  0.6],\n",
       "       [ 0.6,  0.6,  0.5,  0.6,  0.6,  0.6,  0.6, -0. ,  0.3],\n",
       "       [ 0.3,  0.3,  0.3,  0.2,  0.6,  0.6,  0.6,  0.6,  0.1]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.squeeze(1).numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3,  0.5,  0.4, -0.2,  0.2,  0.5, -0.2,  0.2,  0.3],\n",
       "       [ 0.2,  0.2,  0.5, -0.4, -0.1, -0.1,  0.5,  0.2,  0.5],\n",
       "       [ 0.5,  0.6,  0.5, -0.6, -0.2, -0.1,  0.4,  0.4,  0.5],\n",
       "       [ 0.6,  0. , -0. , -0.6, -0.2, -0.2,  0.6,  0.1,  0.4],\n",
       "       [ 0.4, -0.2,  0.1, -0.4, -0.2, -0.4,  0.3,  0.5,  0.6],\n",
       "       [ 0. , -0. ,  0.3, -0.4, -0.2, -0.4,  0.6,  0.4,  0.6],\n",
       "       [-0.5, -0.5, -0.5,  0.5,  0.7,  0.5,  0.4,  0.4, -0.4],\n",
       "       [-0.3, -0.6, -0.4,  0.2,  0.6,  0.5,  0.5,  0.5, -0.2],\n",
       "       [-0.5, -0.6, -0.5,  0.5,  0.6, -0.2,  0.3,  0.2,  0.5]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncorrelated_data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Renormalization)",
   "language": "python",
   "name": "renormalization"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
