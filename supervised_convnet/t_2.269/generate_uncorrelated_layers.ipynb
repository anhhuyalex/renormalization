{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../ising81x81_temp2.269.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0a6ca7c5af13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mx3x3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrozen\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfrozen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../ising81x81_temp2.269.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Batch size, channels, height, width\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/renormalization/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../ising81x81_temp2.269.npy'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import sys\n",
    "import x3x3.frozen as frozen\n",
    "\n",
    "data = np.load(\"../ising81x81_temp2.269.npy\")\n",
    "\n",
    "# Batch size, channels, height, width\n",
    "\n",
    "# train on 3 x 3\n",
    "class SupervisedConvNet(nn.Module):\n",
    "    def __init__(self, filter_size, square_size, hidden_size, num_hidden_layers, center,\n",
    "                first_activation = \"tanh\", activation_func = \"sigmoid\",\n",
    "                out_channels = 1):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        filter_size ~ size of the convolution kernel (3 x 3)\n",
    "        square size ~ how many strides of convolution in the input\n",
    "        \"\"\"\n",
    "        super(SupervisedConvNet, self).__init__()\n",
    "        self.filter_size = filter_size\n",
    "        self.square_size = square_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.out_channels = out_channels\n",
    "        if first_activation == \"tanh\":\n",
    "            self.first_activation = torch.tanh\n",
    "        elif first_activation == \"relu\":\n",
    "            self.first_activation = torch.nn.LeakyReLU(0.1)\n",
    "        if activation_func == \"sigmoid\":\n",
    "            self.activation_func = torch.sigmoid\n",
    "        elif activation_func == \"relu\":\n",
    "            self.activation_func = torch.nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, out_channels, filter_size, padding=0, stride = filter_size)\n",
    "        # parameters\n",
    "        param = {}\n",
    "        if center == \"keep\":\n",
    "            param['conv2d.weight'] = torch.tensor([[[[1.0, 1.0, 1.0],\n",
    "                      [1.0, 1.0, 1.0],\n",
    "                      [1.0, 1.0, 1.0]]]])/9\n",
    "            param['conv2d.bias'] = torch.tensor([0.0])\n",
    "            self.conv1.bias = torch.nn.Parameter(param['conv2d.bias'], requires_grad=False)\n",
    "        elif center == \"omit\":\n",
    "            param['conv2d.weight'] = torch.tensor([[[[1.0, 1.0, 1.0],\n",
    "                      [1.0, 0.0, 1.0],\n",
    "                      [1.0, 1.0, 1.0]]]])/8\n",
    "            # param['conv2d.bias'] = torch.tensor([0.0])\n",
    "        elif center == \"pre_trained\":\n",
    "            param['conv2d.weight'] = torch.tensor([[[[-0.0900, -0.0407, -0.0965],\n",
    "          [-0.0413, -0.0011, -0.0363],\n",
    "          [-0.0906, -0.0344, -0.0908]]]])\n",
    "            param['conv2d.bias'] = torch.tensor([-0.0345])\n",
    "            self.conv1.bias = torch.nn.Parameter(param['conv2d.bias'], requires_grad=False)\n",
    "        self.conv1.weight = torch.nn.Parameter(param['conv2d.weight'], requires_grad=False)\n",
    "\n",
    "\n",
    "        self.first_linear = nn.Linear(self.out_channels * square_size ** 2, hidden_size)\n",
    "        hidden_layer = [nn.Linear(hidden_size, hidden_size) for _ in range(num_hidden_layers)]\n",
    "        self.linear_hidden = nn.ModuleList(hidden_layer)\n",
    "        self.linear_output = nn.Linear(hidden_size, 1)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_activation(self.conv1(x))#.view(-1, 1, self.out_channels * self.square_size**2)\n",
    "#         x = self.activation_func(self.first_linear(x))\n",
    "#         for linear in self.linear_hidden:\n",
    "#             x = self.activation_func(linear(x))\n",
    "#         x = torch.sigmoid(self.linear_output(x))\n",
    "#         x = x.squeeze(1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def coarse_grain_frozen_conv(correlated_data = data):\n",
    "    run_mode = \"frozen_convolution_pretrained_relu\"\n",
    "    mode = \"run\"\n",
    "    if mode == \"run\":\n",
    "        hidden_size = 10\n",
    "        out_channels = 1\n",
    "        num_hidden_layers = 1\n",
    "\n",
    "\n",
    "        if run_mode == \"frozen_convolution_pretrained_relu\":\n",
    "            \"\"\"\n",
    "            \"\"\"\n",
    "            run_num = 1\n",
    "            filename = f\"frozen_convolution_pretrained_relu_{run_num}.pl\"\n",
    "            out_channels = 1\n",
    "            try:\n",
    "                with open(filename, \"rb\") as handle:\n",
    "                    results = pickle.load(handle)\n",
    "            except:\n",
    "                results = []\n",
    "            results = []\n",
    "            model = SupervisedConvNet(filter_size = 3, square_size = 27, \\\n",
    "                    hidden_size = hidden_size, out_channels = out_channels,\n",
    "                    center = \"pre_trained\", first_activation = \"tanh\",\n",
    "                    activation_func = \"relu\", num_hidden_layers = num_hidden_layers)\n",
    "            data = torch.tensor(correlated_data).unsqueeze(1).type('torch.FloatTensor')\n",
    "            out = model(data)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = coarse_grain_frozen_conv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0, :10, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[0, 0, :10, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.squeeze(1).numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_uncorrelated_data(data):\n",
    "    # data expects an array of shape [10000, 27, 27]\n",
    "    uncorrelated_data = []\n",
    "    for _ in range(10000):\n",
    "        sample = np.random.randint(0, 10000, (9, 9))\n",
    "        horizontal, vertical = np.random.randint(0, 25, (2, 9, 9))\n",
    "        uncorrelated = []\n",
    "        for i in range(9):\n",
    "            tile = []\n",
    "            for j in range(9):\n",
    "                tile.append(data[sample[i, j], horizontal[i, j]:(horizontal[i, j] + 3), \\\n",
    "                        vertical[i, j]:(vertical[i, j] + 3)])\n",
    "            uncorrelated.append(np.hstack(tile))\n",
    "        uncorrelated_data.append(np.vstack(uncorrelated))\n",
    "\n",
    "    uncorrelated_data = np.array(uncorrelated_data)\n",
    "    return uncorrelated_data\n",
    "\n",
    "uncorrelated_data = generate_uncorrelated_data(out.squeeze(1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncorrelated_data[0, :10, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[0, :10, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alng/Google Drive/Year 4: Synthesis/NS162: Statistical Mechanics/Renormalization Research Project/renormalization/supervised_convnet/t_2.269\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Renormalization",
   "language": "python",
   "name": "renormalization"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
