{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"colab_hyperopt_duplicate_2.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1567748332537,"user_tz":-420,"elapsed":178305,"user":{"displayName":"Huy Nguyen","photoUrl":"","userId":"05352249580863404953"}},"id":"jymXhF9qsym5","outputId":"a216cb88-ad65-4906-9a3d-cec5739c7a7b","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# !kill -9 -1\n","# memory footprint support libraries/code\n","!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip install gputil\n","!pip install psutil\n","!pip install humanize\n","import psutil\n","import humanize\n","import os\n","import GPUtil as GPU\n","GPUs = GPU.getGPUs()\n","# XXX: only one GPU on Colab and isn’t guaranteed\n","gpu = GPUs[0]\n","def printm():\n"," process = psutil.Process(os.getpid())\n"," print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n"," print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","printm()\n","\n","\n","\n","# !pip install -U --target=/usr/local/lib/python3.6/dist-packages git+https://github.com/pytorch/botorch.git\n","\n","# !pip install -U -q torch==1.2.0 torchvision\n","\n","# !pip install -U scikit-learn\n","# !pip install -U --target=/usr/local/lib/python3.6/dist-packages git+https://github.com/anhhuyalex/Ax.git\n","  \n","!pip install -U --target=/usr/local/lib/python3.6/dist-packages git+https://github.com/anhhuyalex/Ax.git\n","  \n","%cd /content\n","# %cd /usr/local/lib/python3.6/dist-packages\n","!rm -rf botorch\n","%cd /content\n","!git clone https://github.com/pytorch/botorch.git\n","%cd botorch\n","!pip install .\n","\n","!pip install sqlalchemy"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting gputil\n","  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n","Building wheels for collected packages: gputil\n","  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7410 sha256=b84982488953997e76d6b7490489d2f323b70d6aa394198073030641682dc792\n","  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n","Successfully built gputil\n","Installing collected packages: gputil\n","Successfully installed gputil-1.4.0\n","Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n","Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n","Gen RAM Free: 12.8 GB  | Proc size: 154.6 MB\n","GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n","Collecting git+https://github.com/anhhuyalex/Ax.git\n","  Cloning https://github.com/anhhuyalex/Ax.git to /tmp/pip-req-build-asddl8np\n","  Running command git clone -q https://github.com/anhhuyalex/Ax.git /tmp/pip-req-build-asddl8np\n","Collecting botorch>=0.1.3 (from ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/94/15177eb5675109ebf63f18047371320dde678648bb5cd5761325c772269f/botorch-0.1.3-py3-none-any.whl (169kB)\n","\u001b[K     |████████████████████████████████| 174kB 3.4MB/s \n","\u001b[?25hCollecting jinja2 (from ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/e7/fd8b501e7a6dfe492a433deb7b9d833d39ca74916fa8bc63dd1a4947a671/Jinja2-2.10.1-py2.py3-none-any.whl (124kB)\n","\u001b[K     |████████████████████████████████| 133kB 41.9MB/s \n","\u001b[?25hCollecting pandas (from ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/9b/52e228545d14f14bb2a1622e225f38463c8726645165e1cb7dde95bfe6d4/pandas-0.25.1-cp36-cp36m-manylinux1_x86_64.whl (10.5MB)\n","\u001b[K     |████████████████████████████████| 10.5MB 26.7MB/s \n","\u001b[?25hCollecting scipy (from ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/50/a552a5aff252ae915f522e44642bb49a7b7b31677f9580cfd11bcc869976/scipy-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (25.2MB)\n","\u001b[K     |████████████████████████████████| 25.2MB 1.5MB/s \n","\u001b[?25hCollecting sklearn (from ax-platform==0.1.4)\n","  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n","Collecting plotly (from ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/19/8437e22c84083a6d5d8a3c80f4edc73c9dcbb89261d07e6bd13b48752bbd/plotly-4.1.1-py2.py3-none-any.whl (7.1MB)\n","\u001b[K     |████████████████████████████████| 7.1MB 34.3MB/s \n","\u001b[?25hCollecting torch>=1.2 (from botorch>=0.1.3->ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/57/d5cceb0799c06733eefce80c395459f28970ebb9e896846ce96ab579a3f1/torch-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (748.8MB)\n","\u001b[K     |████████████████████████████████| 748.9MB 26kB/s \n","\u001b[?25hCollecting gpytorch>=0.3.5 (from botorch>=0.1.3->ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/e4/e74dc12c6d07a5d8628dfb573b01297f7c2b44eec524be4b401c0782d39c/gpytorch-0.3.5.tar.gz (211kB)\n","\u001b[K     |████████████████████████████████| 215kB 34.4MB/s \n","\u001b[?25hCollecting MarkupSafe>=0.23 (from jinja2->ax-platform==0.1.4)\n","  Downloading https://files.pythonhosted.org/packages/b2/5f/23e0023be6bb885d00ffbefad2942bc51a620328ee910f64abe5a8d18dd1/MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl\n","Collecting python-dateutil>=2.6.1 (from pandas->ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n","\u001b[K     |████████████████████████████████| 235kB 52.6MB/s \n","\u001b[?25hCollecting pytz>=2017.2 (from pandas->ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/76/46d697698a143e05f77bec5a526bf4e56a0be61d63425b68f4ba553b51f2/pytz-2019.2-py2.py3-none-any.whl (508kB)\n","\u001b[K     |████████████████████████████████| 512kB 43.7MB/s \n","\u001b[?25hCollecting numpy>=1.13.3 (from pandas->ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/92/57179ed45307ec6179e344231c47da7f3f3da9e2eee5c8ab506bd279ce4e/numpy-1.17.1-cp36-cp36m-manylinux1_x86_64.whl (20.4MB)\n","\u001b[K     |████████████████████████████████| 20.4MB 45.7MB/s \n","\u001b[?25hCollecting scikit-learn (from sklearn->ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/c5/d2238762d780dde84a20b8c761f563fe882b88c5a5fb03c056547c442a19/scikit_learn-0.21.3-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n","\u001b[K     |████████████████████████████████| 6.7MB 23.4MB/s \n","\u001b[?25hCollecting retrying>=1.3.3 (from plotly->ax-platform==0.1.4)\n","  Downloading https://files.pythonhosted.org/packages/44/ef/beae4b4ef80902f22e3af073397f079c96969c69b2c7d52a57ea9ae61c9d/retrying-1.3.3.tar.gz\n","Collecting six (from plotly->ax-platform==0.1.4)\n","  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n","Collecting joblib>=0.11 (from scikit-learn->sklearn->ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl (278kB)\n","\u001b[K     |████████████████████████████████| 286kB 20.0MB/s \n","\u001b[?25hBuilding wheels for collected packages: ax-platform, sklearn, gpytorch, retrying\n","  Building wheel for ax-platform (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ax-platform: filename=ax_platform-0.1.4-cp36-cp36m-linux_x86_64.whl size=918254 sha256=0d52bbc63cd570d0634c548d7acd5061ebab1da2882a4cbcd4f65a71b4d945b8\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-9sy4cgat/wheels/cf/31/a7/531e4606a720574d740203ff00855672549f50a7d1b9bc736e\n","  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=730bf10c28ebb67c836a7ca99b09a5d3273d0946d4037627485fd09fe3064a60\n","  Stored in directory: /root/.cache/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n","  Building wheel for gpytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gpytorch: filename=gpytorch-0.3.5-py2.py3-none-any.whl size=349720 sha256=7775ccda31a2e65c92eac774558380af9f9a5ae46b30d9b18a53160d28203f86\n","  Stored in directory: /root/.cache/pip/wheels/d6/31/88/c43a94e0073a54056ac663366f2195de36535b38a81a378196\n","  Building wheel for retrying (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for retrying: filename=retrying-1.3.3-cp36-none-any.whl size=11429 sha256=04589fef9cc10a4634f5597e311e19d8de47607cf6494efe2718f1881034413c\n","  Stored in directory: /root/.cache/pip/wheels/d7/a9/33/acc7b709e2a35caa7d4cae442f6fe6fbf2c43f80823d46460c\n","Successfully built ax-platform sklearn gpytorch retrying\n","\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=0.24.0, but you'll have pandas 0.25.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: numpy, torch, scipy, gpytorch, botorch, MarkupSafe, jinja2, six, python-dateutil, pytz, pandas, joblib, scikit-learn, sklearn, retrying, plotly, ax-platform\n","Successfully installed MarkupSafe-1.1.1 ax-platform-0.1.4 botorch-0.1.3 gpytorch-0.3.5 jinja2-2.10.1 joblib-0.13.2 numpy-1.17.1 pandas-0.25.1 plotly-4.1.1 python-dateutil-2.8.0 pytz-2019.2 retrying-1.3.3 scikit-learn-0.21.3 scipy-1.3.1 six-1.12.0 sklearn-0.0 torch-1.2.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["dateutil","numpy","pandas","pytz","six"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["/content\n","/content\n","Cloning into 'botorch'...\n","remote: Enumerating objects: 260, done.\u001b[K\n","remote: Counting objects: 100% (260/260), done.\u001b[K\n","remote: Compressing objects: 100% (182/182), done.\u001b[K\n","remote: Total 5956 (delta 105), reused 127 (delta 40), pack-reused 5696\u001b[K\n","Receiving objects: 100% (5956/5956), 10.53 MiB | 19.16 MiB/s, done.\n","Resolving deltas: 100% (3803/3803), done.\n","/content/botorch\n","Processing /content/botorch\n","Requirement already satisfied: torch>=1.2 in /usr/local/lib/python3.6/dist-packages (from botorch==0.1.3) (1.2.0)\n","Requirement already satisfied: gpytorch>=0.3.5 in /usr/local/lib/python3.6/dist-packages (from botorch==0.1.3) (0.3.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from botorch==0.1.3) (1.3.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.2->botorch==0.1.3) (1.17.1)\n","Building wheels for collected packages: botorch\n","  Building wheel for botorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for botorch: filename=botorch-0.1.3-cp36-none-any.whl size=175349 sha256=fd781920d8ad1c43a127af1b091a3b0236d30d4bc1dd3068d3496d4b7c6b8a06\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-rhcf3za8/wheels/d8/0e/3f/502176509633fec729eabc1a42e465b3603faf0c30b4782f33\n","Successfully built botorch\n","Installing collected packages: botorch\n","  Found existing installation: botorch 0.1.3\n","    Uninstalling botorch-0.1.3:\n","      Successfully uninstalled botorch-0.1.3\n","Successfully installed botorch-0.1.3\n","Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.6/dist-packages (1.3.7)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"A_wAj6vUdOya","outputId":"f3f56ce0-175d-4248-99e0-820b7e3981aa","executionInfo":{"status":"ok","timestamp":1567748453173,"user_tz":-420,"elapsed":21428,"user":{"displayName":"Huy Nguyen","photoUrl":"","userId":"05352249580863404953"}},"colab":{"base_uri":"https://localhost:8080/","height":189}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1567748471490,"user_tz":-420,"elapsed":12324,"user":{"displayName":"Huy Nguyen","photoUrl":"","userId":"05352249580863404953"}},"id":"o2AjMK7Oxq4X","outputId":"2aee1847-ebb9-4780-ddd3-053746bcc4fd","colab":{"base_uri":"https://localhost:8080/","height":182}},"source":["%cd /content/\n","!git clone https://github.com/anhhuyalex/renormalization.git\n","!cp /content/drive/My\\ Drive/Year\\ 4\\:\\ Synthesis/NS162\\:\\ Statistical\\ Mechanics/Renormalization\\ Research\\ Project/renormalization/supervised_convnet/t_2.269/3x3/ising81x81_temp2.269_uncorrelated9x9.npy /content/renormalization/supervised_convnet/t_2.269/3x3\n","!cp /content/drive/My\\ Drive/Year\\ 4\\:\\ Synthesis/NS162\\:\\ Statistical\\ Mechanics/Renormalization\\ Research\\ Project/renormalization/supervised_convnet/t_2.269/ising81x81_temp2.269.npy /content/renormalization/supervised_convnet/t_2.269      "],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content\n","Cloning into 'renormalization'...\n","remote: Enumerating objects: 260, done.\u001b[K\n","remote: Counting objects: 100% (260/260), done.\u001b[K\n","remote: Compressing objects: 100% (144/144), done.\u001b[K\n","remote: Total 260 (delta 149), reused 211 (delta 100), pack-reused 0\u001b[K\n","Receiving objects: 100% (260/260), 588.31 KiB | 7.84 MiB/s, done.\n","Resolving deltas: 100% (149/149), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1567748474084,"user_tz":-420,"elapsed":14311,"user":{"displayName":"Huy Nguyen","photoUrl":"","userId":"05352249580863404953"}},"id":"4RQS6gpLaAL3","outputId":"eca2d30d-5b71-4f92-911a-096f683f21cf","colab":{"base_uri":"https://localhost:8080/","height":340}},"source":["%cd /content/renormalization/supervised_convnet/t_2.269/3x3\n","import torch\n","import numpy as np\n","import pickle\n","\n","\n","from ax import RangeParameter, ParameterType\n","from ax.service.ax_client import AxClient\n","from ax.plot.contour import plot_contour\n","from ax.plot.trace import optimization_trace_single_method\n","from ax.service.managed_loop import optimize\n","from ax.utils.notebook.plotting import render, init_notebook_plotting\n","\n","import sys\n","import time\n","sys.path.insert(0, \"../../\")\n","import supervised_convnet\n","import train, frozen\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/renormalization/supervised_convnet/t_2.269/3x3\n","Uncorrelated [[ 1  1  1 -1 -1 -1  1 -1 -1]\n"," [ 1  1  1 -1 -1 -1 -1 -1 -1]\n"," [ 1  1  1 -1  1  1  1  1  1]\n"," [ 1  1 -1  1 -1 -1 -1 -1 -1]\n"," [ 1  1 -1  1 -1 -1 -1 -1 -1]\n"," [ 1  1  1  1 -1 -1 -1 -1  1]\n"," [ 1  1 -1 -1 -1 -1  1  1  1]\n"," [ 1 -1 -1 -1 -1 -1  1  1  1]\n"," [ 1  1  1 -1 -1 -1  1  1 -1]]\n","Correlated [[ 1  1 -1  1 -1 -1 -1 -1  1]\n"," [ 1  1 -1 -1 -1 -1 -1 -1 -1]\n"," [ 1  1 -1 -1 -1  1  1  1  1]\n"," [-1 -1 -1 -1 -1 -1  1  1  1]\n"," [ 1 -1 -1 -1 -1  1  1  1  1]\n"," [-1 -1 -1 -1 -1  1  1  1  1]\n"," [-1 -1 -1 -1 -1  1  1 -1 -1]\n"," [-1 -1 -1 -1 -1 -1  1  1  1]\n"," [-1 -1  1 -1 -1 -1 -1 -1  1]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1xWt_dQhaDc6","colab":{}},"source":["# Parameters\n","num_hidden_layers = 1\n","out_channels = 1\n","num_workers = 15\n","run_mode = \"frozen_convolution_pretrained_relu\" # sys.argv[1]\n","n_loops = 3000\n","save_loop = min(n_loops, 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Cup0cjvgaYfJ","colab":{}},"source":["def init_model_and_train(hidden_size, batch_size, train_size, n_epochs, lr, weight_decay,\n","            betas0, betas1, seed):\n","    # Parameters\n","    num_hidden_layers = 1\n","    out_channels = 1\n","\n","\n","    if run_mode == \"unfrozen_convolution_relu\":\n","        model = supervised_convnet.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","                hidden_size = hidden_size, out_channels = out_channels,\n","                first_activation = \"tanh\", activation_func = \"relu\",\n","                num_hidden_layers = num_hidden_layers, seed = seed)\n","        results = train.trainer(model = model, batch_size = batch_size, train_size = train_size, n_epochs = n_epochs, lr = lr,\n","                    weight_decay = weight_decay,\n","                    betas0 = 1-betas0, betas1 = 1-betas1)\n","    elif run_mode == \"frozen_convolution_no_center_relu\":\n","        model = frozen.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","                hidden_size = hidden_size, out_channels = out_channels,\n","                center = \"omit\", first_activation = \"tanh\",\n","                activation_func = \"relu\", num_hidden_layers = num_hidden_layers)\n","        results = train.trainer(model = model, batch_size = batch_size, train_size = train_size, n_epochs = n_epochs, lr = lr,\n","                    weight_decay = weight_decay,\n","                    betas0 = 1-betas0, betas1 = 1-betas1)\n","    elif run_mode == \"frozen_convolution_pretrained_relu\":\n","        model = frozen.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","                hidden_size = hidden_size, out_channels = out_channels,\n","                center = \"pre_trained\", first_activation = \"tanh\",\n","                activation_func = \"relu\", num_hidden_layers = num_hidden_layers)\n","        results = train.trainer(model = model, batch_size = batch_size, train_size = train_size, n_epochs = n_epochs, lr = lr,\n","                    weight_decay = weight_decay,\n","                    betas0 = 1-betas0, betas1 = 1-betas1)\n","    elif run_mode == \"unfrozen_convolution_2_channels\":\n","        out_channels = 2\n","        model = supervised_convnet.SupervisedConvNet(filter_size = 3, square_size = 3,\n","                hidden_size = hidden_size, out_channels = out_channels,\n","                first_activation = \"tanh\", activation_func = \"relu\",\n","                num_hidden_layers = num_hidden_layers, seed = seed)\n","        results = train.trainer(model = model, batch_size = batch_size, train_size = train_size, n_epochs = n_epochs, lr = lr,\n","                    weight_decay = weight_decay,\n","                    betas0 = 1-betas0, betas1 = 1-betas1)\n","    return (results[0])\n","\n","\n","\n","def train_evaluate(parameterization):\n","    # parameters\n","    batch_size = parameterization[\"batch_size\"]\n","    train_size = parameterization[\"train_size\"]\n","    n_epochs = parameterization[\"n_epochs\"]\n","    lr = parameterization[\"lr\"]\n","    weight_decay = parameterization[\"weight_decay\"]\n","    betas0 = parameterization[\"betas0\"]\n","    betas1 = parameterization[\"betas1\"]\n","    hidden_size = 10\n","\n","    results = []\n","    for seed in range(num_workers):\n","        results.append(init_model_and_train(hidden_size, batch_size, train_size,\n","        n_epochs, lr, weight_decay, betas0, betas1,\n","        time.time() + seed))\n","\n","    print (\"results\", results)\n","    mean = np.mean(results)\n","    SEM = np.std(results)/np.sqrt(num_workers)\n","    # pool.close() # no more tasks\n","    # pool.join()  # wrap up current tasks\n","    return {\"objective\": (mean, SEM)}\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BGvXFlryTeko","colab_type":"code","colab":{}},"source":["%%capture\n","\n","# Initialize client\n","ax_client = AxClient()\n","try:\n","    with open(f\"/content/drive/My Drive/Year 4: Synthesis/NS162: Statistical Mechanics/Renormalization Research Project/renormalization/supervised_convnet/t_2.269/3x3/colab/hyperparameters_{run_mode}.pl\", \"rb\") as handle:\n","        hyper = pickle.load(handle)\n","    v = hyper[\"axclient\"].copy()\n","    ax_client = ax_client.from_json_snapshot(v)\n","except:\n","    ax_client.create_experiment(\n","        parameters=[\n","            {\n","              \"name\": \"batch_size\",\n","              \"type\": \"range\",\n","              \"bounds\": [1, 5000],\n","              \"value_type\": \"int\"\n","            },\n","            {\n","              \"name\": \"train_size\",\n","              \"type\": \"range\",\n","              \"bounds\": [100, 5000],\n","              \"value_type\": \"int\"\n","            },\n","            {\n","              \"name\": \"n_epochs\",\n","              \"type\": \"range\",\n","              \"bounds\": [50, 250],\n","              \"value_type\": \"int\"\n","            },\n","            {\n","              \"name\": \"lr\",\n","              \"type\": \"range\",\n","              \"bounds\": [1e-4, 1],\n","              \"value_type\": \"float\",\n","              \"log_scale\": True\n","            },\n","            {\n","              \"name\": \"weight_decay\",\n","              \"type\": \"range\",\n","              \"bounds\": [1e-5, 2e-1],\n","              \"value_type\": \"float\",\n","              \"log_scale\": True\n","            },\n","            {\n","              \"name\": \"betas0\",\n","              \"type\": \"range\",\n","              \"bounds\": [1e-5, 2e-1],\n","              \"value_type\": \"float\",\n","              \"log_scale\": True\n","            },\n","            {\n","              \"name\": \"betas1\",\n","              \"type\": \"range\",\n","              \"bounds\": [1e-5, 2e-1],\n","              \"value_type\": \"float\",\n","              \"log_scale\": True\n","            }\n","        ],\n","        parameter_constraints=[\"0.02 * train_size + -1 * batch_size <= 0\", \"train_size >= batch_size\"],\n","        minimize=False,\n","        objective_name=\"objective\",\n","        outcome_constraints=None,\n","        name=\"Test\"\n","    )\n","\n","# print (\"axclient\",ax_client.experiment.trials )\n","# for loop in range(n_loops):\n","for loop in range(n_loops):\n","    print(f\"Running trial {loop}/{n_loops}...\")\n","    parameters, trial_index = ax_client.get_next_trial()\n","    print(\"trial_index\", trial_index)\n","    time.sleep(2)\n","#     parameters[\"n_epochs\"] = 5\n","     # Local evaluation here can be replaced with deployment to external system.\n","    ax_client.complete_trial(trial_index=trial_index, raw_data=train_evaluate(parameters))\n","    print(\"Best params\", ax_client.get_best_parameters())\n","    # periodic save\n","    if loop % save_loop == (save_loop - 1):\n","        optim_result = ax_client.get_best_parameters()\n","        # print(\"best_parameters\", optim_result)\n","        # print(\"was I saved?\", ax._save_experiment_and_generation_strategy_if_possible())\n","        hyper = {}\n","        hyper[\"best_params\"] = optim_result\n","        hyper[\"axclient\"] = ax_client.to_json_snapshot()\n","        # print(\"optim_result\", optim_result)\n","        with open(f\"/content/drive/My Drive/Year 4: Synthesis/NS162: Statistical Mechanics/Renormalization Research Project/renormalization/supervised_convnet/t_2.269/3x3/colab/hyperparameters_{run_mode}.pl\", \"wb\") as handle:\n","            pickle.dump(hyper, handle, protocol = pickle.HIGHEST_PROTOCOL)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MYCqR9pTT21U","colab_type":"code","colab":{}},"source":["i = 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n2avIIuQlH5h","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}