{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hyperopt.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"g_engCTw8fpd","colab_type":"code","outputId":"c138e809-da5d-4777-f65c-9761f551afbe","executionInfo":{"status":"ok","timestamp":1567671399002,"user_tz":-420,"elapsed":142561,"user":{"displayName":"Huy Nguyen","photoUrl":"","userId":"05352249580863404953"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# \n","\n","# !pip install -U --target=/usr/local/lib/python3.6/dist-packages git+https://github.com/pytorch/botorch.git\n","\n","# !pip install -U -q torch==1.2.0 torchvision\n","\n","# !pip install -U scikit-learn\n","# !pip install -U --target=/usr/local/lib/python3.6/dist-packages git+https://github.com/anhhuyalex/Ax.git\n","  \n","!pip install -U --target=/usr/local/lib/python3.6/dist-packages git+https://github.com/anhhuyalex/Ax.git\n","  \n","%cd /content\n","# %cd /usr/local/lib/python3.6/dist-packages\n","!rm -rf botorch\n","%cd /content\n","!git clone https://github.com/pytorch/botorch.git\n","%cd botorch\n","!pip install .\n","\n","!pip install sqlalchemy"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/anhhuyalex/Ax.git\n","  Cloning https://github.com/anhhuyalex/Ax.git to /tmp/pip-req-build-keur6kd_\n","  Running command git clone -q https://github.com/anhhuyalex/Ax.git /tmp/pip-req-build-keur6kd_\n","Collecting botorch>=0.1.3 (from ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/94/15177eb5675109ebf63f18047371320dde678648bb5cd5761325c772269f/botorch-0.1.3-py3-none-any.whl (169kB)\n","\u001b[K     |████████████████████████████████| 174kB 8.1MB/s \n","\u001b[?25hCollecting jinja2 (from ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/e7/fd8b501e7a6dfe492a433deb7b9d833d39ca74916fa8bc63dd1a4947a671/Jinja2-2.10.1-py2.py3-none-any.whl (124kB)\n","\u001b[K     |████████████████████████████████| 133kB 59.1MB/s \n","\u001b[?25hCollecting pandas (from ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/9b/52e228545d14f14bb2a1622e225f38463c8726645165e1cb7dde95bfe6d4/pandas-0.25.1-cp36-cp36m-manylinux1_x86_64.whl (10.5MB)\n","\u001b[K     |████████████████████████████████| 10.5MB 72.5MB/s \n","\u001b[?25hCollecting scipy (from ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/50/a552a5aff252ae915f522e44642bb49a7b7b31677f9580cfd11bcc869976/scipy-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (25.2MB)\n","\u001b[K     |████████████████████████████████| 25.2MB 47.7MB/s \n","\u001b[?25hCollecting sklearn (from ax-platform==0.1.4)\n","  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n","Collecting plotly (from ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/19/8437e22c84083a6d5d8a3c80f4edc73c9dcbb89261d07e6bd13b48752bbd/plotly-4.1.1-py2.py3-none-any.whl (7.1MB)\n","\u001b[K     |████████████████████████████████| 7.1MB 47.6MB/s \n","\u001b[?25hCollecting gpytorch>=0.3.5 (from botorch>=0.1.3->ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/e4/e74dc12c6d07a5d8628dfb573b01297f7c2b44eec524be4b401c0782d39c/gpytorch-0.3.5.tar.gz (211kB)\n","\u001b[K     |████████████████████████████████| 215kB 52.1MB/s \n","\u001b[?25hCollecting torch>=1.2 (from botorch>=0.1.3->ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/57/d5cceb0799c06733eefce80c395459f28970ebb9e896846ce96ab579a3f1/torch-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (748.8MB)\n","\u001b[K     |████████████████████████████████| 748.9MB 29kB/s \n","\u001b[?25hCollecting MarkupSafe>=0.23 (from jinja2->ax-platform==0.1.4)\n","  Downloading https://files.pythonhosted.org/packages/b2/5f/23e0023be6bb885d00ffbefad2942bc51a620328ee910f64abe5a8d18dd1/MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl\n","Collecting numpy>=1.13.3 (from pandas->ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/92/57179ed45307ec6179e344231c47da7f3f3da9e2eee5c8ab506bd279ce4e/numpy-1.17.1-cp36-cp36m-manylinux1_x86_64.whl (20.4MB)\n","\u001b[K     |████████████████████████████████| 20.4MB 42.9MB/s \n","\u001b[?25hCollecting python-dateutil>=2.6.1 (from pandas->ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n","\u001b[K     |████████████████████████████████| 235kB 64.7MB/s \n","\u001b[?25hCollecting pytz>=2017.2 (from pandas->ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/76/46d697698a143e05f77bec5a526bf4e56a0be61d63425b68f4ba553b51f2/pytz-2019.2-py2.py3-none-any.whl (508kB)\n","\u001b[K     |████████████████████████████████| 512kB 58.5MB/s \n","\u001b[?25hCollecting scikit-learn (from sklearn->ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/c5/d2238762d780dde84a20b8c761f563fe882b88c5a5fb03c056547c442a19/scikit_learn-0.21.3-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n","\u001b[K     |████████████████████████████████| 6.7MB 26.5MB/s \n","\u001b[?25hCollecting six (from plotly->ax-platform==0.1.4)\n","  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n","Collecting retrying>=1.3.3 (from plotly->ax-platform==0.1.4)\n","  Downloading https://files.pythonhosted.org/packages/44/ef/beae4b4ef80902f22e3af073397f079c96969c69b2c7d52a57ea9ae61c9d/retrying-1.3.3.tar.gz\n","Collecting joblib>=0.11 (from scikit-learn->sklearn->ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl (278kB)\n","\u001b[K     |████████████████████████████████| 286kB 43.7MB/s \n","\u001b[?25hBuilding wheels for collected packages: ax-platform, sklearn, gpytorch, retrying\n","  Building wheel for ax-platform (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ax-platform: filename=ax_platform-0.1.4-cp36-cp36m-linux_x86_64.whl size=918248 sha256=02f3d8a48adefbc52dd6118e1849605126377d94b6d2f33f6cb8c4d2fe43c656\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-e7ajb2yl/wheels/cf/31/a7/531e4606a720574d740203ff00855672549f50a7d1b9bc736e\n","  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=809d9ea168b714527e9a24db0a64934e461ae0346ce1b3afd644a9cb84ce3780\n","  Stored in directory: /root/.cache/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n","  Building wheel for gpytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gpytorch: filename=gpytorch-0.3.5-py2.py3-none-any.whl size=349720 sha256=90fe3f3284d9bcda59face774c2ecc96158fa7934dc47eac27813d8528cbbaff\n","  Stored in directory: /root/.cache/pip/wheels/d6/31/88/c43a94e0073a54056ac663366f2195de36535b38a81a378196\n","  Building wheel for retrying (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for retrying: filename=retrying-1.3.3-cp36-none-any.whl size=11429 sha256=f23ca1654f5e0b456d9a7da13031c13a5255a7afbfb23037660ca07ec0b70c5f\n","  Stored in directory: /root/.cache/pip/wheels/d7/a9/33/acc7b709e2a35caa7d4cae442f6fe6fbf2c43f80823d46460c\n","Successfully built ax-platform sklearn gpytorch retrying\n","\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=0.24.0, but you'll have pandas 0.25.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: gpytorch, numpy, scipy, torch, botorch, MarkupSafe, jinja2, six, python-dateutil, pytz, pandas, joblib, scikit-learn, sklearn, retrying, plotly, ax-platform\n","Successfully installed MarkupSafe-1.1.1 ax-platform-0.1.4 botorch-0.1.3 gpytorch-0.3.5 jinja2-2.10.1 joblib-0.13.2 numpy-1.17.1 pandas-0.25.1 plotly-4.1.1 python-dateutil-2.8.0 pytz-2019.2 retrying-1.3.3 scikit-learn-0.21.3 scipy-1.3.1 six-1.12.0 sklearn-0.0 torch-1.2.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["dateutil","numpy","pandas","pytz","six"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["/content\n","/content\n","Cloning into 'botorch'...\n","remote: Enumerating objects: 253, done.\u001b[K\n","remote: Counting objects: 100% (253/253), done.\u001b[K\n","remote: Compressing objects: 100% (176/176), done.\u001b[K\n","remote: Total 5949 (delta 100), reused 124 (delta 39), pack-reused 5696\u001b[K\n","Receiving objects: 100% (5949/5949), 10.53 MiB | 13.33 MiB/s, done.\n","Resolving deltas: 100% (3798/3798), done.\n","/content/botorch\n","Processing /content/botorch\n","Requirement already satisfied: torch>=1.2 in /usr/local/lib/python3.6/dist-packages (from botorch==0.1.3) (1.2.0)\n","Requirement already satisfied: gpytorch>=0.3.5 in /usr/local/lib/python3.6/dist-packages (from botorch==0.1.3) (0.3.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from botorch==0.1.3) (1.3.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.2->botorch==0.1.3) (1.17.1)\n","Building wheels for collected packages: botorch\n","  Building wheel for botorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for botorch: filename=botorch-0.1.3-cp36-none-any.whl size=175135 sha256=ac1bd503f067b35a867aecd72a2f4c9070f96f40eaa3c53f2c2653b1fbe4b9c8\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-0wi824vx/wheels/d8/0e/3f/502176509633fec729eabc1a42e465b3603faf0c30b4782f33\n","Successfully built botorch\n","Installing collected packages: botorch\n","  Found existing installation: botorch 0.1.3\n","    Uninstalling botorch-0.1.3:\n","      Successfully uninstalled botorch-0.1.3\n","Successfully installed botorch-0.1.3\n","Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.6/dist-packages (1.3.7)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kMpk4RwwlC4x","colab_type":"code","outputId":"da8fdbcc-4f39-4ed0-ae59-f321f4bc8d90","executionInfo":{"status":"ok","timestamp":1567052391396,"user_tz":-420,"elapsed":101538,"user":{"displayName":"Huy Nguyen","photoUrl":"","userId":"05352249580863404953"}},"colab":{"base_uri":"https://localhost:8080/","height":463}},"source":[""],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/pytorch/botorch.git\n","  Cloning https://github.com/pytorch/botorch.git to /tmp/pip-req-build-9kwtgry5\n","  Running command git clone -q https://github.com/pytorch/botorch.git /tmp/pip-req-build-9kwtgry5\n","Collecting torch>=1.2 (from botorch==0.1.3)\n","  Using cached https://files.pythonhosted.org/packages/30/57/d5cceb0799c06733eefce80c395459f28970ebb9e896846ce96ab579a3f1/torch-1.2.0-cp36-cp36m-manylinux1_x86_64.whl\n","Collecting gpytorch>=0.3.5 (from botorch==0.1.3)\n","Collecting scipy (from botorch==0.1.3)\n","  Using cached https://files.pythonhosted.org/packages/29/50/a552a5aff252ae915f522e44642bb49a7b7b31677f9580cfd11bcc869976/scipy-1.3.1-cp36-cp36m-manylinux1_x86_64.whl\n","Collecting numpy (from torch>=1.2->botorch==0.1.3)\n","  Using cached https://files.pythonhosted.org/packages/75/92/57179ed45307ec6179e344231c47da7f3f3da9e2eee5c8ab506bd279ce4e/numpy-1.17.1-cp36-cp36m-manylinux1_x86_64.whl\n","Building wheels for collected packages: botorch\n","  Building wheel for botorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for botorch: filename=botorch-0.1.3-cp36-none-any.whl size=175126 sha256=154fde2c7ac78b7be391d0b23e120d695155142afdc5c7a9e7b725be7ad598f5\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-my6avjjg/wheels/82/70/31/16688bea51fa7ff1a0100a484854a6c2a9663fde3055aa478a\n","Successfully built botorch\n","\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=0.24.0, but you'll have pandas 0.25.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: numpy, torch, gpytorch, scipy, botorch\n","Successfully installed botorch-0.1.3 gpytorch-0.3.5 numpy-1.17.1 scipy-1.3.1 torch-1.2.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"uJuszQGG_m1D","colab_type":"code","colab":{}},"source":["\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lIKufxcqJZzf","colab_type":"code","outputId":"ba537c8c-83b1-4c41-cf8e-8351b1ef3cdd","executionInfo":{"status":"ok","timestamp":1567142472007,"user_tz":-420,"elapsed":26298,"user":{"displayName":"Huy Nguyen","photoUrl":"","userId":"05352249580863404953"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["%cd /content/\n","!git clone https://github.com/anhhuyalex/renormalization.git\n","!cp /content/drive/My\\ Drive/Year\\ 4\\:\\ Synthesis/NS162\\:\\ Statistical\\ Mechanics/Renormalization\\ Research\\ Project/renormalization/supervised_convnet/t_2.269/3x3/ising81x81_temp2.269_uncorrelated9x9.npy /content/renormalization/supervised_convnet/t_2.269/3x3\n","!cp /content/drive/My\\ Drive/Year\\ 4\\:\\ Synthesis/NS162\\:\\ Statistical\\ Mechanics/Renormalization\\ Research\\ Project/renormalization/supervised_convnet/t_2.269/ising81x81_temp2.269.npy /content/renormalization/supervised_convnet/t_2.269      "],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content\n","Cloning into 'renormalization'...\n","remote: Enumerating objects: 236, done.\u001b[K\n","remote: Counting objects: 100% (236/236), done.\u001b[K\n","remote: Compressing objects: 100% (135/135), done.\u001b[K\n","remote: Total 236 (delta 131), reused 190 (delta 85), pack-reused 0\u001b[K\n","Receiving objects: 100% (236/236), 546.02 KiB | 583.00 KiB/s, done.\n","Resolving deltas: 100% (131/131), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NU7OJp_nAbkW","colab_type":"code","outputId":"49c5d6fd-4862-4bb0-8b65-f459035fef54","executionInfo":{"status":"ok","timestamp":1567142477451,"user_tz":-420,"elapsed":3303,"user":{"displayName":"Huy Nguyen","photoUrl":"","userId":"05352249580863404953"}},"colab":{"base_uri":"https://localhost:8080/","height":340}},"source":["%cd /content/renormalization/supervised_convnet/t_2.269/3x3\n","import torch\n","import numpy as np\n","import pickle\n","import multiprocessing as mp\n","\n","from ax import RangeParameter, ParameterType\n","from ax.service.ax_client import AxClient\n","from ax.plot.contour import plot_contour\n","from ax.plot.trace import optimization_trace_single_method\n","from ax.service.managed_loop import optimize\n","from ax.utils.notebook.plotting import render, init_notebook_plotting\n","\n","import sys\n","import time\n","sys.path.insert(0, \"../../\")\n","import supervised_convnet\n","import train, frozen"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/renormalization/supervised_convnet/t_2.269/3x3\n","Uncorrelated [[ 1  1  1 -1 -1 -1  1 -1 -1]\n"," [ 1  1  1 -1 -1 -1 -1 -1 -1]\n"," [ 1  1  1 -1  1  1  1  1  1]\n"," [ 1  1 -1  1 -1 -1 -1 -1 -1]\n"," [ 1  1 -1  1 -1 -1 -1 -1 -1]\n"," [ 1  1  1  1 -1 -1 -1 -1  1]\n"," [ 1  1 -1 -1 -1 -1  1  1  1]\n"," [ 1 -1 -1 -1 -1 -1  1  1  1]\n"," [ 1  1  1 -1 -1 -1  1  1 -1]]\n","Correlated [[ 1  1 -1  1 -1 -1 -1 -1  1]\n"," [ 1  1 -1 -1 -1 -1 -1 -1 -1]\n"," [ 1  1 -1 -1 -1  1  1  1  1]\n"," [-1 -1 -1 -1 -1 -1  1  1  1]\n"," [ 1 -1 -1 -1 -1  1  1  1  1]\n"," [-1 -1 -1 -1 -1  1  1  1  1]\n"," [-1 -1 -1 -1 -1  1  1 -1 -1]\n"," [-1 -1 -1 -1 -1 -1  1  1  1]\n"," [-1 -1  1 -1 -1 -1 -1 -1  1]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SbOqeR18C56q","colab_type":"code","colab":{}},"source":["# Parameters\n","num_hidden_layers = 1\n","out_channels = 1\n","weight = 0.02\n","num_workers = 4\n","\n","# Initialize client\n","ax = AxClient()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yH3jfmeHU625","colab_type":"code","outputId":"66204c39-1771-4c87-a20c-73f124c8fe1f","executionInfo":{"status":"ok","timestamp":1567142534741,"user_tz":-420,"elapsed":1650,"user":{"displayName":"Huy Nguyen","photoUrl":"","userId":"05352249580863404953"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["def init_model_and_train(hidden_size, batch_size, train_size, n_epochs, lr, weight_decay,\n","            betas0, betas1, seed, output):\n","    model = supervised_convnet.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","            hidden_size = hidden_size, out_channels = out_channels,\n","            first_activation = \"tanh\", activation_func = \"relu\",\n","            num_hidden_layers = num_hidden_layers, seed = seed)\n","    results = train.trainer(model = model, batch_size = batch_size, train_size = train_size, n_epochs = n_epochs, lr = lr,\n","                weight_decay = weight_decay,\n","                betas0 = 1-betas0, betas1 = 1-betas1)\n","    output.put(results)\n","\n","def start_process():\n","    print ('Starting', mp.current_process().name)\n","\n","# def train_evaluate(parameterization):\n","#     # parameters\n","#     batch_size = parameterization[\"batch_size\"]\n","#     train_size = parameterization[\"train_size\"]\n","#     n_epochs = parameterization[\"n_epochs\"]\n","#     lr = parameterization[\"lr\"]\n","#     weight_decay = parameterization[\"weight_decay\"]\n","#     betas0 = parameterization[\"betas0\"]\n","#     betas1 = parameterization[\"betas1\"]\n","#     hidden_size = 10\n","#\n","#\n","#     output = []\n","#     with mp.Pool(processes=num_workers, initializer=start_process) as pool:\n","#     # accuracy = train.trainer(model = model, batch_size = batch_size, train_size = train_size, n_epochs = n_epochs, lr = lr,\n","#     #             weight_decay = weight_decay,\n","#     #             betas0 = 1-betas0, betas1 = 0.99)[0]\n","#     # results = [pool.apply(train.trainer, {\"model\" : model, \"batch_size\" : batch_size,\n","#     #             \"train_size\" : train_size, \"n_epochs\" : n_epochs, \"lr\" : lr,\n","#     #             \"weight_decay\" : weight_decay,\n","#     #             \"betas0\" : 1-betas0, \"betas1\" : 0.99}) for x in range(5)]\n","#         iterable = [(hidden_size, batch_size, train_size,\n","#                     n_epochs, lr, weight_decay, betas0, betas1, time.time() + seed) for seed in range(num_workers)]\n","#         print(\"iterable\", iterable)\n","#         output = pool.starmap(init_model_and_train, iterable)\n","#     pool.join()\n","#     output = [result[0] for result in output]\n","#     print(output)\n","#     mean = np.mean(output)\n","#     SEM = np.std(output)/np.sqrt(4)\n","#     # pool.close() # no more tasks\n","#     # pool.join()  # wrap up current tasks\n","#     return mean, SEM\n","\n","\n","def train_evaluate(parameterization):\n","    # parameters\n","    batch_size = parameterization[\"batch_size\"]\n","    train_size = parameterization[\"train_size\"]\n","    n_epochs = parameterization[\"n_epochs\"]\n","    lr = parameterization[\"lr\"]\n","    weight_decay = parameterization[\"weight_decay\"]\n","    betas0 = parameterization[\"betas0\"]\n","    betas1 = parameterization[\"betas1\"]\n","    hidden_size = 10\n","\n","    # Define an output queue\n","    output = mp.Queue()\n","\n","    # Setup a list of processes that we want to run\n","    processes = [mp.Process(target=init_model_and_train, args=(\n","                    hidden_size, batch_size, train_size,\n","                    n_epochs, lr, weight_decay, betas0, betas1,\n","                    time.time() + seed, output\n","                )) for seed in range(num_workers)]\n","\n","    # Run processes\n","    for p in processes:\n","        p.start()\n","\n","    # Exit the completed processes\n","    for p in processes:\n","        p.join()\n","\n","    # Get process results from the output queue\n","    results = [output.get() for p in processes]\n","    results = [res[0] for res in results]\n","    mean = np.mean(results)\n","    SEM = np.std(results)/np.sqrt(4)\n","    # pool.close() # no more tasks\n","    # pool.join()  # wrap up current tasks\n","    return mean, SEM\n","\n","\n","ax.create_experiment(\n","    parameters=[\n","        {\n","          \"name\": \"batch_size\",\n","          \"type\": \"range\",\n","          \"bounds\": [1, 5000],\n","          \"value_type\": \"int\"\n","        },\n","        {\n","          \"name\": \"train_size\",\n","          \"type\": \"range\",\n","          \"bounds\": [100, 5000],\n","          \"value_type\": \"int\"\n","        },\n","        {\n","          \"name\": \"n_epochs\",\n","          \"type\": \"range\",\n","          \"bounds\": [50, 250],\n","          \"value_type\": \"int\"\n","        },\n","        {\n","          \"name\": \"lr\",\n","          \"type\": \"range\",\n","          \"bounds\": [1e-4, 1],\n","          \"value_type\": \"float\",\n","          \"log_scale\": True\n","        },\n","        {\n","          \"name\": \"weight_decay\",\n","          \"type\": \"range\",\n","          \"bounds\": [1e-5, 2e-1],\n","          \"value_type\": \"float\",\n","          \"log_scale\": True\n","        },\n","        {\n","          \"name\": \"betas0\",\n","          \"type\": \"range\",\n","          \"bounds\": [1e-5, 2e-1],\n","          \"value_type\": \"float\",\n","          \"log_scale\": True\n","        },\n","        {\n","          \"name\": \"betas1\",\n","          \"type\": \"range\",\n","          \"bounds\": [1e-5, 2e-1],\n","          \"value_type\": \"float\",\n","          \"log_scale\": True\n","        }\n","    ],\n","    parameter_constraints=[\"0.02 * n_epochs + -1 * batch_size <= 0\"],\n","    minimize=False,\n","    outcome_constraints=None,\n","    name=\"Test\"\n",")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[INFO 08-30 05:22:13] ax.service.utils.dispatch: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+GPEI', steps=[Sobol for 7 arms, GPEI for subsequent arms], generated 0 arm(s) so far). Iterations after 7 will take longer to generate due to model-fitting.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"QaA_x4e0VhwV","colab_type":"code","outputId":"a727a69b-f2a8-40e7-b284-aca847ad27ac","executionInfo":{"status":"error","timestamp":1567138711295,"user_tz":-420,"elapsed":74344,"user":{"displayName":"Huy Nguyen","photoUrl":"","userId":"05352249580863404953"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["for i in range(1):\n","    print(f\"Running trial {i+1}/30...\")\n","    parameters, trial_index = ax.get_next_trial()\n","    print(parameters)\n","     # Local evaluation here can be replaced with deployment to external system.\n","#     ax.complete_trial(trial_index=trial_index, raw_data=train_evaluate(parameters))\n","train_evaluate(parameters)\n","# best_parameters, values = ax.get_best_parameters()\n","# print(\"best_parameters\", best_parameters)\n","\n","# with open(\"hyperparameters.pl\", \"wb\") as handle:\n","#     pickle.dump(optim_result, handle, protocol = pickle.HIGHEST_PROTOCOL)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Running trial 1/30...\n","{'batch_size': 1356, 'train_size': 4860, 'n_epochs': 238, 'lr': 0.905589446280529, 'weight_decay': 0.1603220224791051, 'betas0': 0.0003864157009784237, 'betas1': 0.003227154379380984}\n","Testing out: \n","batch_size:  1356\n","train_size:  4860\n","Testing out: \n","n_epochs:  238\n","lr:  0.905589446280529\n","batch_size:  1356\n","train_size:  4860\n","Testing out: \n","weight_decay:  0.1603220224791051\n","Testing out: \n","batch_size:  1356\n","betas0:  0.9996135842990216\n","n_epochs:  238\n","betas1:  0.996772845620619\n","lr:  0.905589446280529\n","weight_decay:  0.1603220224791051\n","hidden_size:  10\n","betas0:  0.9996135842990216\n","betas1:  0.996772845620619\n","hidden_size:  10\n","batch_size:  1356\n","conv1.weight tensor([[[[ 0.2455, -0.0727,  0.2083],\n","          [ 0.0231, -0.0938,  0.1609],\n","          [-0.2284, -0.0532, -0.2396]]]])train_size:  4860\n","train_size:  4860\n","n_epochs:  238\n","lr:  0.905589446280529\n","weight_decay:  0.1603220224791051\n","betas0:  0.9996135842990216\n","betas1:  0.996772845620619\n","conv1.weight tensor([[[[-0.2317, -0.0256,  0.2961],\n","          [ 0.0630,  0.1497, -0.1804],\n","          [ 0.2130, -0.2214,  0.2906]]]])hidden_size:  10\n","\n","conv1.bias tensor([0.1454])\n","n_epochs:  238\n","first_linear.weight tensor([[ 0.3222,  0.0556, -0.2167, -0.0004,  0.0787, -0.0126,  0.0310,  0.1580,\n","         -0.3032],\n","        [ 0.2365,  0.2365, -0.2191,  0.0580,  0.1408, -0.0695, -0.2275,  0.0130,\n","          0.0935],\n","        [ 0.0384, -0.2609,  0.2830,  0.0465,  0.3140, -0.3240, -0.2456, -0.2352,\n","          0.0198],\n","        [-0.0995, -0.2527,  0.2861,  0.0902, -0.0012,  0.1527, -0.1881, -0.1069,\n","          0.1725],\n","        [ 0.0815,  0.3125,  0.2816,  0.1281,  0.3272,  0.2967,  0.3024, -0.0952,\n","         -0.0669],\n","        [ 0.2952, -0.0301, -0.2875, -0.2735, -0.2366,  0.1395,  0.0758,  0.0054,\n","         -0.0160],\n","        [-0.1149, -0.1748, -0.1855, -0.2897,  0.1924,  0.1466, -0.2958,  0.1188,\n","         -0.2582],\n","        [-0.2806,  0.1780,  0.1583, -0.0878, -0.2006, -0.3253,  0.2148,  0.0499,\n","         -0.2626],\n","        [ 0.2993, -0.1504,  0.3261, -0.2308, -0.0700,  0.1507, -0.0401, -0.0600,\n","          0.1297],\n","        [ 0.1824, -0.1982, -0.0370,  0.2807,  0.1241, -0.2408, -0.1246, -0.0623,\n","          0.1982]])conv1.weight tensor([[[[ 0.1347, -0.1360, -0.2159],\n","          [ 0.0571,  0.0051, -0.0972],\n","          [ 0.2609, -0.1563,  0.3105]]]])\n","\n","conv1.bias tensor([0.1271])\n","conv1.bias tensor([0.0238])\n","first_linear.weight tensor([[ 0.1905, -0.1745, -0.0642,  0.1982, -0.1128,  0.2854, -0.1589,  0.0167,\n","          0.2506],\n","        [ 0.1599, -0.1734,  0.1162, -0.2913, -0.3062, -0.1534, -0.1186, -0.3296,\n","         -0.2227],\n","        [ 0.0992,  0.2668, -0.1616,  0.2757, -0.0941,  0.2528, -0.2155,  0.0508,\n","          0.0575],\n","        [-0.2151, -0.0191, -0.0737, -0.2281,  0.1828,  0.0272,  0.0807,  0.0839,\n","         -0.3289],\n","        [ 0.1988, -0.1399,  0.2951, -0.3144,  0.2982,  0.2263,  0.2672, -0.3234,\n","          0.1221],\n","        [-0.2065, -0.0990, -0.1010,  0.1136,  0.0666, -0.2244, -0.2560, -0.1591,\n","         -0.3144],\n","        [-0.0620, -0.2064,  0.1012,  0.0219,  0.3199,  0.0951, -0.2300, -0.2330,\n","          0.2426],\n","        [-0.2380, -0.2956, -0.1703, -0.2995, -0.1393,  0.0141, -0.1598, -0.1307,\n","          0.1151],\n","        [ 0.2995, -0.0650,  0.0612,  0.3135,  0.2086,  0.0874, -0.2593,  0.0030,\n","         -0.2577],\n","        [ 0.1530,  0.1832,  0.2814, -0.1273,  0.2087, -0.1783,  0.2334, -0.1973,\n","          0.0228]])\n","first_linear.weight tensor([[ 0.1815,  0.2410,  0.1227,  0.3190,  0.1388, -0.1399,  0.3090,  0.1235,\n","          0.0989],\n","        [ 0.1507,  0.2949,  0.3052, -0.0144, -0.3279, -0.2779, -0.3202,  0.1108,\n","          0.0726],\n","        [-0.0746, -0.1455,  0.1623, -0.1774,  0.2616,  0.0625, -0.2907, -0.2126,\n","          0.2288],\n","        [-0.0738,  0.0942,  0.0933,  0.2685, -0.1237,  0.3157,  0.3057,  0.0344,\n","         -0.1453],\n","        [ 0.0850,  0.2997, -0.1352, -0.1683, -0.1538,  0.1351, -0.3230,  0.0837,\n","         -0.0988],\n","        [-0.0535, -0.0708, -0.0867,  0.3146,  0.3311,  0.0352,  0.1567,  0.3236,\n","         -0.2114],\n","        [-0.0221, -0.1782, -0.1850, -0.0808, -0.1374,  0.1167, -0.0155,  0.0047,\n","         -0.1055],\n","        [ 0.3007,  0.0377,  0.0346, -0.0098, -0.2938,  0.1437,  0.1924, -0.0397,\n","          0.1363],\n","        [ 0.3296, -0.0642, -0.2809,  0.2901,  0.0392, -0.3157,  0.0065,  0.1437,\n","         -0.1084],\n","        [-0.0876,  0.0732, -0.3187,  0.0681, -0.3231, -0.1753,  0.2392, -0.2250,\n","          0.1707]])lr:  0.905589446280529\n","first_linear.bias tensor([ 0.1253,  0.0750, -0.2928,  0.1866,  0.1639, -0.0810, -0.2007, -0.0447,\n","        -0.0854, -0.1730])\n","\n","weight_decay:  0.1603220224791051\n","\n","first_linear.bias tensor([ 0.2261, -0.0929,  0.1968,  0.1820,  0.1799,  0.0122,  0.0915, -0.0643,\n","         0.1788, -0.0370])linear_hidden.0.weight tensor([[-0.1999, -0.1305,  0.2051,  0.2480,  0.2543, -0.0390, -0.1829, -0.1987,\n","         -0.3028,  0.0173],\n","        [ 0.2546, -0.1644, -0.1788, -0.2943,  0.1218,  0.2031, -0.0159,  0.0154,\n","         -0.1924,  0.2660],\n","        [-0.1723, -0.2003, -0.1039, -0.0044, -0.3076, -0.1401, -0.1094,  0.0518,\n","          0.2304, -0.2387],\n","        [ 0.0154, -0.2808,  0.1250,  0.0772, -0.0221, -0.0600,  0.2575,  0.2918,\n","         -0.2140,  0.2909],\n","        [-0.1113,  0.1266,  0.0401, -0.2681,  0.0312,  0.1306, -0.2872,  0.3087,\n","         -0.0513,  0.1811],\n","        [-0.1812,  0.2711, -0.0503,  0.1532,  0.3081, -0.1401,  0.1746,  0.0780,\n","         -0.2891,  0.1870],\n","        [ 0.1595,  0.0307,  0.0260,  0.2334,  0.0295,  0.1167, -0.0059, -0.0241,\n","         -0.2548,  0.1676],\n","        [-0.0658, -0.2494,  0.1527,  0.0588, -0.1373, -0.1871, -0.1132,  0.3079,\n","          0.2466,  0.1571],\n","        [ 0.0211, -0.1223, -0.3136,  0.2290, -0.2600, -0.0916, -0.1449,  0.2660,\n","         -0.1732,  0.1064],\n","        [-0.1662,  0.2062,  0.1408, -0.1719, -0.0022,  0.2262, -0.0026,  0.2186,\n","         -0.2244, -0.2276]])\n","first_linear.bias tensor([ 0.0240,  0.1595, -0.0816,  0.0572, -0.0652,  0.2242, -0.1904,  0.1698,\n","        -0.3235, -0.2275])\n","linear_hidden.0.weight tensor([[ 0.2968,  0.2314, -0.1776, -0.1660, -0.2076, -0.0293, -0.1089,  0.0565,\n","          0.2156, -0.1062],\n","        [-0.3069, -0.1179,  0.1599,  0.2436,  0.1055, -0.1987,  0.1717,  0.0262,\n","          0.2985, -0.2908],\n","        [ 0.0292, -0.3053,  0.1740,  0.2114, -0.1202, -0.1474,  0.0586, -0.1996,\n","          0.0926,  0.0097],\n","        [ 0.1167, -0.2893,  0.2397,  0.1447, -0.2882,  0.0806,  0.2219,  0.1163,\n","          0.0608, -0.1463],\n","        [-0.0446, -0.1827, -0.3060,  0.1507, -0.0816,  0.1294, -0.2478, -0.2835,\n","          0.1875,  0.0464],\n","        [ 0.2017,  0.2454, -0.2285,  0.0964, -0.1675,  0.0162,  0.2637, -0.2227,\n","         -0.1491, -0.1575],\n","        [ 0.2649,  0.0985,  0.2338, -0.0537, -0.2588,  0.1029,  0.2349, -0.1319,\n","          0.1967, -0.0204],\n","        [-0.0272,  0.2994, -0.0206,  0.2805,  0.0311,  0.1093,  0.0519, -0.1856,\n","          0.0300, -0.1646],\n","        [ 0.0184,  0.0813, -0.1663,  0.2270, -0.1142,  0.2113, -0.0116,  0.2001,\n","         -0.1342,  0.1062],\n","        [-0.2283,  0.2100,  0.1325,  0.0438, -0.0614,  0.0688, -0.2458,  0.1734,\n","         -0.1858,  0.2806]])linear_hidden.0.bias tensor([ 0.2135,  0.2103, -0.1611, -0.1165, -0.1290, -0.0149, -0.2609, -0.3044,\n","        -0.0063,  0.2968])\n","\n","linear_hidden.0.bias tensor([-0.3046, -0.3048, -0.2479,  0.1564,  0.1309,  0.0631,  0.2160,  0.1343,\n","        -0.2229,  0.2812])betas0:  0.9996135842990216\n","\n","betas1:  0.996772845620619\n","hidden_size:  10\n","\n","conv1.weight tensor([[[[ 0.1799, -0.0698, -0.0423],\n","          [-0.1647, -0.2564,  0.2399],\n","          [-0.0564,  0.2745,  0.2189]]]])linear_hidden.0.weight tensor([[-0.2195,  0.1832, -0.0259, -0.1861, -0.1476, -0.1043,  0.0130,  0.2784,\n","         -0.0899,  0.0837],\n","        [-0.1321, -0.2166,  0.1136, -0.2533, -0.1381,  0.2532,  0.2497,  0.1281,\n","          0.2191, -0.1541],\n","        [ 0.2075,  0.1950,  0.2882,  0.2770, -0.0909, -0.1694, -0.0086, -0.1456,\n","         -0.2183, -0.0623],\n","        [-0.0554,  0.1420, -0.0472,  0.0761,  0.3133, -0.2416,  0.1290,  0.2625,\n","         -0.0366, -0.2059],\n","        [ 0.0842,  0.0271, -0.1249, -0.0313, -0.0787,  0.2698,  0.1297,  0.0004,\n","          0.0626,  0.2781],\n","        [-0.2823,  0.2799,  0.2613,  0.2073,  0.0363, -0.2478,  0.1602,  0.2341,\n","         -0.1595,  0.1194],\n","        [ 0.0469, -0.0962, -0.0018,  0.1585,  0.2217,  0.1497, -0.2688,  0.1129,\n","         -0.0423,  0.0022],\n","        [ 0.0643, -0.1588, -0.1375, -0.2526,  0.1429,  0.1990,  0.0534,  0.0074,\n","         -0.1171,  0.3071],\n","        [-0.1221,  0.0892,  0.2251, -0.1041,  0.2573, -0.2874,  0.1557,  0.2221,\n","         -0.0257, -0.2591],\n","        [-0.1412,  0.1245, -0.2566,  0.1395, -0.0738,  0.0979,  0.2536,  0.0713,\n","         -0.1037, -0.0668]])linear_output.weight tensor([[-0.0018,  0.0681,  0.2650, -0.0443,  0.1297,  0.1155,  0.3133, -0.1329,\n","         -0.1217,  0.1627]])linear_output.weight tensor([[-0.2269, -0.1853, -0.0243, -0.0754,  0.2979, -0.1262,  0.2929,  0.1083,\n","          0.3121, -0.0502]])\n","\n","linear_hidden.0.bias tensor([-0.2713, -0.0518, -0.2584, -0.2350,  0.0376, -0.0471,  0.2563, -0.1098,\n","        -0.0594,  0.0920])\n","conv1.bias tensor([0.3254])\n","\n","linear_output.bias tensor([-0.2235])\n","epoch 1\n","first_linear.weight tensor([[-0.0467, -0.1284, -0.2756,  0.3294,  0.0757,  0.0716,  0.2246,  0.1828,\n","          0.1840],\n","        [ 0.2079,  0.1174,  0.3046, -0.3134,  0.1979,  0.1060,  0.0054, -0.2254,\n","         -0.2253],\n","        [ 0.3099, -0.2583, -0.0256,  0.1283, -0.2679,  0.0665,  0.1365, -0.1821,\n","         -0.0807],\n","        [-0.1666, -0.2395,  0.2064,  0.0327,  0.2364,  0.1530,  0.0201,  0.2331,\n","          0.2710],\n","        [-0.0275, -0.1201, -0.3056, -0.1428, -0.2368,  0.0427, -0.1007, -0.2677,\n","          0.3284],\n","        [-0.0304, -0.0117, -0.1573, -0.1356, -0.0464, -0.0859, -0.1680,  0.2867,\n","         -0.0201],\n","        [ 0.0225, -0.0406,  0.2465,  0.2194,  0.3056, -0.2455, -0.0018, -0.2740,\n","          0.2194],\n","        [-0.2748, -0.3309,  0.0456,  0.0466,  0.1343,  0.0727,  0.1379,  0.1475,\n","         -0.0426],\n","        [ 0.1922,  0.0213, -0.2061,  0.3025,  0.1105,  0.2796,  0.1392, -0.1301,\n","         -0.2284],\n","        [-0.1033, -0.0878,  0.1747,  0.1757, -0.2871, -0.3303, -0.2406, -0.3091,\n","          0.2952]])linear_output.bias tensor([0.2754])\n","epoch 1\n","\n","\n","linear_output.weight tensor([[-0.0523, -0.2233, -0.2196, -0.2401, -0.1406, -0.2649, -0.0070, -0.1309,\n","          0.1207,  0.0311]])\n","first_linear.bias tensor([ 0.2947, -0.1165,  0.1531, -0.3024, -0.0721,  0.2647, -0.2602, -0.3174,\n","         0.2087, -0.2177])\n","linear_hidden.0.weight tensor([[-5.9338e-02, -2.0871e-01,  5.8007e-02,  1.4952e-01,  1.5724e-01,\n","          5.9367e-03,  3.2971e-02,  3.1366e-01,  1.1339e-01,  2.6050e-01],\n","        [-1.1143e-01,  1.9474e-01,  1.2101e-01,  2.6735e-01,  2.7729e-01,\n","         -8.2122e-02, -6.8028e-03, -2.6063e-01,  3.0299e-01, -2.1123e-01],\n","        [ 9.5202e-02,  6.1671e-02, -6.6455e-02,  1.9968e-01, -1.6674e-02,\n","          1.5282e-01, -1.6259e-01,  3.0666e-01, -1.1533e-01, -5.3767e-02],\n","        [-1.3356e-01, -3.0295e-01, -2.4781e-01, -2.5593e-01, -3.3738e-03,\n","          2.7927e-01, -8.5197e-02, -2.1373e-01, -2.1557e-01, -5.7243e-02],\n","        [ 1.8361e-01, -2.7516e-04, -6.2375e-02,  1.3638e-01, -2.9673e-01,\n","         -9.2223e-04, -4.3243e-02, -2.3051e-01, -2.8521e-01,  6.0434e-02],\n","        [-2.5327e-01,  1.2279e-01, -1.7616e-01,  3.0572e-01, -2.1655e-01,\n","          1.3931e-01,  2.5643e-01, -4.1098e-02,  3.0545e-01, -1.7614e-01],\n","        [ 7.3750e-02, -1.7148e-01, -3.0144e-01,  2.2115e-01, -2.7171e-01,\n","          2.2356e-01, -2.1914e-01, -2.5364e-01,  1.4901e-01, -1.5340e-01],\n","        [ 5.7475e-02, -3.8089e-02, -1.4658e-01,  5.3203e-02, -5.3082e-02,\n","          2.8185e-02, -1.2638e-01,  2.8710e-01,  2.6049e-01, -2.7412e-01],\n","        [-5.6749e-03,  2.0383e-01,  2.7761e-03, -3.3197e-02,  1.9213e-01,\n","         -5.1741e-02, -1.9176e-01,  2.4233e-01, -6.7896e-02,  5.5615e-02],\n","        [-1.0344e-01, -1.3892e-01,  2.1989e-01, -1.0845e-01, -6.6195e-02,\n","         -2.3104e-01, -1.3495e-01,  2.7193e-01, -1.5368e-01,  4.6681e-02]])\n","linear_output.bias tensor([-0.0869])\n","linear_hidden.0.bias tensor([ 0.1963,  0.1992,  0.1106, -0.0661,  0.0948, -0.0976,  0.2912, -0.1408,\n","         0.2321, -0.2522])epoch 1\n","\n","linear_output.weight tensor([[-0.1696, -0.0854,  0.0064, -0.0667, -0.2511, -0.0300,  0.2870,  0.3050,\n","         -0.2933,  0.2706]])\n","linear_output.bias tensor([0.0424])\n","epoch 1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tSkjTcdXeQGW","colab_type":"code","outputId":"fb515591-2b53-4bf2-c2a2-be8f1f848921","executionInfo":{"status":"ok","timestamp":1567138719932,"user_tz":-420,"elapsed":4322,"user":{"displayName":"Huy Nguyen","photoUrl":"","userId":"05352249580863404953"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":[""],"execution_count":0,"outputs":[{"output_type":"stream","text":["/bin/bash: killall: command not found\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RlD8t6QGezlS","colab_type":"code","outputId":"3e6bd6fb-a953-4b3f-e802-e24093adf78b","executionInfo":{"status":"ok","timestamp":1567102070267,"user_tz":-420,"elapsed":501,"user":{"displayName":"Huy Nguyen","photoUrl":"","userId":"05352249580863404953"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["train.__file__"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/My Drive/Year 4: Synthesis/NS162: Statistical Mechanics/Renormalization Research Project/renormalization/supervised_convnet/t_2.269/3x3/train.py'"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"rkBEK0uzj-sv","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}