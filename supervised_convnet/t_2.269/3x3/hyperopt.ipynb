{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hyperopt.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"g_engCTw8fpd","colab_type":"code","outputId":"10f91744-ae0d-40c3-bd79-6389fca9ba54","executionInfo":{"status":"ok","timestamp":1567696752376,"user_tz":-420,"elapsed":3645,"user":{"displayName":"Huy Nguyen","photoUrl":"","userId":"05352249580863404953"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# \n","\n","# !pip install -U --target=/usr/local/lib/python3.6/dist-packages git+https://github.com/pytorch/botorch.git\n","\n","# !pip install -U -q torch==1.2.0 torchvision\n","\n","# !pip install -U scikit-learn\n","# !pip install -U --target=/usr/local/lib/python3.6/dist-packages git+https://github.com/anhhuyalex/Ax.git\n","  \n","!pip install -U --target=/usr/local/lib/python3.6/dist-packages git+https://github.com/anhhuyalex/Ax.git\n","  \n","%cd /content\n","# %cd /usr/local/lib/python3.6/dist-packages\n","!rm -rf botorch\n","%cd /content\n","!git clone https://github.com/pytorch/botorch.git\n","%cd botorch\n","!pip install .\n","\n","!pip install sqlalchemy"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/anhhuyalex/Ax.git\n","  Cloning https://github.com/anhhuyalex/Ax.git to /tmp/pip-req-build-5dgscdim\n","  Running command git clone -q https://github.com/anhhuyalex/Ax.git /tmp/pip-req-build-5dgscdim\n","Collecting botorch>=0.1.3 (from ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/94/15177eb5675109ebf63f18047371320dde678648bb5cd5761325c772269f/botorch-0.1.3-py3-none-any.whl (169kB)\n","\u001b[K     |████████████████████████████████| 174kB 6.8MB/s \n","\u001b[?25hCollecting jinja2 (from ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/e7/fd8b501e7a6dfe492a433deb7b9d833d39ca74916fa8bc63dd1a4947a671/Jinja2-2.10.1-py2.py3-none-any.whl (124kB)\n","\u001b[K     |████████████████████████████████| 133kB 49.1MB/s \n","\u001b[?25hCollecting pandas (from ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/9b/52e228545d14f14bb2a1622e225f38463c8726645165e1cb7dde95bfe6d4/pandas-0.25.1-cp36-cp36m-manylinux1_x86_64.whl (10.5MB)\n","\u001b[K     |████████████████████████████████| 10.5MB 45.1MB/s \n","\u001b[?25hCollecting scipy (from ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/50/a552a5aff252ae915f522e44642bb49a7b7b31677f9580cfd11bcc869976/scipy-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (25.2MB)\n","\u001b[K     |████████████████████████████████| 25.2MB 1.7MB/s \n","\u001b[?25hCollecting sklearn (from ax-platform==0.1.4)\n","  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n","Collecting plotly (from ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/19/8437e22c84083a6d5d8a3c80f4edc73c9dcbb89261d07e6bd13b48752bbd/plotly-4.1.1-py2.py3-none-any.whl (7.1MB)\n","\u001b[K     |████████████████████████████████| 7.1MB 34.7MB/s \n","\u001b[?25hCollecting torch>=1.2 (from botorch>=0.1.3->ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/57/d5cceb0799c06733eefce80c395459f28970ebb9e896846ce96ab579a3f1/torch-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (748.8MB)\n","\u001b[K     |████████████████████████████████| 748.9MB 20kB/s \n","\u001b[?25hCollecting gpytorch>=0.3.5 (from botorch>=0.1.3->ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/e4/e74dc12c6d07a5d8628dfb573b01297f7c2b44eec524be4b401c0782d39c/gpytorch-0.3.5.tar.gz (211kB)\n","\u001b[K     |████████████████████████████████| 215kB 44.7MB/s \n","\u001b[?25hCollecting MarkupSafe>=0.23 (from jinja2->ax-platform==0.1.4)\n","  Downloading https://files.pythonhosted.org/packages/b2/5f/23e0023be6bb885d00ffbefad2942bc51a620328ee910f64abe5a8d18dd1/MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl\n","Collecting pytz>=2017.2 (from pandas->ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/76/46d697698a143e05f77bec5a526bf4e56a0be61d63425b68f4ba553b51f2/pytz-2019.2-py2.py3-none-any.whl (508kB)\n","\u001b[K     |████████████████████████████████| 512kB 38.2MB/s \n","\u001b[?25hCollecting numpy>=1.13.3 (from pandas->ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/92/57179ed45307ec6179e344231c47da7f3f3da9e2eee5c8ab506bd279ce4e/numpy-1.17.1-cp36-cp36m-manylinux1_x86_64.whl (20.4MB)\n","\u001b[K     |████████████████████████████████| 20.4MB 33.5MB/s \n","\u001b[?25hCollecting python-dateutil>=2.6.1 (from pandas->ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n","\u001b[K     |████████████████████████████████| 235kB 40.6MB/s \n","\u001b[?25hCollecting scikit-learn (from sklearn->ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/c5/d2238762d780dde84a20b8c761f563fe882b88c5a5fb03c056547c442a19/scikit_learn-0.21.3-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n","\u001b[K     |████████████████████████████████| 6.7MB 26.0MB/s \n","\u001b[?25hCollecting retrying>=1.3.3 (from plotly->ax-platform==0.1.4)\n","  Downloading https://files.pythonhosted.org/packages/44/ef/beae4b4ef80902f22e3af073397f079c96969c69b2c7d52a57ea9ae61c9d/retrying-1.3.3.tar.gz\n","Collecting six (from plotly->ax-platform==0.1.4)\n","  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n","Collecting joblib>=0.11 (from scikit-learn->sklearn->ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl (278kB)\n","\u001b[K     |████████████████████████████████| 286kB 43.8MB/s \n","\u001b[?25hBuilding wheels for collected packages: ax-platform, sklearn, gpytorch, retrying\n","  Building wheel for ax-platform (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ax-platform: filename=ax_platform-0.1.4-cp36-cp36m-linux_x86_64.whl size=918268 sha256=22f2074486e517c35b8facf19d1eca0b96bfd14c22fb3812a2bdcb30618366ce\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-ns8otps5/wheels/cf/31/a7/531e4606a720574d740203ff00855672549f50a7d1b9bc736e\n","  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=8ece746dd611ae4313005cb55c5c2cc863556fd88f9b57d8070af3f827ee59b0\n","  Stored in directory: /root/.cache/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n","  Building wheel for gpytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gpytorch: filename=gpytorch-0.3.5-py2.py3-none-any.whl size=349720 sha256=f4b407cd1082ed4a821b3d8c8d7f0ab9e22a3430b15d1ab8ce7ed84f3bef8a56\n","  Stored in directory: /root/.cache/pip/wheels/d6/31/88/c43a94e0073a54056ac663366f2195de36535b38a81a378196\n","  Building wheel for retrying (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for retrying: filename=retrying-1.3.3-cp36-none-any.whl size=11429 sha256=d1a3923de7837e201d1af59431db1a74690b372af1b7f61ec1c9e8eb00a53403\n","  Stored in directory: /root/.cache/pip/wheels/d7/a9/33/acc7b709e2a35caa7d4cae442f6fe6fbf2c43f80823d46460c\n","Successfully built ax-platform sklearn gpytorch retrying\n","\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=0.24.0, but you'll have pandas 0.25.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: numpy, torch, gpytorch, scipy, botorch, MarkupSafe, jinja2, pytz, six, python-dateutil, pandas, joblib, scikit-learn, sklearn, retrying, plotly, ax-platform\n","Successfully installed MarkupSafe-1.1.1 ax-platform-0.1.4 botorch-0.1.3 gpytorch-0.3.5 jinja2-2.10.1 joblib-0.13.2 numpy-1.17.1 pandas-0.25.1 plotly-4.1.1 python-dateutil-2.8.0 pytz-2019.2 retrying-1.3.3 scikit-learn-0.21.3 scipy-1.3.1 six-1.12.0 sklearn-0.0 torch-1.2.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["dateutil","numpy","pandas","pytz","six"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["/content\n","/content\n","Cloning into 'botorch'...\n","remote: Enumerating objects: 253, done.\u001b[K\n","remote: Counting objects: 100% (253/253), done.\u001b[K\n","remote: Compressing objects: 100% (176/176), done.\u001b[K\n","remote: Total 5949 (delta 100), reused 124 (delta 39), pack-reused 5696\u001b[K\n","Receiving objects: 100% (5949/5949), 10.53 MiB | 13.34 MiB/s, done.\n","Resolving deltas: 100% (3798/3798), done.\n","/content/botorch\n","Processing /content/botorch\n","Requirement already satisfied: torch>=1.2 in /usr/local/lib/python3.6/dist-packages (from botorch==0.1.3) (1.2.0)\n","Requirement already satisfied: gpytorch>=0.3.5 in /usr/local/lib/python3.6/dist-packages (from botorch==0.1.3) (0.3.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from botorch==0.1.3) (1.3.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.2->botorch==0.1.3) (1.17.1)\n","Building wheels for collected packages: botorch\n","  Building wheel for botorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for botorch: filename=botorch-0.1.3-cp36-none-any.whl size=175135 sha256=c2593e26597db0fa30a4ef590d30367c1b0bd6553995a2904e511b4d1ee38e0a\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-i5p0tlr6/wheels/d8/0e/3f/502176509633fec729eabc1a42e465b3603faf0c30b4782f33\n","Successfully built botorch\n","Installing collected packages: botorch\n","  Found existing installation: botorch 0.1.3\n","    Uninstalling botorch-0.1.3:\n","      Successfully uninstalled botorch-0.1.3\n","Successfully installed botorch-0.1.3\n","Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.6/dist-packages (1.3.7)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uJuszQGG_m1D","colab_type":"code","outputId":"7d6e3816-73a4-40c1-cafc-14c796afe642","executionInfo":{"status":"ok","timestamp":1567696885178,"user_tz":-420,"elapsed":45464,"user":{"displayName":"Huy Nguyen","photoUrl":"","userId":"05352249580863404953"}},"colab":{"base_uri":"https://localhost:8080/","height":189}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lIKufxcqJZzf","colab_type":"code","outputId":"a1012850-ef61-4c2c-f793-5cfc611f29a8","executionInfo":{"status":"ok","timestamp":1567696907579,"user_tz":-420,"elapsed":21580,"user":{"displayName":"Huy Nguyen","photoUrl":"","userId":"05352249580863404953"}},"colab":{"base_uri":"https://localhost:8080/","height":182}},"source":["%cd /content/\n","!git clone https://github.com/anhhuyalex/renormalization.git\n","!cp /content/drive/My\\ Drive/Year\\ 4\\:\\ Synthesis/NS162\\:\\ Statistical\\ Mechanics/Renormalization\\ Research\\ Project/renormalization/supervised_convnet/t_2.269/3x3/ising81x81_temp2.269_uncorrelated9x9.npy /content/renormalization/supervised_convnet/t_2.269/3x3\n","!cp /content/drive/My\\ Drive/Year\\ 4\\:\\ Synthesis/NS162\\:\\ Statistical\\ Mechanics/Renormalization\\ Research\\ Project/renormalization/supervised_convnet/t_2.269/ising81x81_temp2.269.npy /content/renormalization/supervised_convnet/t_2.269      "],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content\n","Cloning into 'renormalization'...\n","remote: Enumerating objects: 260, done.\u001b[K\n","remote: Counting objects: 100% (260/260), done.\u001b[K\n","remote: Compressing objects: 100% (144/144), done.\u001b[K\n","remote: Total 260 (delta 149), reused 211 (delta 100), pack-reused 0\u001b[K\n","Receiving objects: 100% (260/260), 588.31 KiB | 1.63 MiB/s, done.\n","Resolving deltas: 100% (149/149), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NU7OJp_nAbkW","colab_type":"code","outputId":"d8761770-b3bf-44b0-8692-3551e50dda97","executionInfo":{"status":"ok","timestamp":1567696911821,"user_tz":-420,"elapsed":3429,"user":{"displayName":"Huy Nguyen","photoUrl":"","userId":"05352249580863404953"}},"colab":{"base_uri":"https://localhost:8080/","height":340}},"source":["%cd /content/renormalization/supervised_convnet/t_2.269/3x3\n","import torch\n","import numpy as np\n","import pickle\n","\n","\n","from ax import RangeParameter, ParameterType\n","from ax.service.ax_client import AxClient\n","from ax.plot.contour import plot_contour\n","from ax.plot.trace import optimization_trace_single_method\n","from ax.service.managed_loop import optimize\n","from ax.utils.notebook.plotting import render, init_notebook_plotting\n","\n","import sys\n","import time\n","sys.path.insert(0, \"../../\")\n","import supervised_convnet\n","import train, frozen\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/renormalization/supervised_convnet/t_2.269/3x3\n","Uncorrelated [[ 1  1  1 -1 -1 -1  1 -1 -1]\n"," [ 1  1  1 -1 -1 -1 -1 -1 -1]\n"," [ 1  1  1 -1  1  1  1  1  1]\n"," [ 1  1 -1  1 -1 -1 -1 -1 -1]\n"," [ 1  1 -1  1 -1 -1 -1 -1 -1]\n"," [ 1  1  1  1 -1 -1 -1 -1  1]\n"," [ 1  1 -1 -1 -1 -1  1  1  1]\n"," [ 1 -1 -1 -1 -1 -1  1  1  1]\n"," [ 1  1  1 -1 -1 -1  1  1 -1]]\n","Correlated [[ 1  1 -1  1 -1 -1 -1 -1  1]\n"," [ 1  1 -1 -1 -1 -1 -1 -1 -1]\n"," [ 1  1 -1 -1 -1  1  1  1  1]\n"," [-1 -1 -1 -1 -1 -1  1  1  1]\n"," [ 1 -1 -1 -1 -1  1  1  1  1]\n"," [-1 -1 -1 -1 -1  1  1  1  1]\n"," [-1 -1 -1 -1 -1  1  1 -1 -1]\n"," [-1 -1 -1 -1 -1 -1  1  1  1]\n"," [-1 -1  1 -1 -1 -1 -1 -1  1]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SbOqeR18C56q","colab_type":"code","colab":{}},"source":["# Parameters\n","num_hidden_layers = 1\n","out_channels = 1\n","num_workers = 15\n","run_mode = \"frozen_convolution_no_center_relu\" # sys.argv[1]\n","n_loops = 3000\n","save_loop = min(n_loops, 10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yH3jfmeHU625","colab_type":"code","colab":{}},"source":["def init_model_and_train(hidden_size, batch_size, train_size, n_epochs, lr, weight_decay,\n","            betas0, betas1, seed):\n","    # Parameters\n","    num_hidden_layers = 1\n","    out_channels = 1\n","\n","\n","    if run_mode == \"unfrozen_convolution_relu\":\n","        model = supervised_convnet.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","                hidden_size = hidden_size, out_channels = out_channels,\n","                first_activation = \"tanh\", activation_func = \"relu\",\n","                num_hidden_layers = num_hidden_layers, seed = seed)\n","        results = train.trainer(model = model, batch_size = batch_size, train_size = train_size, n_epochs = n_epochs, lr = lr,\n","                    weight_decay = weight_decay,\n","                    betas0 = 1-betas0, betas1 = 1-betas1)\n","    elif run_mode == \"frozen_convolution_no_center_relu\":\n","        model = frozen.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","                hidden_size = hidden_size, out_channels = out_channels,\n","                center = \"omit\", first_activation = \"tanh\",\n","                activation_func = \"relu\", num_hidden_layers = num_hidden_layers)\n","        results = train.trainer(model = model, batch_size = batch_size, train_size = train_size, n_epochs = n_epochs, lr = lr,\n","                    weight_decay = weight_decay,\n","                    betas0 = 1-betas0, betas1 = 1-betas1)\n","    elif run_mode == \"frozen_convolution_pretrained_relu\":\n","        model = frozen.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","                hidden_size = hidden_size, out_channels = out_channels,\n","                center = \"pre_trained\", first_activation = \"tanh\",\n","                activation_func = \"relu\", num_hidden_layers = num_hidden_layers)\n","        results = train.trainer(model = model, batch_size = batch_size, train_size = train_size, n_epochs = n_epochs, lr = lr,\n","                    weight_decay = weight_decay,\n","                    betas0 = 1-betas0, betas1 = 1-betas1)\n","    elif run_mode == \"unfrozen_convolution_2_channels\":\n","        out_channels = 2\n","        model = supervised_convnet.SupervisedConvNet(filter_size = 3, square_size = 3,\n","                hidden_size = hidden_size, out_channels = out_channels,\n","                first_activation = \"tanh\", activation_func = \"relu\",\n","                num_hidden_layers = num_hidden_layers, seed = seed)\n","        results = train.trainer(model = model, batch_size = batch_size, train_size = train_size, n_epochs = n_epochs, lr = lr,\n","                    weight_decay = weight_decay,\n","                    betas0 = 1-betas0, betas1 = 1-betas1)\n","    return (results[0])\n","\n","\n","\n","def train_evaluate(parameterization):\n","    # parameters\n","    batch_size = parameterization[\"batch_size\"]\n","    train_size = parameterization[\"train_size\"]\n","    n_epochs = parameterization[\"n_epochs\"]\n","    lr = parameterization[\"lr\"]\n","    weight_decay = parameterization[\"weight_decay\"]\n","    betas0 = parameterization[\"betas0\"]\n","    betas1 = parameterization[\"betas1\"]\n","    hidden_size = 10\n","\n","    results = []\n","    for seed in range(num_workers):\n","        results.append(init_model_and_train(hidden_size, batch_size, train_size,\n","        n_epochs, lr, weight_decay, betas0, betas1,\n","        time.time() + seed))\n","\n","    print (\"results\", results)\n","    mean = np.mean(results)\n","    SEM = np.std(results)/np.sqrt(num_workers)\n","    # pool.close() # no more tasks\n","    # pool.join()  # wrap up current tasks\n","    return {\"objective\": (mean, SEM)}\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QaA_x4e0VhwV","colab_type":"code","colab":{}},"source":["%%capture\n","\n","# Initialize client\n","ax_client = AxClient()\n","try:\n","    with open(f\"/content/drive/My Drive/Year 4: Synthesis/NS162: Statistical Mechanics/Renormalization Research Project/renormalization/supervised_convnet/t_2.269/3x3/colab/hyperparameters_{run_mode}.pl\", \"rb\") as handle:\n","        hyper = pickle.load(handle)\n","    v = hyper[\"axclient\"].copy()\n","    ax_client = ax_client.from_json_snapshot(v)\n","except:\n","    ax_client.create_experiment(\n","        parameters=[\n","            {\n","              \"name\": \"batch_size\",\n","              \"type\": \"range\",\n","              \"bounds\": [1, 5000],\n","              \"value_type\": \"int\"\n","            },\n","            {\n","              \"name\": \"train_size\",\n","              \"type\": \"range\",\n","              \"bounds\": [100, 5000],\n","              \"value_type\": \"int\"\n","            },\n","            {\n","              \"name\": \"n_epochs\",\n","              \"type\": \"range\",\n","              \"bounds\": [50, 250],\n","              \"value_type\": \"int\"\n","            },\n","            {\n","              \"name\": \"lr\",\n","              \"type\": \"range\",\n","              \"bounds\": [1e-4, 1],\n","              \"value_type\": \"float\",\n","              \"log_scale\": True\n","            },\n","            {\n","              \"name\": \"weight_decay\",\n","              \"type\": \"range\",\n","              \"bounds\": [1e-5, 2e-1],\n","              \"value_type\": \"float\",\n","              \"log_scale\": True\n","            },\n","            {\n","              \"name\": \"betas0\",\n","              \"type\": \"range\",\n","              \"bounds\": [1e-5, 2e-1],\n","              \"value_type\": \"float\",\n","              \"log_scale\": True\n","            },\n","            {\n","              \"name\": \"betas1\",\n","              \"type\": \"range\",\n","              \"bounds\": [1e-5, 2e-1],\n","              \"value_type\": \"float\",\n","              \"log_scale\": True\n","            }\n","        ],\n","        parameter_constraints=[\"0.02 * train_size + -1 * batch_size <= 0\", \"train_size >= batch_size\"],\n","        minimize=False,\n","        objective_name=\"objective\",\n","        outcome_constraints=None,\n","        name=\"Test\"\n","    )\n","\n","# print (\"axclient\",ax_client.experiment.trials )\n","# for loop in range(n_loops):\n","for loop in range(n_loops):\n","    print(f\"Running trial {loop}/{n_loops}...\")\n","    parameters, trial_index = ax_client.get_next_trial()\n","    print(\"trial_index\", trial_index)\n","    time.sleep(2)\n","#     parameters[\"n_epochs\"] = 5\n","     # Local evaluation here can be replaced with deployment to external system.\n","    ax_client.complete_trial(trial_index=trial_index, raw_data=train_evaluate(parameters))\n","    print(\"Best params\", ax_client.get_best_parameters())\n","    # periodic save\n","    if loop % save_loop == (save_loop - 1):\n","        optim_result = ax_client.get_best_parameters()\n","        # print(\"best_parameters\", optim_result)\n","        # print(\"was I saved?\", ax._save_experiment_and_generation_strategy_if_possible())\n","        hyper = {}\n","        hyper[\"best_params\"] = optim_result\n","        hyper[\"axclient\"] = ax_client.to_json_snapshot()\n","        # print(\"optim_result\", optim_result)\n","        with open(f\"/content/drive/My Drive/Year 4: Synthesis/NS162: Statistical Mechanics/Renormalization Research Project/renormalization/supervised_convnet/t_2.269/3x3/colab/hyperparameters_{run_mode}.pl\", \"wb\") as handle:\n","            pickle.dump(hyper, handle, protocol = pickle.HIGHEST_PROTOCOL)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tSkjTcdXeQGW","colab_type":"code","colab":{}},"source":["i = 0 "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RlD8t6QGezlS","colab_type":"code","outputId":"3e6bd6fb-a953-4b3f-e802-e24093adf78b","executionInfo":{"status":"ok","timestamp":1567102070267,"user_tz":-420,"elapsed":501,"user":{"displayName":"Huy Nguyen","photoUrl":"","userId":"05352249580863404953"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["train.__file__"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/My Drive/Year 4: Synthesis/NS162: Statistical Mechanics/Renormalization Research Project/renormalization/supervised_convnet/t_2.269/3x3/train.py'"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"rkBEK0uzj-sv","colab_type":"code","outputId":"729cf094-2937-4523-a3a7-3f317f2fa7ef","executionInfo":{"status":"error","timestamp":1567672130666,"user_tz":-420,"elapsed":1054,"user":{"displayName":"Huy Nguyen","photoUrl":"","userId":"05352249580863404953"}},"colab":{"base_uri":"https://localhost:8080/","height":184}},"source":["open(f\"/content/drive/My Drive/Year 4: Synthesis/NS162: Statistical Mechanics/Renormalization Research Project/renormalization/supervised_convnet/t_2.269/colab/hyperparameters_{run_mode}.pl\", \"wb\")\n"],"execution_count":0,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-a68ed25944c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"/content/drive/My Drive/Year 4: Synthesis/NS162: Statistical Mechanics/Renormalization Research Project/renormalization/supervised_convnet/t_2.269/colab/hyperparameters_{run_mode}.pl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/Year 4: Synthesis/NS162: Statistical Mechanics/Renormalization Research Project/renormalization/supervised_convnet/t_2.269/colab/hyperparameters_unfrozen_convolution_relu.pl'"]}]},{"cell_type":"code","metadata":{"id":"fly_JhV0ilbX","colab_type":"code","outputId":"5db22b03-3da2-4528-b7fb-5228e6532e56","executionInfo":{"status":"ok","timestamp":1567672244336,"user_tz":-420,"elapsed":1036,"user":{"displayName":"Huy Nguyen","photoUrl":"","userId":"05352249580863404953"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["open(f\"/content/drive/My Drive/Year 4: Synthesis/NS162: Statistical Mechanics/Renormalization Research Project/renormalization/supervised_convnet/t_2.269/hyperparameters_{run_mode}.pl\", \"wb\")"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<_io.BufferedWriter name='/content/drive/My Drive/Year 4: Synthesis/NS162: Statistical Mechanics/Renormalization Research Project/renormalization/supervised_convnet/t_2.269/hyperparameters_unfrozen_convolution_relu.pl'>"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"aczCEhOQirGb","colab_type":"code","colab":{}},"source":["with open(f\"/content/drive/My Drive/Year 4: Synthesis/NS162: Statistical Mechanics/Renormalization Research Project/renormalization/supervised_convnet/t_2.269/hyperparameters_{run_mode}.pl\", \"wb\") as handle:\n","    pickle.dump(hyper, handle, protocol = pickle.HIGHEST_PROTOCOL)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FZqjHc5HvCIr","colab_type":"code","outputId":"daf381f3-12d1-45f8-c6c4-9f2838fa498b","executionInfo":{"status":"ok","timestamp":1567675571405,"user_tz":-420,"elapsed":5091,"user":{"displayName":"Huy Nguyen","photoUrl":"","userId":"05352249580863404953"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["!ls /content/drive/My\\ Drive/Year\\ 4:\\ Synthesis/NS162:\\ Statistical\\ Mechanics/Renormalization\\ Research\\ Project/renormalization/supervised_convnet/t_2.269/"],"execution_count":0,"outputs":[{"output_type":"stream","text":[" 3x3\t        generate_uncorrelated_data.py\t\t       runs\n"," 81x81\t        hyperparameters_unfrozen_convolution_relu.pl\n","'9x9->3x3.pt'   ising81x81_temp2.269.npy\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Xv9ZRNCqvUnx","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}