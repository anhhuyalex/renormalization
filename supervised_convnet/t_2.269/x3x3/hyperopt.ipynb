{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7732,
     "status": "ok",
     "timestamp": 1567925649255,
     "user": {
      "displayName": "Huy Nguyen",
      "photoUrl": "",
      "userId": "05352249580863404953"
     },
     "user_tz": -420
    },
    "id": "g_engCTw8fpd",
    "outputId": "e78aebaf-caa1-42bc-db63-7ae46c1d2177"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay          49G   26G   21G  56% /\n",
      "tmpfs            64M     0   64M   0% /dev\n",
      "tmpfs           6.4G     0  6.4G   0% /sys/fs/cgroup\n",
      "tmpfs           6.4G  8.0K  6.4G   1% /var/colab\n",
      "/dev/sda1        55G   28G   28G  50% /etc/hosts\n",
      "shm             6.0G  4.0K  6.0G   1% /dev/shm\n",
      "tmpfs           6.4G     0  6.4G   0% /proc/acpi\n",
      "tmpfs           6.4G     0  6.4G   0% /proc/scsi\n",
      "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n",
      "processor\t: 0\n",
      "vendor_id\t: GenuineIntel\n",
      "cpu family\t: 6\n",
      "model\t\t: 79\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
      "stepping\t: 0\n",
      "microcode\t: 0x1\n",
      "cpu MHz\t\t: 2200.000\n",
      "cache size\t: 56320 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 2\n",
      "core id\t\t: 0\n",
      "cpu cores\t: 1\n",
      "apicid\t\t: 0\n",
      "initial apicid\t: 0\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
      "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n",
      "bogomips\t: 4400.00\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 46 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n",
      "processor\t: 1\n",
      "vendor_id\t: GenuineIntel\n",
      "cpu family\t: 6\n",
      "model\t\t: 79\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
      "stepping\t: 0\n",
      "microcode\t: 0x1\n",
      "cpu MHz\t\t: 2200.000\n",
      "cache size\t: 56320 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 2\n",
      "core id\t\t: 0\n",
      "cpu cores\t: 1\n",
      "apicid\t\t: 1\n",
      "initial apicid\t: 1\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
      "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n",
      "bogomips\t: 4400.00\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 46 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n",
      "MemTotal:       13335192 kB\n",
      "MemFree:        11073480 kB\n",
      "MemAvailable:   12542556 kB\n",
      "Buffers:           74228 kB\n",
      "Cached:          1557396 kB\n",
      "SwapCached:            0 kB\n",
      "Active:           665872 kB\n",
      "Inactive:        1362108 kB\n",
      "Active(anon):     377224 kB\n",
      "Inactive(anon):      308 kB\n",
      "Active(file):     288648 kB\n",
      "Inactive(file):  1361800 kB\n",
      "Unevictable:           0 kB\n",
      "Mlocked:               0 kB\n",
      "SwapTotal:             0 kB\n",
      "SwapFree:              0 kB\n",
      "Dirty:                84 kB\n",
      "Writeback:             0 kB\n",
      "AnonPages:        396436 kB\n",
      "Mapped:           217012 kB\n",
      "Shmem:               840 kB\n",
      "Slab:             148464 kB\n",
      "SReclaimable:     119276 kB\n",
      "SUnreclaim:        29188 kB\n",
      "KernelStack:        3504 kB\n",
      "PageTables:         5304 kB\n",
      "NFS_Unstable:          0 kB\n",
      "Bounce:                0 kB\n",
      "WritebackTmp:          0 kB\n",
      "CommitLimit:     6667596 kB\n",
      "Committed_AS:    2791780 kB\n",
      "VmallocTotal:   34359738367 kB\n",
      "VmallocUsed:           0 kB\n",
      "VmallocChunk:          0 kB\n",
      "AnonHugePages:         0 kB\n",
      "ShmemHugePages:        0 kB\n",
      "ShmemPmdMapped:        0 kB\n",
      "HugePages_Total:       0\n",
      "HugePages_Free:        0\n",
      "HugePages_Rsvd:        0\n",
      "HugePages_Surp:        0\n",
      "Hugepagesize:       2048 kB\n",
      "DirectMap4k:       63476 kB\n",
      "DirectMap2M:     6227968 kB\n",
      "DirectMap1G:     9437184 kB\n"
     ]
    }
   ],
   "source": [
    "!df -h\n",
    "!cat /proc/cpuinfo\n",
    "!cat /proc/meminfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 238145,
     "status": "ok",
     "timestamp": 1568435727010,
     "user": {
      "displayName": "Huy Nguyen",
      "photoUrl": "",
      "userId": "05352249580863404953"
     },
     "user_tz": -420
    },
    "id": "dq7wa0jTwlLZ",
    "outputId": "69ceccc2-80f5-48e5-8098-7770b5a252c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gputil\n",
      "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
      "Building wheels for collected packages: gputil\n",
      "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7410 sha256=a6f9e749afee172845dada24aa4a59486992cbeb735b2b2e46ab825ff1e812e0\n",
      "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
      "Successfully built gputil\n",
      "Installing collected packages: gputil\n",
      "Successfully installed gputil-1.4.0\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
      "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
      "Collecting git+https://github.com/anhhuyalex/Ax.git\n",
      "  Cloning https://github.com/anhhuyalex/Ax.git to /tmp/pip-req-build-50gjr4xb\n",
      "  Running command git clone -q https://github.com/anhhuyalex/Ax.git /tmp/pip-req-build-50gjr4xb\n",
      "Collecting botorch>=0.1.3 (from ax-platform==0.1.4)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/94/15177eb5675109ebf63f18047371320dde678648bb5cd5761325c772269f/botorch-0.1.3-py3-none-any.whl (169kB)\n",
      "\u001b[K     |████████████████████████████████| 174kB 4.9MB/s \n",
      "\u001b[?25hCollecting jinja2 (from ax-platform==0.1.4)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/e7/fd8b501e7a6dfe492a433deb7b9d833d39ca74916fa8bc63dd1a4947a671/Jinja2-2.10.1-py2.py3-none-any.whl (124kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 47.9MB/s \n",
      "\u001b[?25hCollecting pandas (from ax-platform==0.1.4)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/9b/52e228545d14f14bb2a1622e225f38463c8726645165e1cb7dde95bfe6d4/pandas-0.25.1-cp36-cp36m-manylinux1_x86_64.whl (10.5MB)\n",
      "\u001b[K     |████████████████████████████████| 10.5MB 49.7MB/s \n",
      "\u001b[?25hCollecting scipy (from ax-platform==0.1.4)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/50/a552a5aff252ae915f522e44642bb49a7b7b31677f9580cfd11bcc869976/scipy-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (25.2MB)\n",
      "\u001b[K     |████████████████████████████████| 25.2MB 39.3MB/s \n",
      "\u001b[?25hCollecting sklearn (from ax-platform==0.1.4)\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Collecting plotly (from ax-platform==0.1.4)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/19/8437e22c84083a6d5d8a3c80f4edc73c9dcbb89261d07e6bd13b48752bbd/plotly-4.1.1-py2.py3-none-any.whl (7.1MB)\n",
      "\u001b[K     |████████████████████████████████| 7.1MB 32.4MB/s \n",
      "\u001b[?25hCollecting torch>=1.2 (from botorch>=0.1.3->ax-platform==0.1.4)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/57/d5cceb0799c06733eefce80c395459f28970ebb9e896846ce96ab579a3f1/torch-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (748.8MB)\n",
      "\u001b[K     |████████████████████████████████| 748.9MB 23kB/s \n",
      "\u001b[?25hCollecting gpytorch>=0.3.5 (from botorch>=0.1.3->ax-platform==0.1.4)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/e4/e74dc12c6d07a5d8628dfb573b01297f7c2b44eec524be4b401c0782d39c/gpytorch-0.3.5.tar.gz (211kB)\n",
      "\u001b[K     |████████████████████████████████| 215kB 57.7MB/s \n",
      "\u001b[?25hCollecting MarkupSafe>=0.23 (from jinja2->ax-platform==0.1.4)\n",
      "  Downloading https://files.pythonhosted.org/packages/b2/5f/23e0023be6bb885d00ffbefad2942bc51a620328ee910f64abe5a8d18dd1/MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting python-dateutil>=2.6.1 (from pandas->ax-platform==0.1.4)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n",
      "\u001b[K     |████████████████████████████████| 235kB 47.7MB/s \n",
      "\u001b[?25hCollecting numpy>=1.13.3 (from pandas->ax-platform==0.1.4)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/e6/c3fdc53aed9fa19d6ff3abf97dfad768ae3afce1b7431f7500000816bda5/numpy-1.17.2-cp36-cp36m-manylinux1_x86_64.whl (20.4MB)\n",
      "\u001b[K     |████████████████████████████████| 20.4MB 35.8MB/s \n",
      "\u001b[?25hCollecting pytz>=2017.2 (from pandas->ax-platform==0.1.4)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/76/46d697698a143e05f77bec5a526bf4e56a0be61d63425b68f4ba553b51f2/pytz-2019.2-py2.py3-none-any.whl (508kB)\n",
      "\u001b[K     |████████████████████████████████| 512kB 40.0MB/s \n",
      "\u001b[?25hCollecting scikit-learn (from sklearn->ax-platform==0.1.4)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/c5/d2238762d780dde84a20b8c761f563fe882b88c5a5fb03c056547c442a19/scikit_learn-0.21.3-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n",
      "\u001b[K     |████████████████████████████████| 6.7MB 42.1MB/s \n",
      "\u001b[?25hCollecting six (from plotly->ax-platform==0.1.4)\n",
      "  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
      "Collecting retrying>=1.3.3 (from plotly->ax-platform==0.1.4)\n",
      "  Downloading https://files.pythonhosted.org/packages/44/ef/beae4b4ef80902f22e3af073397f079c96969c69b2c7d52a57ea9ae61c9d/retrying-1.3.3.tar.gz\n",
      "Collecting joblib>=0.11 (from scikit-learn->sklearn->ax-platform==0.1.4)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl (278kB)\n",
      "\u001b[K     |████████████████████████████████| 286kB 53.9MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: ax-platform, sklearn, gpytorch, retrying\n",
      "  Building wheel for ax-platform (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for ax-platform: filename=ax_platform-0.1.4-cp36-cp36m-linux_x86_64.whl size=918254 sha256=c953695a6cb55bd7bfa2f7e71570a75fa7d6f0b3aa89a9b09089c1801a28b31d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-8l8blixa/wheels/cf/31/a7/531e4606a720574d740203ff00855672549f50a7d1b9bc736e\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=c162ae824291b8621fd025d4a61aeec112e3ecf87ed13c90a625c85e043cfd38\n",
      "  Stored in directory: /root/.cache/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
      "  Building wheel for gpytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gpytorch: filename=gpytorch-0.3.5-py2.py3-none-any.whl size=349720 sha256=5095f710595b16f5903267ec27ef5b41f313eab0769ee53ccebebad39375a5e3\n",
      "  Stored in directory: /root/.cache/pip/wheels/d6/31/88/c43a94e0073a54056ac663366f2195de36535b38a81a378196\n",
      "  Building wheel for retrying (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for retrying: filename=retrying-1.3.3-cp36-none-any.whl size=11429 sha256=ee3a6af2554228939cc5fa483cc5e1ba70219e48f4992cf0c9f1af4a5da062df\n",
      "  Stored in directory: /root/.cache/pip/wheels/d7/a9/33/acc7b709e2a35caa7d4cae442f6fe6fbf2c43f80823d46460c\n",
      "Successfully built ax-platform sklearn gpytorch retrying\n",
      "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=0.24.0, but you'll have pandas 0.25.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy, torch, gpytorch, scipy, botorch, MarkupSafe, jinja2, six, python-dateutil, pytz, pandas, joblib, scikit-learn, sklearn, retrying, plotly, ax-platform\n",
      "Successfully installed MarkupSafe-1.1.1 ax-platform-0.1.4 botorch-0.1.3 gpytorch-0.3.5 jinja2-2.10.1 joblib-0.13.2 numpy-1.17.2 pandas-0.25.1 plotly-4.1.1 python-dateutil-2.8.0 pytz-2019.2 retrying-1.3.3 scikit-learn-0.21.3 scipy-1.3.1 six-1.12.0 sklearn-0.0 torch-1.2.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "dateutil",
         "numpy",
         "pandas",
         "pytz",
         "six"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "/content\n",
      "Cloning into 'botorch'...\n",
      "remote: Enumerating objects: 12, done.\u001b[K\n",
      "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
      "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
      "remote: Total 6051 (delta 1), reused 7 (delta 1), pack-reused 6039\u001b[K\n",
      "Receiving objects: 100% (6051/6051), 10.33 MiB | 15.76 MiB/s, done.\n",
      "Resolving deltas: 100% (3955/3955), done.\n",
      "/content/botorch\n",
      "Processing /content/botorch\n",
      "Requirement already satisfied: torch>=1.2 in /usr/local/lib/python3.6/dist-packages (from botorch==0.1.3) (1.2.0)\n",
      "Requirement already satisfied: gpytorch>=0.3.5 in /usr/local/lib/python3.6/dist-packages (from botorch==0.1.3) (0.3.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from botorch==0.1.3) (1.3.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.2->botorch==0.1.3) (1.17.2)\n",
      "Building wheels for collected packages: botorch\n",
      "  Building wheel for botorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for botorch: filename=botorch-0.1.3-cp36-none-any.whl size=172334 sha256=736d1932c66526b37139f2630e0323f825e9a36e33b908dffe3f858c69af3300\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-cxtlckhw/wheels/d8/0e/3f/502176509633fec729eabc1a42e465b3603faf0c30b4782f33\n",
      "Successfully built botorch\n",
      "Installing collected packages: botorch\n",
      "  Found existing installation: botorch 0.1.3\n",
      "    Uninstalling botorch-0.1.3:\n",
      "      Successfully uninstalled botorch-0.1.3\n",
      "Successfully installed botorch-0.1.3\n",
      "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.6/dist-packages (1.3.8)\n",
      "Collecting setproctitle\n",
      "  Downloading https://files.pythonhosted.org/packages/5a/0d/dc0d2234aacba6cf1a729964383e3452c52096dc695581248b548786f2b3/setproctitle-1.1.10.tar.gz\n",
      "Building wheels for collected packages: setproctitle\n",
      "  Building wheel for setproctitle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for setproctitle: filename=setproctitle-1.1.10-cp36-cp36m-linux_x86_64.whl size=33929 sha256=ab0637e76de751ee03e1375b271449ce7a97ef1bee992c5640a10de9dedbf349\n",
      "  Stored in directory: /root/.cache/pip/wheels/e6/b1/a6/9719530228e258eba904501fef99d5d85c80d52bd8f14438a3\n",
      "Successfully built setproctitle\n",
      "Installing collected packages: setproctitle\n",
      "Successfully installed setproctitle-1.1.10\n",
      "Collecting ray[rllib]\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/d1/3490a0361d6127ea794c8cc7d0495fc4e1bfb9e06dd5b565c7fb9b23df2d/ray-0.7.4-cp36-cp36m-manylinux1_x86_64.whl (74.9MB)\n",
      "\u001b[K     |████████████████████████████████| 74.9MB 421kB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (1.17.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (3.0.12)\n",
      "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (3.6.4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (3.13)\n",
      "Collecting funcsigs (from ray[rllib])\n",
      "  Downloading https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (2.6.0)\n",
      "Requirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (1.12.0)\n",
      "Collecting protobuf>=3.8.0 (from ray[rllib])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/f4/a27952733796330cd17c17ea1f974459f5fefbbad119c0f296a6d807fec3/protobuf-3.9.1-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2MB 29.4MB/s \n",
      "\u001b[?25hCollecting colorama (from ray[rllib])\n",
      "  Downloading https://files.pythonhosted.org/packages/4f/a6/728666f39bfff1719fc94c481890b2106837da9318031f71a8424b662e12/colorama-0.4.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (7.0)\n",
      "Collecting redis>=3.3.2 (from ray[rllib])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/64/b1e90af9bf0c7f6ef55e46b81ab527b33b785824d65300bb65636534b530/redis-3.3.8-py2.py3-none-any.whl (66kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 16.8MB/s \n",
      "\u001b[?25hCollecting lz4; extra == \"rllib\" (from ray[rllib])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/c6/96bbb3525a63ebc53ea700cc7d37ab9045542d33b4d262d0f0408ad9bbf2/lz4-2.1.10-cp36-cp36m-manylinux1_x86_64.whl (385kB)\n",
      "\u001b[K     |████████████████████████████████| 389kB 50.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: gym[atari]; extra == \"rllib\" in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (0.10.11)\n",
      "Collecting opencv-python-headless; extra == \"rllib\" (from ray[rllib])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/dc/b250f03ab68068033fd2356428c1357431d8ebc6a26405098e0f27c94f7a/opencv_python_headless-4.1.1.26-cp36-cp36m-manylinux1_x86_64.whl (22.1MB)\n",
      "\u001b[K     |████████████████████████████████| 22.1MB 37.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy; extra == \"rllib\" in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (1.3.1)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[rllib]) (7.2.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[rllib]) (1.3.0)\n",
      "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[rllib]) (1.8.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->ray[rllib]) (41.2.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[rllib]) (19.1.0)\n",
      "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[rllib]) (0.7.1)\n",
      "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari]; extra == \"rllib\"->ray[rllib]) (2.21.0)\n",
      "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari]; extra == \"rllib\"->ray[rllib]) (1.4.3)\n",
      "Requirement already satisfied: Pillow; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]; extra == \"rllib\"->ray[rllib]) (4.3.0)\n",
      "Requirement already satisfied: PyOpenGL; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]; extra == \"rllib\"->ray[rllib]) (3.1.0)\n",
      "Requirement already satisfied: atari-py>=0.1.4; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]; extra == \"rllib\"->ray[rllib]) (0.1.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari]; extra == \"rllib\"->ray[rllib]) (2019.6.16)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari]; extra == \"rllib\"->ray[rllib]) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari]; extra == \"rllib\"->ray[rllib]) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari]; extra == \"rllib\"->ray[rllib]) (1.24.3)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym[atari]; extra == \"rllib\"->ray[rllib]) (0.16.0)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow; extra == \"atari\"->gym[atari]; extra == \"rllib\"->ray[rllib]) (0.46)\n",
      "Installing collected packages: funcsigs, protobuf, colorama, redis, lz4, opencv-python-headless, ray\n",
      "  Found existing installation: protobuf 3.7.1\n",
      "    Uninstalling protobuf-3.7.1:\n",
      "      Successfully uninstalled protobuf-3.7.1\n",
      "Successfully installed colorama-0.4.1 funcsigs-1.0.2 lz4-2.1.10 opencv-python-headless-4.1.1.26 protobuf-3.9.1 ray-0.7.4 redis-3.3.8\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "google"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling pyarrow-0.14.1:\n",
      "  Successfully uninstalled pyarrow-0.14.1\n"
     ]
    }
   ],
   "source": [
    "# !kill -9 -1\n",
    "# memory footprint support libraries/code\n",
    "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "!pip install gputil\n",
    "!pip install psutil\n",
    "!pip install humanize\n",
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "GPUs = GPU.getGPUs()\n",
    "# XXX: only one GPU on Colab and isn’t guaranteed\n",
    "# gpu = GPUs[0]\n",
    "# def printm():\n",
    "#  process = psutil.Process(os.getpid())\n",
    "#  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    "#  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "# printm()\n",
    "\n",
    "\n",
    "\n",
    "# !pip install -U --target=/usr/local/lib/python3.6/dist-packages git+https://github.com/pytorch/botorch.git\n",
    "\n",
    "# !pip install -U -q torch==1.2.0 torchvision\n",
    "\n",
    "# !pip install -U scikit-learn\n",
    "# !pip install -U --target=/usr/local/lib/python3.6/dist-packages git+https://github.com/anhhuyalex/Ax.git\n",
    "  \n",
    "!pip install -U --target=/usr/local/lib/python3.6/dist-packages git+https://github.com/anhhuyalex/Ax.git\n",
    "  \n",
    "  \n",
    "%cd /content\n",
    "# %cd /usr/local/lib/python3.6/dist-packages\n",
    "!rm -rf botorch\n",
    "%cd /content\n",
    "!git clone https://github.com/pytorch/botorch.git\n",
    "%cd botorch\n",
    "!pip install .\n",
    "\n",
    "!pip install sqlalchemy\n",
    "!pip install setproctitle\n",
    "!pip install ray[rllib]  # also recommended: ray[debug]\n",
    "!pip uninstall -y pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 42447,
     "status": "ok",
     "timestamp": 1568435783617,
     "user": {
      "displayName": "Huy Nguyen",
      "photoUrl": "",
      "userId": "05352249580863404953"
     },
     "user_tz": -420
    },
    "id": "uJuszQGG_m1D",
    "outputId": "2e58003c-c2ef-4e6c-b9bc-c7d5335fe2b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13545,
     "status": "ok",
     "timestamp": 1568435799137,
     "user": {
      "displayName": "Huy Nguyen",
      "photoUrl": "",
      "userId": "05352249580863404953"
     },
     "user_tz": -420
    },
    "id": "lIKufxcqJZzf",
    "outputId": "69c21418-986a-4cec-ba24-5e03d5dc4d6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "Cloning into 'renormalization'...\n",
      "remote: Enumerating objects: 273, done.\u001b[K\n",
      "remote: Counting objects: 100% (273/273), done.\u001b[K\n",
      "remote: Compressing objects: 100% (151/151), done.\u001b[K\n",
      "remote: Total 273 (delta 160), reused 219 (delta 106), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (273/273), 643.62 KiB | 3.12 MiB/s, done.\n",
      "Resolving deltas: 100% (160/160), done.\n"
     ]
    }
   ],
   "source": [
    "%cd /content/\n",
    "!git clone https://github.com/anhhuyalex/renormalization.git\n",
    "!cp /content/drive/My\\ Drive/Year\\ 4\\:\\ Synthesis/NS162\\:\\ Statistical\\ Mechanics/Renormalization\\ Research\\ Project/renormalization/supervised_convnet/t_2.269/3x3/ising81x81_temp2.269_uncorrelated9x9.npy /content/renormalization/supervised_convnet/t_2.269/3x3\n",
    "!cp /content/drive/My\\ Drive/Year\\ 4\\:\\ Synthesis/NS162\\:\\ Statistical\\ Mechanics/Renormalization\\ Research\\ Project/renormalization/supervised_convnet/t_2.269/ising81x81_temp2.269.npy /content/renormalization/supervised_convnet/t_2.269      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2766,
     "status": "ok",
     "timestamp": 1568435829104,
     "user": {
      "displayName": "Huy Nguyen",
      "photoUrl": "",
      "userId": "05352249580863404953"
     },
     "user_tz": -420
    },
    "id": "NU7OJp_nAbkW",
    "outputId": "42567a1c-79db-40dd-a6d6-f72dc8521eaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/renormalization/supervised_convnet/t_2.269/3x3\n"
     ]
    }
   ],
   "source": [
    "%cd /content/renormalization/supervised_convnet/t_2.269/3x3\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "import ray\n",
    "\n",
    "from ax import RangeParameter, ParameterType\n",
    "from ax.service.ax_client import AxClient\n",
    "from ax.plot.contour import plot_contour\n",
    "from ax.plot.trace import optimization_trace_single_method\n",
    "from ax.service.managed_loop import optimize\n",
    "from ax.utils.notebook.plotting import render, init_notebook_plotting\n",
    "\n",
    "import sys\n",
    "import time\n",
    "sys.path.insert(0, \"../../\")\n",
    "import supervised_convnet\n",
    "import train, frozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "SbOqeR18C56q"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "num_hidden_layers = 1\n",
    "out_channels = 1\n",
    "num_workers = 2\n",
    "num_times = 8\n",
    "run_mode = \"unfrozen_convolution_2_channels\"\n",
    "n_loops = 3000\n",
    "save_loop = min(n_loops, 2)\n",
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4268,
     "status": "ok",
     "timestamp": 1568435830670,
     "user": {
      "displayName": "Huy Nguyen",
      "photoUrl": "",
      "userId": "05352249580863404953"
     },
     "user_tz": -420
    },
    "id": "yH3jfmeHU625",
    "outputId": "7ba0e906-8d9e-4aa4-c088-a7daf11dcd3f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-14 04:37:08,641\tINFO resource_spec.py:205 -- Starting Ray with 3.56 GiB memory available for workers and up to 1.8 GiB for objects. You can adjust these settings with ray.remote(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    }
   ],
   "source": [
    "# Start Ray.\n",
    "ray.init()\n",
    "#ray.init(num_gpus=1)\n",
    "\n",
    "# GPU for use in colab\n",
    "def model_to_cuda(model):\n",
    "    if use_cuda and torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "    return model\n",
    "\n",
    "# @ray.remote(num_gpus = 1/num_workers)\n",
    "@ray.remote\n",
    "def init_model_and_train(hidden_size, batch_size, train_size, n_epochs, lr, weight_decay,\n",
    "            betas0, betas1, seed, use_cuda):\n",
    "    # Parameters\n",
    "    num_hidden_layers = 1\n",
    "    out_channels = 1\n",
    "\n",
    "\n",
    "    if run_mode == \"unfrozen_convolution_relu\":\n",
    "        model = supervised_convnet.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n",
    "                hidden_size = hidden_size, out_channels = out_channels,\n",
    "                first_activation = \"tanh\", activation_func = \"relu\",\n",
    "                num_hidden_layers = num_hidden_layers, seed = seed)\n",
    "        model = model_to_cuda(model)\n",
    "        results = train.trainer(model = model, batch_size = batch_size, train_size = train_size, n_epochs = n_epochs, lr = lr,\n",
    "                    weight_decay = weight_decay,\n",
    "                    betas0 = 1-betas0, betas1 = 1-betas1, use_cuda = use_cuda)\n",
    "    elif run_mode == \"frozen_convolution_no_center_relu\":\n",
    "        model = frozen.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n",
    "                hidden_size = hidden_size, out_channels = out_channels,\n",
    "                center = \"omit\", first_activation = \"tanh\",\n",
    "                activation_func = \"relu\", num_hidden_layers = num_hidden_layers)\n",
    "        model = model_to_cuda(model)\n",
    "        results = train.trainer(model = model, batch_size = batch_size, train_size = train_size, n_epochs = n_epochs, lr = lr,\n",
    "                    weight_decay = weight_decay,\n",
    "                    betas0 = 1-betas0, betas1 = 1-betas1, use_cuda = use_cuda)\n",
    "    elif run_mode == \"frozen_convolution_pretrained_relu\":\n",
    "        model = frozen.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n",
    "                hidden_size = hidden_size, out_channels = out_channels,\n",
    "                center = \"pre_trained\", first_activation = \"tanh\",\n",
    "                activation_func = \"relu\", num_hidden_layers = num_hidden_layers)\n",
    "        model = model_to_cuda(model)\n",
    "        results = train.trainer(model = model, batch_size = batch_size, train_size = train_size, n_epochs = n_epochs, lr = lr,\n",
    "                    weight_decay = weight_decay,\n",
    "                    betas0 = 1-betas0, betas1 = 1-betas1, use_cuda = use_cuda)\n",
    "    elif run_mode == \"unfrozen_convolution_2_channels\":\n",
    "        out_channels = 2\n",
    "        model = supervised_convnet.SupervisedConvNet(filter_size = 3, square_size = 3,\n",
    "                hidden_size = hidden_size, out_channels = out_channels,\n",
    "                first_activation = \"tanh\", activation_func = \"relu\",\n",
    "                num_hidden_layers = num_hidden_layers, seed = seed)\n",
    "        model = model_to_cuda(model)\n",
    "        results = train.trainer(model = model, batch_size = batch_size, train_size = train_size, n_epochs = n_epochs, lr = lr,\n",
    "                    weight_decay = weight_decay,\n",
    "                    betas0 = 1-betas0, betas1 = 1-betas1, use_cuda = use_cuda)\n",
    "    return (results[0])\n",
    "\n",
    "\n",
    "\n",
    "def train_evaluate(parameterization, use_cuda = use_cuda):\n",
    "    # parameters\n",
    "    batch_size = parameterization[\"batch_size\"]\n",
    "    train_size = parameterization[\"train_size\"]\n",
    "    n_epochs = parameterization[\"n_epochs\"]\n",
    "    lr = parameterization[\"lr\"]\n",
    "    weight_decay = parameterization[\"weight_decay\"]\n",
    "    betas0 = parameterization[\"betas0\"]\n",
    "    betas1 = parameterization[\"betas1\"]\n",
    "    hidden_size = 10\n",
    "    use_cuda = use_cuda\n",
    "\n",
    "    results = []\n",
    "    # Start 4 tasks in parallel.\n",
    "    for _ in range(num_times):\n",
    "        result_ids = []\n",
    "        for seed in range(num_workers):\n",
    "            result_ids.append(init_model_and_train.remote(hidden_size, batch_size, train_size,\n",
    "            n_epochs, lr, weight_decay, betas0, betas1,\n",
    "            time.time() + seed, use_cuda))\n",
    "\n",
    "        # Wait for the tasks to complete and retrieve the results.\n",
    "        # With at least 4 cores, this will take 1 second.\n",
    "        results.append(ray.get(result_ids))  # [0, 1, 2, 3]\n",
    "\n",
    "    # results = []\n",
    "    # for seed in range(num_workers):\n",
    "    #     results.append(init_model_and_train(hidden_size, batch_size, train_size,\n",
    "    #     n_epochs, lr, weight_decay, betas0, betas1,\n",
    "    #     time.time() + seed))\n",
    "\n",
    "    print (\"results\", results)\n",
    "    mean = np.mean(results)\n",
    "    SEM = np.std(results)/np.sqrt(len(results))\n",
    "    # pool.close() # no more tasks\n",
    "    # pool.join()  # wrap up current tasks\n",
    "    return {\"objective\": (mean, SEM)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "QaA_x4e0VhwV"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Initialize client\n",
    "ax_client = AxClient()\n",
    "try:\n",
    "    with open(f\"/content/drive/My Drive/Year 4: Synthesis/NS162: Statistical Mechanics/Renormalization Research Project/renormalization/supervised_convnet/t_2.269/3x3/colab/hyperparameters_{run_mode}.pl\", \"rb\") as handle:\n",
    "        hyper = pickle.load(handle)\n",
    "    v = hyper[\"axclient\"].copy()\n",
    "    ax_client = ax_client.from_json_snapshot(v)\n",
    "except:\n",
    "    ax_client.create_experiment(\n",
    "        parameters=[\n",
    "            {\n",
    "              \"name\": \"batch_size\",\n",
    "              \"type\": \"range\",\n",
    "              \"bounds\": [1, 5000],\n",
    "              \"value_type\": \"int\"\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"train_size\",\n",
    "              \"type\": \"range\",\n",
    "              \"bounds\": [100, 5000],\n",
    "              \"value_type\": \"int\"\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"n_epochs\",\n",
    "              \"type\": \"range\",\n",
    "              \"bounds\": [50, 250],\n",
    "              \"value_type\": \"int\"\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"lr\",\n",
    "              \"type\": \"range\",\n",
    "              \"bounds\": [1e-4, 1],\n",
    "              \"value_type\": \"float\",\n",
    "              \"log_scale\": True\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"weight_decay\",\n",
    "              \"type\": \"range\",\n",
    "              \"bounds\": [1e-5, 2e-1],\n",
    "              \"value_type\": \"float\",\n",
    "              \"log_scale\": True\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"betas0\",\n",
    "              \"type\": \"range\",\n",
    "              \"bounds\": [1e-5, 2e-1],\n",
    "              \"value_type\": \"float\",\n",
    "              \"log_scale\": True\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"betas1\",\n",
    "              \"type\": \"range\",\n",
    "              \"bounds\": [1e-5, 2e-1],\n",
    "              \"value_type\": \"float\",\n",
    "              \"log_scale\": True\n",
    "            }\n",
    "        ],\n",
    "        parameter_constraints=[\"0.02 * train_size + -1 * batch_size <= 0\", \"train_size >= batch_size\"],\n",
    "        minimize=False,\n",
    "        objective_name=\"objective\",\n",
    "        outcome_constraints=None,\n",
    "        name=\"Test\"\n",
    "    )\n",
    "\n",
    "# print (\"axclient\",ax_client.experiment.trials )\n",
    "# for loop in range(n_loops):\n",
    "for loop in range(n_loops):\n",
    "    print(f\"Running trial {loop}/{n_loops}...\")\n",
    "    parameters, trial_index = ax_client.get_next_trial()\n",
    "    print(\"trial_index\", trial_index)\n",
    "#     time.sleep(2)\n",
    "    # parameters[\"n_epochs\"] = 5\n",
    "     # Local evaluation here can be replaced with deployment to external system.\n",
    "    ax_client.complete_trial(trial_index=trial_index, raw_data=train_evaluate(parameters))\n",
    "    print(\"Best params\", ax_client.get_best_parameters())\n",
    "    # periodic save\n",
    "    if loop % save_loop == (save_loop - 1):\n",
    "        optim_result = ax_client.get_best_parameters()\n",
    "        # print(\"best_parameters\", optim_result)\n",
    "        # print(\"was I saved?\", ax._save_experiment_and_generation_strategy_if_possible())\n",
    "        hyper = {}\n",
    "        hyper[\"best_params\"] = optim_result\n",
    "        hyper[\"axclient\"] = ax_client.to_json_snapshot()\n",
    "        # print(\"optim_result\", optim_result)\n",
    "        with open(f\"/content/drive/My Drive/Year 4: Synthesis/NS162: Statistical Mechanics/Renormalization Research Project/renormalization/supervised_convnet/t_2.269/3x3/colab/hyperparameters_{run_mode}.pl\", \"wb\") as handle:\n",
    "            pickle.dump(hyper, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "tSkjTcdXeQGW"
   },
   "outputs": [],
   "source": [
    " i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 501,
     "status": "ok",
     "timestamp": 1567102070267,
     "user": {
      "displayName": "Huy Nguyen",
      "photoUrl": "",
      "userId": "05352249580863404953"
     },
     "user_tz": -420
    },
    "id": "RlD8t6QGezlS",
    "outputId": "3e6bd6fb-a953-4b3f-e802-e24093adf78b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/drive/My Drive/Year 4: Synthesis/NS162: Statistical Mechanics/Renormalization Research Project/renormalization/supervised_convnet/t_2.269/3x3/train.py'"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1054,
     "status": "error",
     "timestamp": 1567672130666,
     "user": {
      "displayName": "Huy Nguyen",
      "photoUrl": "",
      "userId": "05352249580863404953"
     },
     "user_tz": -420
    },
    "id": "rkBEK0uzj-sv",
    "outputId": "729cf094-2937-4523-a3a7-3f317f2fa7ef"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a68ed25944c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"/content/drive/My Drive/Year 4: Synthesis/NS162: Statistical Mechanics/Renormalization Research Project/renormalization/supervised_convnet/t_2.269/colab/hyperparameters_{run_mode}.pl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/Year 4: Synthesis/NS162: Statistical Mechanics/Renormalization Research Project/renormalization/supervised_convnet/t_2.269/colab/hyperparameters_unfrozen_convolution_relu.pl'"
     ]
    }
   ],
   "source": [
    "open(f\"/content/drive/My Drive/Year 4: Synthesis/NS162: Statistical Mechanics/Renormalization Research Project/renormalization/supervised_convnet/t_2.269/colab/hyperparameters_{run_mode}.pl\", \"wb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1036,
     "status": "ok",
     "timestamp": 1567672244336,
     "user": {
      "displayName": "Huy Nguyen",
      "photoUrl": "",
      "userId": "05352249580863404953"
     },
     "user_tz": -420
    },
    "id": "fly_JhV0ilbX",
    "outputId": "5db22b03-3da2-4528-b7fb-5228e6532e56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedWriter name='/content/drive/My Drive/Year 4: Synthesis/NS162: Statistical Mechanics/Renormalization Research Project/renormalization/supervised_convnet/t_2.269/hyperparameters_unfrozen_convolution_relu.pl'>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(f\"/content/drive/My Drive/Year 4: Synthesis/NS162: Statistical Mechanics/Renormalization Research Project/renormalization/supervised_convnet/t_2.269/hyperparameters_{run_mode}.pl\", \"wb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "aczCEhOQirGb"
   },
   "outputs": [],
   "source": [
    "with open(f\"/content/drive/My Drive/Year 4: Synthesis/NS162: Statistical Mechanics/Renormalization Research Project/renormalization/supervised_convnet/t_2.269/hyperparameters_{run_mode}.pl\", \"wb\") as handle:\n",
    "    pickle.dump(hyper, handle, protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5091,
     "status": "ok",
     "timestamp": 1567675571405,
     "user": {
      "displayName": "Huy Nguyen",
      "photoUrl": "",
      "userId": "05352249580863404953"
     },
     "user_tz": -420
    },
    "id": "FZqjHc5HvCIr",
    "outputId": "daf381f3-12d1-45f8-c6c4-9f2838fa498b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3x3\t        generate_uncorrelated_data.py\t\t       runs\n",
      " 81x81\t        hyperparameters_unfrozen_convolution_relu.pl\n",
      "'9x9->3x3.pt'   ising81x81_temp2.269.npy\n"
     ]
    }
   ],
   "source": [
    "!ls /content/drive/My\\ Drive/Year\\ 4:\\ Synthesis/NS162:\\ Statistical\\ Mechanics/Renormalization\\ Research\\ Project/renormalization/supervised_convnet/t_2.269/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Xv9ZRNCqvUnx"
   },
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "0oCXPjxqre5c"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hyperopt.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
