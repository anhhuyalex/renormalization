{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"distribution.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"gVq8WMGt6hio","colab_type":"code","colab":{}},"source":["!pip install sqlalchemy\n","!pip install setproctitle\n","!pip install ray[rllib]  # also recommended: ray[debug]\n","!pip uninstall -y pyarrow"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HrbCG_Qc8cKg","colab_type":"code","outputId":"083e6c5d-d721-42fa-958d-33b97f19c271","executionInfo":{"status":"ok","timestamp":1568356679141,"user_tz":-420,"elapsed":24110,"user":{"displayName":"Huy Nguyen","photoUrl":"","userId":"05352249580863404953"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","%cd  /content/drive/My\\ Drive/Year\\ 4\\:\\ Synthesis/NS162\\:\\ Statistical\\ Mechanics/Renormalization\\ Research\\ Project/renormalization/supervised_convnet/t_2.269/3x3/"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n","/content/drive/My Drive/Year 4: Synthesis/NS162: Statistical Mechanics/Renormalization Research Project/renormalization/supervised_convnet/t_2.269/3x3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_5iNza3_8jQc","colab_type":"code","outputId":"1d98dbf3-6a12-43ae-e3aa-62f33046523a","executionInfo":{"status":"error","timestamp":1568356729155,"user_tz":-420,"elapsed":11755,"user":{"displayName":"Huy Nguyen","photoUrl":"","userId":"05352249580863404953"}},"colab":{"base_uri":"https://localhost:8080/","height":673}},"source":["%%capture\n","import train, frozen\n","import sys\n","sys.path.insert(0, \"../../\")\n","import supervised_convnet\n","import pickle\n","from collections import defaultdict\n","import numpy as np\n","import time\n","import torch\n","\n","mode = \"run\"\n","run_mode = \"unfrozen_convolution_many_channels\"\n","save_loops = 50\n","use_cuda = True\n","results = []\n","conv_params = {}\n","filename = \"\"\n","def save_progress(results, conv_params, filename, epoch = 500):\n","    new_results = {}\n","    new_results[\"best_val_acc_hist\"] = results\n","    new_results[\"conv_params\"] = conv_params\n","    new_results[\"annotation\"] = \"bias + weights histogram saved\"\n","    new_results[\"epoch\"] = epoch\n","    # new_results[\"first_epo    ch_validate_accuracy_list\"] = first_epoch_validate_accuracy_list\n","    with open(filename, \"wb\") as handle:\n","        pickle.dump(new_results, handle, protocol = pickle.HIGHEST_PROTOCOL)\n","\"\"\"\n","Default activation function: sigmoid\n","\"\"\"\n","\n","# GPU for use in colab\n","def model_to_cuda(model):\n","    if use_cuda and torch.cuda.is_available():\n","        model = model.cuda()\n","    return model\n","  \n","if mode == \"run\":\n","    hidden_size = 10\n","    out_channels = 1\n","    num_hidden_layers = 1\n","    conv_params = defaultdict(list)\n","\n","    if run_mode == \"unfrozen_convolution\":\n","        \"\"\"\n","        \"\"\"\n","        out_channels = 1\n","        filename = \"unfrozen_convolution.pl\"\n","        try:\n","            with open(filename, \"rb\") as handle:\n","                results = pickle.load(handle)\n","        except:\n","            results = []\n","        for _ in range(500):\n","            model = supervised_convnet.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","                    hidden_size = hidden_size, out_channels = out_channels,\n","                    activation_func = \"sigmoid\", num_hidden_layers = num_hidden_layers)\n","            best_val_acc, param_dict, first_epoch_validate_accuracy = train.trainer(model = model)\n","            results.append(best_val_acc)\n","            conv_params[\"weight\"].append(param_dict[\"conv1.weight\"])\n","            conv_params[\"bias\"].append(param_dict[\"conv1.bias\"])\n","    elif run_mode == \"unfrozen_convolution_relu\":\n","        \"\"\"\n","        \"\"\"\n","        out_channels = 1\n","        filename = \"unfrozen_convolution_relu.pl\"\n","        try:\n","            with open(filename, \"rb\") as handle:\n","                results = pickle.load(handle)\n","        except:\n","            results = []\n","        results = []\n","        first_epoch_validate_accuracy_list = []\n","        for _ in range(500):\n","            model = supervised_convnet.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","                    hidden_size = hidden_size, out_channels = out_channels,\n","                    first_activation = \"tanh\", activation_func = \"relu\",\n","                    num_hidden_layers = num_hidden_layers, seed = time.time() + _)\n","            model = model_to_cuda(model)\n","            best_val_acc, param_dict = train.trainer(model = model, batch_size = 86, betas0= 1-0.0018179320494754046, betas1=1- 0.001354073715524798,\n","                                                    lr= 0.004388469485690077, n_epochs= 250, train_size= 4277, weight_decay= 2.346792703571872e-05, use_cuda = use_cuda)\n","            results.append(best_val_acc)\n","            conv_params[\"weight\"].append(param_dict[\"conv1.weight\"])\n","            conv_params[\"bias\"].append(param_dict[\"conv1.bias\"])\n","            if (_ % save_loops) == (0):\n","                save_progress(results, conv_params, filename, _)\n","    elif run_mode == \"frozen_convolution_no_center\":\n","        \"\"\"\n","        \"\"\"\n","        out_channels = 1\n","        filename = \"frozen_convolution_no_center.pl\"\n","        try:\n","            with open(filename, \"rb\") as handle:\n","                results = pickle.load(handle)\n","        except:\n","            results = []\n","        for _ in range(500):\n","            model = frozen.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","                    hidden_size = hidden_size, out_channels = out_channels,\n","                    center = \"omit\", activation_func = \"sigmoid\", num_hidden_layers = num_hidden_layers)\n","            model = model_to_cuda(model)\n","            best_val_acc, param_dict, first_epoch_validate_accuracy = train.trainer(model = model)\n","            results.append(best_val_acc)\n","            if (_ % save_loops) == (0):\n","                save_progress(results, conv_params, filename, _)\n","    elif run_mode == \"frozen_convolution_no_center_relu\":\n","        \"\"\"\n","        \"\"\"\n","        filename = \"frozen_convolution_no_center_relu.pl\"\n","        out_channels = 1\n","        try:\n","            with open(filename, \"rb\") as handle:\n","                results = pickle.load(handle)\n","        except:\n","            results = []\n","        results = []\n","        for _ in range(500):\n","            model = frozen.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","                    hidden_size = hidden_size, out_channels = out_channels,\n","                    center = \"omit\", first_activation = \"tanh\",\n","                    activation_func = \"relu\", num_hidden_layers = num_hidden_layers)\n","            model = model_to_cuda(model)\n","            best_val_acc, param_dict = train.trainer(model = model, batch_size = 100, betas0=1- 0.15428681703555264, betas1=1-1e-5,\n","                                                    lr= 0.021919796543990972, n_epochs= 250, train_size= 5000, weight_decay= 0.0008230830669560186, use_cuda = use_cuda)\n","            # conv_params[\"weight\"].append(param_dict[\"conv1.weight\"])\n","            conv_params[\"bias\"].append(param_dict[\"conv1.bias\"])\n","            results.append(best_val_acc)\n","            if (_ % save_loops) == (0):\n","                save_progress(results, conv_params, filename, _)\n","    elif run_mode == \"frozen_convolution_with_center\":\n","        \"\"\"\n","        \"\"\"\n","        filename = \"frozen_convolution_with_center.pl\"\n","        out_channels = 1\n","        try:\n","            with open(filename, \"rb\") as handle:\n","                results = pickle.load(handle)\n","        except:\n","            results = []\n","        for _ in range(500):\n","            model = frozen.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","                    hidden_size = hidden_size, out_channels = out_channels,\n","                    center = \"keep\", activation_func = \"sigmoid\", num_hidden_layers = num_hidden_layers)\n","            best_val_acc, param_dict, first_epoch_validate_accuracy = train.trainer(model = model)\n","            results.append(best_val_acc)\n","    elif run_mode == \"frozen_convolution_with_center_relu\":\n","        \"\"\"\n","        \"\"\"\n","        filename = \"frozen_convolution_with_center_relu.pl\"\n","        out_channels = 1\n","        try:\n","            with open(filename, \"rb\") as handle:\n","                results = pickle.load(handle)\n","        except:\n","            results = []\n","        for _ in range(500):\n","            model = frozen.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","                    hidden_size = hidden_size, out_channels = out_channels,\n","                    center = \"keep\", activation_func = \"relu\", num_hidden_layers = num_hidden_layers)\n","            best_val_acc, param_dict, first_epoch_validate_accuracy = train.trainer(model = model)\n","            results.append(best_val_acc)\n","    elif run_mode == \"frozen_convolution_pretrained_relu\":\n","        \"\"\"\n","        \"\"\"\n","        filename = \"frozen_convolution_pretrained_relu.pl\"\n","        out_channels = 1\n","        try:\n","            with open(filename, \"rb\") as handle:\n","                results = pickle.load(handle)\n","        except:\n","            results = []\n","        results = []\n","        first_epoch_validate_accuracy_list = []\n","        for _ in range(500):\n","            model = frozen.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","                    hidden_size = hidden_size, out_channels = out_channels,\n","                    center = \"pre_trained\", first_activation = \"tanh\",\n","                    activation_func = \"relu\", num_hidden_layers = num_hidden_layers)\n","            best_val_acc, param_dict = train.trainer(model = model, lr = 0.005)\n","            results.append(best_val_acc)\n","    elif run_mode == \"unfrozen_convolution_many_channels\":\n","        \"\"\"\n","        check to make sure that out_channels below is not 1\n","        \"\"\"\n","        out_channels = 3\n","        filename = \"unfrozen_convolution_{}_channels.pl\".format(out_channels)\n","        print(\"filename\", filename)\n","        try:\n","            with open(filename, \"rb\") as handle:\n","                results = pickle.load(handle)\n","        except:\n","            results = []\n","        for _ in range(500):\n","            model = supervised_convnet.SupervisedConvNet(filter_size = 3, square_size = 3,\n","                    hidden_size = hidden_size, out_channels = out_channels,\n","                    activation_func = \"sigmoid\", num_hidden_layers = num_hidden_layers,\n","                    seed = time.time() + _)\n","            best_val_acc, param_dict = train.trainer(model = model, batch_size = 100, betas0= 1-0.08600510236382716, betas1= 1-0.148443948081689,\n","                                                    lr= 0.0007024370411205373, n_epochs= 250, train_size= 5000, weight_decay= 1.000000000004125e-05, use_cuda = use_cuda)\n","            results.append(best_val_acc)\n","            conv_params[\"weight\"].append(param_dict[\"conv1.weight\"])\n","            conv_params[\"bias\"].append(param_dict[\"conv1.bias\"])\n","            if (_ % save_loops) == (0):\n","                save_progress(results, conv_params, filename, _)\n","    elif run_mode == \"unfrozen_convolution_many_channels_relu\":\n","        \"\"\"\n","        check to make sure that out_channels below is not 1\n","        \"\"\"\n","        out_channels = 2\n","        filename = \"unfrozen_convolution_{}_channels_relu.pl\".format(out_channels)\n","        print(\"filename\", filename)\n","        try:\n","            with open(filename, \"rb\") as handle:\n","                results = pickle.load(handle)\n","        except:\n","            results = []\n","        for _ in range(500):\n","            model = supervised_convnet.SupervisedConvNet(filter_size = 3, square_size = 3,\n","                    hidden_size = hidden_size, out_channels = out_channels,\n","                    first_activation = \"tanh\", activation_func = \"relu\",\n","                    num_hidden_layers = num_hidden_layers, seed = time.time() + _)\n","            best_val_acc, param_dict = train.trainer(model = model)\n","            results.append(best_val_acc)\n","            conv_params[\"weight\"].append(param_dict[\"conv1.weight\"])\n","            conv_params[\"bias\"].append(param_dict[\"conv1.bias\"])\n","    elif run_mode == \"unfrozen_convolution_many_channel_many_hidden\":\n","        \"\"\"\n","        check to make sure that out_channels, num_hidden_layers above is not 1\n","        \"\"\"\n","        out_channels = 2\n","        num_hidden_layers = 2\n","        filename = \"unfrozen_convolution_{}_channels_{}_hidden.pl\".format(out_channels, num_hidden_layers)\n","        print(\"filename\", filename)\n","        try:\n","            with open(filename, \"rb\") as handle:\n","                results = pickle.load(handle)\n","        except:\n","            results = []\n","        for _ in range(500):\n","            model = supervised_convnet.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","                    hidden_size = hidden_size, out_channels = out_channels, num_hidden_layers = num_hidden_layers)\n","            best_val_acc, param_dict, first_epoch_validate_accuracy = train.trainer(model = model)\n","            results.append(best_val_acc)\n","            \n","\n","save_progress(results, conv_params, filename)\n","\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Uncorrelated [[ 1  1  1 -1 -1 -1  1 -1 -1]\n"," [ 1  1  1 -1 -1 -1 -1 -1 -1]\n"," [ 1  1  1 -1  1  1  1  1  1]\n"," [ 1  1 -1  1 -1 -1 -1 -1 -1]\n"," [ 1  1 -1  1 -1 -1 -1 -1 -1]\n"," [ 1  1  1  1 -1 -1 -1 -1  1]\n"," [ 1  1 -1 -1 -1 -1  1  1  1]\n"," [ 1 -1 -1 -1 -1 -1  1  1  1]\n"," [ 1  1  1 -1 -1 -1  1  1 -1]]\n","Correlated [[ 1  1 -1  1 -1 -1 -1 -1  1]\n"," [ 1  1 -1 -1 -1 -1 -1 -1 -1]\n"," [ 1  1 -1 -1 -1  1  1  1  1]\n"," [-1 -1 -1 -1 -1 -1  1  1  1]\n"," [ 1 -1 -1 -1 -1  1  1  1  1]\n"," [-1 -1 -1 -1 -1  1  1  1  1]\n"," [-1 -1 -1 -1 -1  1  1 -1 -1]\n"," [-1 -1 -1 -1 -1 -1  1  1  1]\n"," [-1 -1  1 -1 -1 -1 -1 -1  1]]\n"],"name":"stdout"},{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-666361b5c5cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Shut down previous ray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ray'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"dNnF4m19AcOs","colab_type":"code","colab":{}},"source":["i = 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oWv2KS1TV6Jw","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}