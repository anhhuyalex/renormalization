{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"colab_hyperopt_duplicate_2.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1567925631608,"user_tz":-420,"elapsed":7278,"user":{"displayName":"Huy Nguyen","photoUrl":"","userId":"05352249580863404953"}},"id":"jymXhF9qsym5","outputId":"1d85f72a-e8a7-4eb3-b4af-0f13b0322bdd","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!df -h\n","!cat /proc/cpuinfo\n","!cat /proc/meminfo"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Filesystem      Size  Used Avail Use% Mounted on\n","overlay          49G   26G   21G  56% /\n","tmpfs            64M     0   64M   0% /dev\n","tmpfs           6.4G     0  6.4G   0% /sys/fs/cgroup\n","tmpfs           6.4G  8.0K  6.4G   1% /var/colab\n","/dev/sda1        55G   28G   28G  50% /etc/hosts\n","shm             6.0G  4.0K  6.0G   1% /dev/shm\n","tmpfs           6.4G     0  6.4G   0% /proc/acpi\n","tmpfs           6.4G     0  6.4G   0% /proc/scsi\n","tmpfs           6.4G     0  6.4G   0% /sys/firmware\n","processor\t: 0\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 79\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2200.000\n","cache size\t: 56320 KB\n","physical id\t: 0\n","siblings\t: 2\n","core id\t\t: 0\n","cpu cores\t: 1\n","apicid\t\t: 0\n","initial apicid\t: 0\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4400.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 1\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 79\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2200.000\n","cache size\t: 56320 KB\n","physical id\t: 0\n","siblings\t: 2\n","core id\t\t: 0\n","cpu cores\t: 1\n","apicid\t\t: 1\n","initial apicid\t: 1\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4400.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","MemTotal:       13335192 kB\n","MemFree:        11052804 kB\n","MemAvailable:   12522472 kB\n","Buffers:           74036 kB\n","Cached:          1557936 kB\n","SwapCached:            0 kB\n","Active:           676740 kB\n","Inactive:        1362928 kB\n","Active(anon):     388416 kB\n","Inactive(anon):      304 kB\n","Active(file):     288324 kB\n","Inactive(file):  1362624 kB\n","Unevictable:           0 kB\n","Mlocked:               0 kB\n","SwapTotal:             0 kB\n","SwapFree:              0 kB\n","Dirty:               648 kB\n","Writeback:             0 kB\n","AnonPages:        407832 kB\n","Mapped:           216220 kB\n","Shmem:               840 kB\n","Slab:             149552 kB\n","SReclaimable:     119484 kB\n","SUnreclaim:        30068 kB\n","KernelStack:        3488 kB\n","PageTables:         5280 kB\n","NFS_Unstable:          0 kB\n","Bounce:                0 kB\n","WritebackTmp:          0 kB\n","CommitLimit:     6667596 kB\n","Committed_AS:    2722912 kB\n","VmallocTotal:   34359738367 kB\n","VmallocUsed:           0 kB\n","VmallocChunk:          0 kB\n","AnonHugePages:         0 kB\n","ShmemHugePages:        0 kB\n","ShmemPmdMapped:        0 kB\n","HugePages_Total:       0\n","HugePages_Free:        0\n","HugePages_Rsvd:        0\n","HugePages_Surp:        0\n","Hugepagesize:       2048 kB\n","DirectMap4k:       63476 kB\n","DirectMap2M:     6227968 kB\n","DirectMap1G:     9437184 kB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"A_wAj6vUdOya","outputId":"353bfe49-21f3-431e-9e20-8f99b0c43e89","executionInfo":{"status":"ok","timestamp":1568106111668,"user_tz":-420,"elapsed":206071,"user":{"displayName":"Huy Nguyen","photoUrl":"","userId":"05352249580863404953"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# !kill -9 -1\n","# memory footprint support libraries/code\n","!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip install gputil\n","!pip install psutil\n","!pip install humanize\n","import psutil\n","import humanize\n","import os\n","import GPUtil as GPU\n","GPUs = GPU.getGPUs()\n","# XXX: only one GPU on Colab and isn’t guaranteed\n","# gpu = GPUs[0]\n","# def printm():\n","#  process = psutil.Process(os.getpid())\n","#  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n","#  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","# printm()\n","\n","\n","\n","# !pip install -U --target=/usr/local/lib/python3.6/dist-packages git+https://github.com/pytorch/botorch.git\n","\n","# !pip install -U -q torch==1.2.0 torchvision\n","\n","# !pip install -U scikit-learn\n","# !pip install -U --target=/usr/local/lib/python3.6/dist-packages git+https://github.com/anhhuyalex/Ax.git\n","  \n","!pip install -U --target=/usr/local/lib/python3.6/dist-packages git+https://github.com/anhhuyalex/Ax.git\n","  \n","%cd /content\n","# %cd /usr/local/lib/python3.6/dist-packages\n","!rm -rf botorch\n","%cd /content\n","!git clone https://github.com/pytorch/botorch.git\n","%cd botorch\n","!pip install .\n","\n","!pip install sqlalchemy\n","!pip install setproctitle\n","!pip install ray[rllib]  # also recommended: ray[debug]\n","!pip uninstall -y pyarrow"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting gputil\n","  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n","Building wheels for collected packages: gputil\n","  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7410 sha256=6eebef45f82465a4a478cfcfe77989541f6d27c7acdc9584058df021e8f96e89\n","  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n","Successfully built gputil\n","Installing collected packages: gputil\n","Successfully installed gputil-1.4.0\n","Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n","Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n","Collecting git+https://github.com/anhhuyalex/Ax.git\n","  Cloning https://github.com/anhhuyalex/Ax.git to /tmp/pip-req-build-c082yp_q\n","  Running command git clone -q https://github.com/anhhuyalex/Ax.git /tmp/pip-req-build-c082yp_q\n","Collecting botorch>=0.1.3 (from ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/94/15177eb5675109ebf63f18047371320dde678648bb5cd5761325c772269f/botorch-0.1.3-py3-none-any.whl (169kB)\n","\u001b[K     |████████████████████████████████| 174kB 9.6MB/s \n","\u001b[?25hCollecting jinja2 (from ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/e7/fd8b501e7a6dfe492a433deb7b9d833d39ca74916fa8bc63dd1a4947a671/Jinja2-2.10.1-py2.py3-none-any.whl (124kB)\n","\u001b[K     |████████████████████████████████| 133kB 56.7MB/s \n","\u001b[?25hCollecting pandas (from ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/9b/52e228545d14f14bb2a1622e225f38463c8726645165e1cb7dde95bfe6d4/pandas-0.25.1-cp36-cp36m-manylinux1_x86_64.whl (10.5MB)\n","\u001b[K     |████████████████████████████████| 10.5MB 57.6MB/s \n","\u001b[?25hCollecting scipy (from ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/50/a552a5aff252ae915f522e44642bb49a7b7b31677f9580cfd11bcc869976/scipy-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (25.2MB)\n","\u001b[K     |████████████████████████████████| 25.2MB 1.9MB/s \n","\u001b[?25hCollecting sklearn (from ax-platform==0.1.4)\n","  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n","Collecting plotly (from ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/19/8437e22c84083a6d5d8a3c80f4edc73c9dcbb89261d07e6bd13b48752bbd/plotly-4.1.1-py2.py3-none-any.whl (7.1MB)\n","\u001b[K     |████████████████████████████████| 7.1MB 33.5MB/s \n","\u001b[?25hCollecting torch>=1.2 (from botorch>=0.1.3->ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/57/d5cceb0799c06733eefce80c395459f28970ebb9e896846ce96ab579a3f1/torch-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (748.8MB)\n","\u001b[K     |████████████████████████████████| 748.9MB 23kB/s \n","\u001b[?25hCollecting gpytorch>=0.3.5 (from botorch>=0.1.3->ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/e4/e74dc12c6d07a5d8628dfb573b01297f7c2b44eec524be4b401c0782d39c/gpytorch-0.3.5.tar.gz (211kB)\n","\u001b[K     |████████████████████████████████| 215kB 49.7MB/s \n","\u001b[?25hCollecting MarkupSafe>=0.23 (from jinja2->ax-platform==0.1.4)\n","  Downloading https://files.pythonhosted.org/packages/b2/5f/23e0023be6bb885d00ffbefad2942bc51a620328ee910f64abe5a8d18dd1/MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl\n","Collecting pytz>=2017.2 (from pandas->ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/76/46d697698a143e05f77bec5a526bf4e56a0be61d63425b68f4ba553b51f2/pytz-2019.2-py2.py3-none-any.whl (508kB)\n","\u001b[K     |████████████████████████████████| 512kB 50.3MB/s \n","\u001b[?25hCollecting python-dateutil>=2.6.1 (from pandas->ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n","\u001b[K     |████████████████████████████████| 235kB 45.3MB/s \n","\u001b[?25hCollecting numpy>=1.13.3 (from pandas->ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/e6/c3fdc53aed9fa19d6ff3abf97dfad768ae3afce1b7431f7500000816bda5/numpy-1.17.2-cp36-cp36m-manylinux1_x86_64.whl (20.4MB)\n","\u001b[K     |████████████████████████████████| 20.4MB 1.1MB/s \n","\u001b[?25hCollecting scikit-learn (from sklearn->ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/c5/d2238762d780dde84a20b8c761f563fe882b88c5a5fb03c056547c442a19/scikit_learn-0.21.3-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n","\u001b[K     |████████████████████████████████| 6.7MB 17.8MB/s \n","\u001b[?25hCollecting retrying>=1.3.3 (from plotly->ax-platform==0.1.4)\n","  Downloading https://files.pythonhosted.org/packages/44/ef/beae4b4ef80902f22e3af073397f079c96969c69b2c7d52a57ea9ae61c9d/retrying-1.3.3.tar.gz\n","Collecting six (from plotly->ax-platform==0.1.4)\n","  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n","Collecting joblib>=0.11 (from scikit-learn->sklearn->ax-platform==0.1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl (278kB)\n","\u001b[K     |████████████████████████████████| 286kB 41.4MB/s \n","\u001b[?25hBuilding wheels for collected packages: ax-platform, sklearn, gpytorch, retrying\n","  Building wheel for ax-platform (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ax-platform: filename=ax_platform-0.1.4-cp36-cp36m-linux_x86_64.whl size=918262 sha256=bda36d79df179337d3bcf177d7cf732319da3557ded2339c7e1838796c13ce4d\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-ezeq28dp/wheels/cf/31/a7/531e4606a720574d740203ff00855672549f50a7d1b9bc736e\n","  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=a0f7a029c73a911fa72174988e29e30399049ee29801642bd0ecba8918685a8c\n","  Stored in directory: /root/.cache/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n","  Building wheel for gpytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gpytorch: filename=gpytorch-0.3.5-py2.py3-none-any.whl size=349720 sha256=0dfa7a40d5a8e8acb1c34c4b58b845ce4c8eb97862195dfdc1227d42abefd4cd\n","  Stored in directory: /root/.cache/pip/wheels/d6/31/88/c43a94e0073a54056ac663366f2195de36535b38a81a378196\n","  Building wheel for retrying (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for retrying: filename=retrying-1.3.3-cp36-none-any.whl size=11429 sha256=48dd06081740a34a2803524af51e255c9185dece9163b588b54fd2678015c3a7\n","  Stored in directory: /root/.cache/pip/wheels/d7/a9/33/acc7b709e2a35caa7d4cae442f6fe6fbf2c43f80823d46460c\n","Successfully built ax-platform sklearn gpytorch retrying\n","\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=0.24.0, but you'll have pandas 0.25.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: numpy, torch, scipy, gpytorch, botorch, MarkupSafe, jinja2, pytz, six, python-dateutil, pandas, joblib, scikit-learn, sklearn, retrying, plotly, ax-platform\n","Successfully installed MarkupSafe-1.1.1 ax-platform-0.1.4 botorch-0.1.3 gpytorch-0.3.5 jinja2-2.10.1 joblib-0.13.2 numpy-1.17.2 pandas-0.25.1 plotly-4.1.1 python-dateutil-2.8.0 pytz-2019.2 retrying-1.3.3 scikit-learn-0.21.3 scipy-1.3.1 six-1.12.0 sklearn-0.0 torch-1.2.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["dateutil","numpy","pandas","pytz","six"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["/content\n","/content\n","Cloning into 'botorch'...\n","remote: Enumerating objects: 260, done.\u001b[K\n","remote: Counting objects: 100% (260/260), done.\u001b[K\n","remote: Compressing objects: 100% (182/182), done.\u001b[K\n","remote: Total 5956 (delta 105), reused 127 (delta 40), pack-reused 5696\u001b[K\n","Receiving objects: 100% (5956/5956), 10.53 MiB | 12.83 MiB/s, done.\n","Resolving deltas: 100% (3803/3803), done.\n","/content/botorch\n","Processing /content/botorch\n","Requirement already satisfied: torch>=1.2 in /usr/local/lib/python3.6/dist-packages (from botorch==0.1.3) (1.2.0)\n","Requirement already satisfied: gpytorch>=0.3.5 in /usr/local/lib/python3.6/dist-packages (from botorch==0.1.3) (0.3.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from botorch==0.1.3) (1.3.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.2->botorch==0.1.3) (1.17.2)\n","Building wheels for collected packages: botorch\n","  Building wheel for botorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for botorch: filename=botorch-0.1.3-cp36-none-any.whl size=175349 sha256=5d69facb66416573233c220c697401e066c3729a3cd90d22c00671032b4dda1f\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-4i9vnqe4/wheels/d8/0e/3f/502176509633fec729eabc1a42e465b3603faf0c30b4782f33\n","Successfully built botorch\n","Installing collected packages: botorch\n","  Found existing installation: botorch 0.1.3\n","    Uninstalling botorch-0.1.3:\n","      Successfully uninstalled botorch-0.1.3\n","Successfully installed botorch-0.1.3\n","Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.6/dist-packages (1.3.8)\n","Collecting setproctitle\n","  Downloading https://files.pythonhosted.org/packages/5a/0d/dc0d2234aacba6cf1a729964383e3452c52096dc695581248b548786f2b3/setproctitle-1.1.10.tar.gz\n","Building wheels for collected packages: setproctitle\n","  Building wheel for setproctitle (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for setproctitle: filename=setproctitle-1.1.10-cp36-cp36m-linux_x86_64.whl size=33920 sha256=29e3c943204084dd2d51078e2868f825cc74061a92e575881522f05f3cc4f049\n","  Stored in directory: /root/.cache/pip/wheels/e6/b1/a6/9719530228e258eba904501fef99d5d85c80d52bd8f14438a3\n","Successfully built setproctitle\n","Installing collected packages: setproctitle\n","Successfully installed setproctitle-1.1.10\n","Collecting ray[rllib]\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/d1/3490a0361d6127ea794c8cc7d0495fc4e1bfb9e06dd5b565c7fb9b23df2d/ray-0.7.4-cp36-cp36m-manylinux1_x86_64.whl (74.9MB)\n","\u001b[K     |████████████████████████████████| 74.9MB 40.8MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (3.13)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (3.0.12)\n","Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (1.17.2)\n","Collecting colorama (from ray[rllib])\n","  Downloading https://files.pythonhosted.org/packages/4f/a6/728666f39bfff1719fc94c481890b2106837da9318031f71a8424b662e12/colorama-0.4.1-py2.py3-none-any.whl\n","Collecting redis>=3.3.2 (from ray[rllib])\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/64/b1e90af9bf0c7f6ef55e46b81ab527b33b785824d65300bb65636534b530/redis-3.3.8-py2.py3-none-any.whl (66kB)\n","\u001b[K     |████████████████████████████████| 71kB 20.5MB/s \n","\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (7.0)\n","Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (3.6.4)\n","Requirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (1.12.0)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (2.6.0)\n","Collecting funcsigs (from ray[rllib])\n","  Downloading https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n","Collecting protobuf>=3.8.0 (from ray[rllib])\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/f4/a27952733796330cd17c17ea1f974459f5fefbbad119c0f296a6d807fec3/protobuf-3.9.1-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 42.0MB/s \n","\u001b[?25hCollecting lz4; extra == \"rllib\" (from ray[rllib])\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/c6/96bbb3525a63ebc53ea700cc7d37ab9045542d33b4d262d0f0408ad9bbf2/lz4-2.1.10-cp36-cp36m-manylinux1_x86_64.whl (385kB)\n","\u001b[K     |████████████████████████████████| 389kB 40.9MB/s \n","\u001b[?25hRequirement already satisfied: scipy; extra == \"rllib\" in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (1.3.1)\n","Requirement already satisfied: gym[atari]; extra == \"rllib\" in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (0.10.11)\n","Collecting opencv-python-headless; extra == \"rllib\" (from ray[rllib])\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/dc/b250f03ab68068033fd2356428c1357431d8ebc6a26405098e0f27c94f7a/opencv_python_headless-4.1.1.26-cp36-cp36m-manylinux1_x86_64.whl (22.1MB)\n","\u001b[K     |████████████████████████████████| 22.1MB 39.8MB/s \n","\u001b[?25hRequirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[rllib]) (0.7.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->ray[rllib]) (41.2.0)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[rllib]) (1.8.0)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[rllib]) (1.3.0)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[rllib]) (7.2.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[rllib]) (19.1.0)\n","Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari]; extra == \"rllib\"->ray[rllib]) (2.21.0)\n","Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari]; extra == \"rllib\"->ray[rllib]) (1.4.2)\n","Requirement already satisfied: Pillow; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]; extra == \"rllib\"->ray[rllib]) (4.3.0)\n","Requirement already satisfied: atari-py>=0.1.4; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]; extra == \"rllib\"->ray[rllib]) (0.1.15)\n","Requirement already satisfied: PyOpenGL; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]; extra == \"rllib\"->ray[rllib]) (3.1.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari]; extra == \"rllib\"->ray[rllib]) (2019.6.16)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari]; extra == \"rllib\"->ray[rllib]) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari]; extra == \"rllib\"->ray[rllib]) (1.24.3)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari]; extra == \"rllib\"->ray[rllib]) (2.8)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym[atari]; extra == \"rllib\"->ray[rllib]) (0.16.0)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow; extra == \"atari\"->gym[atari]; extra == \"rllib\"->ray[rllib]) (0.46)\n","Installing collected packages: colorama, redis, funcsigs, protobuf, lz4, opencv-python-headless, ray\n","  Found existing installation: protobuf 3.7.1\n","    Uninstalling protobuf-3.7.1:\n","      Successfully uninstalled protobuf-3.7.1\n","Successfully installed colorama-0.4.1 funcsigs-1.0.2 lz4-2.1.10 opencv-python-headless-4.1.1.26 protobuf-3.9.1 ray-0.7.4 redis-3.3.8\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["Uninstalling pyarrow-0.14.1:\n","  Successfully uninstalled pyarrow-0.14.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1568106680092,"user_tz":-420,"elapsed":31159,"user":{"displayName":"Huy Nguyen","photoUrl":"","userId":"05352249580863404953"}},"id":"o2AjMK7Oxq4X","outputId":"98231e62-c19b-42dd-c336-8cfe593f6ba7","colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jS6TL0xk5KzS","colab_type":"code","outputId":"192e25c5-32b2-4a12-e00f-91f861ce07c9","executionInfo":{"status":"ok","timestamp":1568106758782,"user_tz":-420,"elapsed":15070,"user":{"displayName":"Huy Nguyen","photoUrl":"","userId":"05352249580863404953"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["%cd /content/\n","!git clone https://github.com/anhhuyalex/renormalization.git\n","!cp /content/drive/My\\ Drive/Year\\ 4\\:\\ Synthesis/NS162\\:\\ Statistical\\ Mechanics/Renormalization\\ Research\\ Project/renormalization/supervised_convnet/t_2.269/3x3/ising81x81_temp2.269_uncorrelated9x9.npy /content/renormalization/supervised_convnet/t_2.269/3x3\n","!cp /content/drive/My\\ Drive/Year\\ 4\\:\\ Synthesis/NS162\\:\\ Statistical\\ Mechanics/Renormalization\\ Research\\ Project/renormalization/supervised_convnet/t_2.269/ising81x81_temp2.269.npy /content/renormalization/supervised_convnet/t_2.269      "],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content\n","Cloning into 'renormalization'...\n","remote: Enumerating objects: 273, done.\u001b[K\n","remote: Counting objects: 100% (273/273), done.\u001b[K\n","remote: Compressing objects: 100% (151/151), done.\u001b[K\n","remote: Total 273 (delta 160), reused 219 (delta 106), pack-reused 0\n","Receiving objects: 100% (273/273), 643.62 KiB | 1.74 MiB/s, done.\n","Resolving deltas: 100% (160/160), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1568106765328,"user_tz":-420,"elapsed":4197,"user":{"displayName":"Huy Nguyen","photoUrl":"","userId":"05352249580863404953"}},"id":"4RQS6gpLaAL3","outputId":"d0cee651-a71b-47ed-8198-d2bf60bd0508","colab":{"base_uri":"https://localhost:8080/","height":748}},"source":["%cd /content/renormalization/supervised_convnet/t_2.269/3x3\n","import torch\n","import numpy as np\n","import pickle\n","import ray\n","\n","from ax import RangeParameter, ParameterType\n","from ax.service.ax_client import AxClient\n","from ax.plot.contour import plot_contour\n","from ax.plot.trace import optimization_trace_single_method\n","from ax.service.managed_loop import optimize\n","from ax.utils.notebook.plotting import render, init_notebook_plotting\n","\n","import sys\n","import time\n","sys.path.insert(0, \"../../\")\n","import supervised_convnet\n","import train, frozen"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/renormalization/supervised_convnet/t_2.269/3x3\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning:\n","\n","Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning:\n","\n","Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning:\n","\n","Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning:\n","\n","Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning:\n","\n","Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning:\n","\n","Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Uncorrelated [[ 1  1  1 -1 -1 -1  1 -1 -1]\n"," [ 1  1  1 -1 -1 -1 -1 -1 -1]\n"," [ 1  1  1 -1  1  1  1  1  1]\n"," [ 1  1 -1  1 -1 -1 -1 -1 -1]\n"," [ 1  1 -1  1 -1 -1 -1 -1 -1]\n"," [ 1  1  1  1 -1 -1 -1 -1  1]\n"," [ 1  1 -1 -1 -1 -1  1  1  1]\n"," [ 1 -1 -1 -1 -1 -1  1  1  1]\n"," [ 1  1  1 -1 -1 -1  1  1 -1]]\n","Correlated [[ 1  1 -1  1 -1 -1 -1 -1  1]\n"," [ 1  1 -1 -1 -1 -1 -1 -1 -1]\n"," [ 1  1 -1 -1 -1  1  1  1  1]\n"," [-1 -1 -1 -1 -1 -1  1  1  1]\n"," [ 1 -1 -1 -1 -1  1  1  1  1]\n"," [-1 -1 -1 -1 -1  1  1  1  1]\n"," [-1 -1 -1 -1 -1  1  1 -1 -1]\n"," [-1 -1 -1 -1 -1 -1  1  1  1]\n"," [-1 -1  1 -1 -1 -1 -1 -1  1]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1xWt_dQhaDc6","colab":{}},"source":["# Parameters\n","num_hidden_layers = 1\n","out_channels = 1\n","num_workers = 2\n","run_mode = \"unfrozen_convolution_relu\"\n","n_loops = 3000\n","save_loop = min(n_loops, 2)\n","use_cuda = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Cup0cjvgaYfJ","outputId":"2623be7b-d4e0-417e-ee92-d3eec3eb61db","executionInfo":{"status":"ok","timestamp":1568106769117,"user_tz":-420,"elapsed":1542,"user":{"displayName":"Huy Nguyen","photoUrl":"","userId":"05352249580863404953"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["# Start Ray.\n","ray.init()\n","#ray.init(num_gpus=1)\n","\n","# GPU for use in colab\n","def model_to_cuda(model):\n","    if use_cuda and torch.cuda.is_available():\n","        model = model.cuda()\n","    return model\n","\n","# @ray.remote(num_gpus = 1/num_workers)\n","@ray.remote\n","def init_model_and_train(hidden_size, batch_size, train_size, n_epochs, lr, weight_decay,\n","            betas0, betas1, seed, use_cuda):\n","    # Parameters\n","    num_hidden_layers = 1\n","    out_channels = 1\n","\n","\n","    if run_mode == \"unfrozen_convolution_relu\":\n","        model = supervised_convnet.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","                hidden_size = hidden_size, out_channels = out_channels,\n","                first_activation = \"tanh\", activation_func = \"relu\",\n","                num_hidden_layers = num_hidden_layers, seed = seed)\n","        model = model_to_cuda(model)\n","        results = train.trainer(model = model, batch_size = batch_size, train_size = train_size, n_epochs = n_epochs, lr = lr,\n","                    weight_decay = weight_decay,\n","                    betas0 = 1-betas0, betas1 = 1-betas1, use_cuda = use_cuda)\n","    elif run_mode == \"frozen_convolution_no_center_relu\":\n","        model = frozen.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","                hidden_size = hidden_size, out_channels = out_channels,\n","                center = \"omit\", first_activation = \"tanh\",\n","                activation_func = \"relu\", num_hidden_layers = num_hidden_layers)\n","        model = model_to_cuda(model)\n","        results = train.trainer(model = model, batch_size = batch_size, train_size = train_size, n_epochs = n_epochs, lr = lr,\n","                    weight_decay = weight_decay,\n","                    betas0 = 1-betas0, betas1 = 1-betas1, use_cuda = use_cuda)\n","    elif run_mode == \"frozen_convolution_pretrained_relu\":\n","        model = frozen.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","                hidden_size = hidden_size, out_channels = out_channels,\n","                center = \"pre_trained\", first_activation = \"tanh\",\n","                activation_func = \"relu\", num_hidden_layers = num_hidden_layers)\n","        model = model_to_cuda(model)\n","        results = train.trainer(model = model, batch_size = batch_size, train_size = train_size, n_epochs = n_epochs, lr = lr,\n","                    weight_decay = weight_decay,\n","                    betas0 = 1-betas0, betas1 = 1-betas1, use_cuda = use_cuda)\n","    elif run_mode == \"unfrozen_convolution_2_channels\":\n","        out_channels = 2\n","        model = supervised_convnet.SupervisedConvNet(filter_size = 3, square_size = 3,\n","                hidden_size = hidden_size, out_channels = out_channels,\n","                first_activation = \"tanh\", activation_func = \"relu\",\n","                num_hidden_layers = num_hidden_layers, seed = seed)\n","        model = model_to_cuda(model)\n","        results = train.trainer(model = model, batch_size = batch_size, train_size = train_size, n_epochs = n_epochs, lr = lr,\n","                    weight_decay = weight_decay,\n","                    betas0 = 1-betas0, betas1 = 1-betas1, use_cuda = use_cuda)\n","    return (results[0])\n","\n","\n","\n","def train_evaluate(parameterization, use_cuda = use_cuda):\n","    # parameters\n","    batch_size = parameterization[\"batch_size\"]\n","    train_size = parameterization[\"train_size\"]\n","    n_epochs = parameterization[\"n_epochs\"]\n","    lr = parameterization[\"lr\"]\n","    weight_decay = parameterization[\"weight_decay\"]\n","    betas0 = parameterization[\"betas0\"]\n","    betas1 = parameterization[\"betas1\"]\n","    hidden_size = 10\n","    use_cuda = use_cuda\n","\n","    results = []\n","    # Start 4 tasks in parallel.\n","    for _ in range(8):\n","        result_ids = []\n","        for seed in range(num_workers):\n","            result_ids.append(init_model_and_train.remote(hidden_size, batch_size, train_size,\n","            n_epochs, lr, weight_decay, betas0, betas1,\n","            time.time() + seed, use_cuda))\n","\n","        # Wait for the tasks to complete and retrieve the results.\n","        # With at least 4 cores, this will take 1 second.\n","        results.append(ray.get(result_ids))  # [0, 1, 2, 3]\n","\n","    # results = []\n","    # for seed in range(num_workers):\n","    #     results.append(init_model_and_train(hidden_size, batch_size, train_size,\n","    #     n_epochs, lr, weight_decay, betas0, betas1,\n","    #     time.time() + seed))\n","\n","    print (\"results\", results)\n","    mean = np.mean(results)\n","    SEM = np.std(results)/np.sqrt(len(results))\n","    # pool.close() # no more tasks\n","    # pool.join()  # wrap up current tasks\n","    return {\"objective\": (mean, SEM)}"],"execution_count":4,"outputs":[{"output_type":"stream","text":["2019-09-10 09:12:48,345\tINFO resource_spec.py:205 -- Starting Ray with 3.86 GiB memory available for workers and up to 1.95 GiB for objects. You can adjust these settings with ray.remote(memory=<bytes>, object_store_memory=<bytes>).\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"BGvXFlryTeko","colab_type":"code","colab":{}},"source":["%%capture\n","# Initialize client\n","ax_client = AxClient()\n","try:\n","    with open(f\"/content/drive/My Drive/Year 4: Synthesis/NS162: Statistical Mechanics/Renormalization Research Project/renormalization/supervised_convnet/t_2.269/3x3/colab/hyperparameters_{run_mode}.pl\", \"rb\") as handle:\n","        hyper = pickle.load(handle)\n","    v = hyper[\"axclient\"].copy()\n","    ax_client = ax_client.from_json_snapshot(v)\n","except:\n","    ax_client.create_experiment(\n","        parameters=[\n","            {\n","              \"name\": \"batch_size\",\n","              \"type\": \"range\",\n","              \"bounds\": [1, 5000],\n","              \"value_type\": \"int\"\n","            },\n","            {\n","              \"name\": \"train_size\",\n","              \"type\": \"range\",\n","              \"bounds\": [100, 5000],\n","              \"value_type\": \"int\"\n","            },\n","            {\n","              \"name\": \"n_epochs\",\n","              \"type\": \"range\",\n","              \"bounds\": [50, 250],\n","              \"value_type\": \"int\"\n","            },\n","            {\n","              \"name\": \"lr\",\n","              \"type\": \"range\",\n","              \"bounds\": [1e-4, 1],\n","              \"value_type\": \"float\",\n","              \"log_scale\": True\n","            },\n","            {\n","              \"name\": \"weight_decay\",\n","              \"type\": \"range\",\n","              \"bounds\": [1e-5, 2e-1],\n","              \"value_type\": \"float\",\n","              \"log_scale\": True\n","            },\n","            {\n","              \"name\": \"betas0\",\n","              \"type\": \"range\",\n","              \"bounds\": [1e-5, 2e-1],\n","              \"value_type\": \"float\",\n","              \"log_scale\": True\n","            },\n","            {\n","              \"name\": \"betas1\",\n","              \"type\": \"range\",\n","              \"bounds\": [1e-5, 2e-1],\n","              \"value_type\": \"float\",\n","              \"log_scale\": True\n","            }\n","        ],\n","        parameter_constraints=[\"0.02 * train_size + -1 * batch_size <= 0\", \"train_size >= batch_size\"],\n","        minimize=False,\n","        objective_name=\"objective\",\n","        outcome_constraints=None,\n","        name=\"Test\"\n","    )\n","\n","# print (\"axclient\",ax_client.experiment.trials )\n","# for loop in range(n_loops):\n","for loop in range(n_loops):\n","    print(f\"Running trial {loop}/{n_loops}...\")\n","    parameters, trial_index = ax_client.get_next_trial()\n","    print(\"trial_index\", trial_index)\n","#     time.sleep(2)\n","    # parameters[\"n_epochs\"] = 5\n","     # Local evaluation here can be replaced with deployment to external system.\n","    ax_client.complete_trial(trial_index=trial_index, raw_data=train_evaluate(parameters))\n","    print(\"Best params\", ax_client.get_best_parameters())\n","    # periodic save\n","    if loop % save_loop == (save_loop - 1):\n","        optim_result = ax_client.get_best_parameters()\n","        # print(\"best_parameters\", optim_result)\n","        # print(\"was I saved?\", ax._save_experiment_and_generation_strategy_if_possible())\n","        hyper = {}\n","        hyper[\"best_params\"] = optim_result\n","        hyper[\"axclient\"] = ax_client.to_json_snapshot()\n","        # print(\"optim_result\", optim_result)\n","        with open(f\"/content/drive/My Drive/Year 4: Synthesis/NS162: Statistical Mechanics/Renormalization Research Project/renormalization/supervised_convnet/t_2.269/3x3/colab/hyperparameters_{run_mode}.pl\", \"wb\") as handle:\n","            pickle.dump(hyper, handle, protocol = pickle.HIGHEST_PROTOCOL)\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MYCqR9pTT21U","colab_type":"code","colab":{}},"source":["i = 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n2avIIuQlH5h","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}