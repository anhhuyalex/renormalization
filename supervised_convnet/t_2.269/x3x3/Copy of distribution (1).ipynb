{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of distribution.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"caG_-0yRXHpq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"3d1b577d-4662-42e3-d504-2676e3ad621d","executionInfo":{"status":"ok","timestamp":1568359082292,"user_tz":-420,"elapsed":36236,"user":{"displayName":"Huy Nguyen","photoUrl":"","userId":"05352249580863404953"}}},"source":["!pip install sqlalchemy\n","!pip install setproctitle\n","!pip install ray[rllib]  # also recommended: ray[debug]\n","!pip uninstall -y pyarrow"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.6/dist-packages (1.3.8)\n","Collecting setproctitle\n","  Downloading https://files.pythonhosted.org/packages/5a/0d/dc0d2234aacba6cf1a729964383e3452c52096dc695581248b548786f2b3/setproctitle-1.1.10.tar.gz\n","Building wheels for collected packages: setproctitle\n","  Building wheel for setproctitle (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for setproctitle: filename=setproctitle-1.1.10-cp36-cp36m-linux_x86_64.whl size=33936 sha256=88d42ec7b545092f3ef9227bc38473198f9be889238cd54c63ff365537aa5b5f\n","  Stored in directory: /root/.cache/pip/wheels/e6/b1/a6/9719530228e258eba904501fef99d5d85c80d52bd8f14438a3\n","Successfully built setproctitle\n","Installing collected packages: setproctitle\n","Successfully installed setproctitle-1.1.10\n","Collecting ray[rllib]\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/d1/3490a0361d6127ea794c8cc7d0495fc4e1bfb9e06dd5b565c7fb9b23df2d/ray-0.7.4-cp36-cp36m-manylinux1_x86_64.whl (74.9MB)\n","\u001b[K     |████████████████████████████████| 74.9MB 30.7MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (1.12.0)\n","Collecting funcsigs (from ray[rllib])\n","  Downloading https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n","Collecting colorama (from ray[rllib])\n","  Downloading https://files.pythonhosted.org/packages/4f/a6/728666f39bfff1719fc94c481890b2106837da9318031f71a8424b662e12/colorama-0.4.1-py2.py3-none-any.whl\n","Collecting protobuf>=3.8.0 (from ray[rllib])\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/f4/a27952733796330cd17c17ea1f974459f5fefbbad119c0f296a6d807fec3/protobuf-3.9.1-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 42.1MB/s \n","\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (2.6.0)\n","Collecting redis>=3.3.2 (from ray[rllib])\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/64/b1e90af9bf0c7f6ef55e46b81ab527b33b785824d65300bb65636534b530/redis-3.3.8-py2.py3-none-any.whl (66kB)\n","\u001b[K     |████████████████████████████████| 71kB 24.8MB/s \n","\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (7.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (3.13)\n","Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (3.6.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (3.0.12)\n","Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (1.16.5)\n","Collecting lz4; extra == \"rllib\" (from ray[rllib])\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/c6/96bbb3525a63ebc53ea700cc7d37ab9045542d33b4d262d0f0408ad9bbf2/lz4-2.1.10-cp36-cp36m-manylinux1_x86_64.whl (385kB)\n","\u001b[K     |████████████████████████████████| 389kB 37.2MB/s \n","\u001b[?25hCollecting opencv-python-headless; extra == \"rllib\" (from ray[rllib])\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/dc/b250f03ab68068033fd2356428c1357431d8ebc6a26405098e0f27c94f7a/opencv_python_headless-4.1.1.26-cp36-cp36m-manylinux1_x86_64.whl (22.1MB)\n","\u001b[K     |████████████████████████████████| 22.1MB 1.2MB/s \n","\u001b[?25hRequirement already satisfied: gym[atari]; extra == \"rllib\" in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (0.10.11)\n","Requirement already satisfied: scipy; extra == \"rllib\" in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (1.3.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->ray[rllib]) (41.2.0)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[rllib]) (0.7.1)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[rllib]) (1.3.0)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[rllib]) (7.2.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[rllib]) (19.1.0)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[rllib]) (1.8.0)\n","Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari]; extra == \"rllib\"->ray[rllib]) (1.4.3)\n","Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari]; extra == \"rllib\"->ray[rllib]) (2.21.0)\n","Requirement already satisfied: atari-py>=0.1.4; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]; extra == \"rllib\"->ray[rllib]) (0.1.15)\n","Requirement already satisfied: PyOpenGL; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]; extra == \"rllib\"->ray[rllib]) (3.1.0)\n","Requirement already satisfied: Pillow; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]; extra == \"rllib\"->ray[rllib]) (4.3.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym[atari]; extra == \"rllib\"->ray[rllib]) (0.16.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari]; extra == \"rllib\"->ray[rllib]) (2019.6.16)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari]; extra == \"rllib\"->ray[rllib]) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari]; extra == \"rllib\"->ray[rllib]) (1.24.3)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari]; extra == \"rllib\"->ray[rllib]) (2.8)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow; extra == \"atari\"->gym[atari]; extra == \"rllib\"->ray[rllib]) (0.46)\n","Installing collected packages: funcsigs, colorama, protobuf, redis, lz4, opencv-python-headless, ray\n","  Found existing installation: protobuf 3.7.1\n","    Uninstalling protobuf-3.7.1:\n","      Successfully uninstalled protobuf-3.7.1\n","Successfully installed colorama-0.4.1 funcsigs-1.0.2 lz4-2.1.10 opencv-python-headless-4.1.1.26 protobuf-3.9.1 ray-0.7.4 redis-3.3.8\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["Uninstalling pyarrow-0.14.1:\n","  Successfully uninstalled pyarrow-0.14.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HrbCG_Qc8cKg","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","%cd  /content/drive/My\\ Drive/Year\\ 4\\:\\ Synthesis/NS162\\:\\ Statistical\\ Mechanics/Renormalization\\ Research\\ Project/renormalization/supervised_convnet/t_2.269/3x3/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_5iNza3_8jQc","colab_type":"code","colab":{}},"source":["# %%capture\n","import train, frozen\n","import sys\n","sys.path.insert(0, \"../../\")\n","import supervised_convnet\n","import pickle\n","from collections import defaultdict\n","import numpy as np\n","import time\n","import torch\n","# import ray\n","\n","# # Shut down previous ray\n","# ray.shutdown()\n","\n","# # Start Ray.\n","# ray.init(ignore_reinit_error = True)\n","\n","mode = \"run\"\n","run_mode = \"unfrozen_convolution_many_channels\"\n","save_loops = 50\n","use_cuda = True\n","results = []\n","conv_params = {}\n","filename = \"\"\n","def save_progress(results, conv_params, filename, epoch = 500):\n","    new_results = {}\n","    new_results[\"best_val_acc_hist\"] = results\n","    new_results[\"conv_params\"] = conv_params\n","    new_results[\"annotation\"] = \"bias + weights histogram saved\"\n","    new_results[\"epoch\"] = epoch\n","    # new_results[\"first_epo    ch_validate_accuracy_list\"] = first_epoch_validate_accuracy_list\n","    with open(filename, \"wb\") as handle:\n","        pickle.dump(new_results, handle, protocol = pickle.HIGHEST_PROTOCOL)\n","\"\"\"\n","Default activation function: sigmoid\n","\"\"\"\n","\n","# GPU for use in colab\n","def model_to_cuda(model):\n","    if use_cuda and torch.cuda.is_available():\n","        model = model.cuda()\n","    return model\n","  \n","if mode == \"run\":\n","    hidden_size = 10\n","    out_channels = 1\n","    num_hidden_layers = 1\n","    conv_params = defaultdict(list)\n","\n","    if run_mode == \"unfrozen_convolution\":\n","        \"\"\"\n","        \"\"\"\n","        out_channels = 1\n","        filename = \"unfrozen_convolution.pl\"\n","        try:\n","            with open(filename, \"rb\") as handle:\n","                results = pickle.load(handle)\n","        except:\n","            results = []\n","        for _ in range(500):\n","            model = supervised_convnet.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","                    hidden_size = hidden_size, out_channels = out_channels,\n","                    activation_func = \"sigmoid\", num_hidden_layers = num_hidden_layers)\n","            best_val_acc, param_dict, first_epoch_validate_accuracy = train.trainer(model = model)\n","            results.append(best_val_acc)\n","            conv_params[\"weight\"].append(param_dict[\"conv1.weight\"])\n","            conv_params[\"bias\"].append(param_dict[\"conv1.bias\"])\n","    elif run_mode == \"unfrozen_convolution_relu\":\n","        \"\"\"\n","        \"\"\"\n","        out_channels = 1\n","        filename = \"unfrozen_convolution_relu.pl\"\n","        try:\n","            with open(filename, \"rb\") as handle:\n","                results = pickle.load(handle)\n","        except:\n","            results = []\n","        results = []\n","        first_epoch_validate_accuracy_list = []\n","        for _ in range(500):\n","            model = supervised_convnet.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","                    hidden_size = hidden_size, out_channels = out_channels,\n","                    first_activation = \"tanh\", activation_func = \"relu\",\n","                    num_hidden_layers = num_hidden_layers, seed = time.time() + _)\n","            model = model_to_cuda(model)\n","            best_val_acc, param_dict = train.trainer(model = model, batch_size = 86, betas0= 0.0018179320494754046, betas1= 0.001354073715524798,\n","                                                    lr= 0.004388469485690077, n_epochs= 250, train_size= 4277, weight_decay= 2.346792703571872e-05, use_cuda = use_cuda)\n","            results.append(best_val_acc)\n","            conv_params[\"weight\"].append(param_dict[\"conv1.weight\"])\n","            conv_params[\"bias\"].append(param_dict[\"conv1.bias\"])\n","            if (_ % save_loops) == (0):\n","                save_progress(results, conv_params, filename, _)\n","    elif run_mode == \"frozen_convolution_no_center\":\n","        \"\"\"\n","        \"\"\"\n","        out_channels = 1\n","        filename = \"frozen_convolution_no_center.pl\"\n","        try:\n","            with open(filename, \"rb\") as handle:\n","                results = pickle.load(handle)\n","        except:\n","            results = []\n","        for _ in range(500):\n","            model = frozen.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","                    hidden_size = hidden_size, out_channels = out_channels,\n","                    center = \"omit\", activation_func = \"sigmoid\", num_hidden_layers = num_hidden_layers)\n","            best_val_acc, param_dict, first_epoch_validate_accuracy = train.trainer(model = model)\n","            results.append(best_val_acc)\n","    elif run_mode == \"frozen_convolution_no_center_relu\":\n","        \"\"\"\n","        \"\"\"\n","        filename = \"frozen_convolution_no_center_relu.pl\"\n","        out_channels = 1\n","        try:\n","            with open(filename, \"rb\") as handle:\n","                results = pickle.load(handle)\n","        except:\n","            results = []\n","        results = []\n","        for _ in range(500):\n","            model = frozen.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","                    hidden_size = hidden_size, out_channels = out_channels,\n","                    center = \"omit\", first_activation = \"tanh\",\n","                    activation_func = \"relu\", num_hidden_layers = num_hidden_layers)\n","            best_val_acc, param_dict = train.trainer(model = model)\n","            # conv_params[\"weight\"].append(param_dict[\"conv1.weight\"])\n","            conv_params[\"bias\"].append(param_dict[\"conv1.bias\"])\n","            results.append(best_val_acc)\n","    elif run_mode == \"frozen_convolution_with_center\":\n","        \"\"\"\n","        \"\"\"\n","        filename = \"frozen_convolution_with_center.pl\"\n","        out_channels = 1\n","        try:\n","            with open(filename, \"rb\") as handle:\n","                results = pickle.load(handle)\n","        except:\n","            results = []\n","        for _ in range(500):\n","            model = frozen.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","                    hidden_size = hidden_size, out_channels = out_channels,\n","                    center = \"keep\", activation_func = \"sigmoid\", num_hidden_layers = num_hidden_layers)\n","            best_val_acc, param_dict, first_epoch_validate_accuracy = train.trainer(model = model)\n","            results.append(best_val_acc)\n","    elif run_mode == \"frozen_convolution_with_center_relu\":\n","        \"\"\"\n","        \"\"\"\n","        filename = \"frozen_convolution_with_center_relu.pl\"\n","        out_channels = 1\n","        try:\n","            with open(filename, \"rb\") as handle:\n","                results = pickle.load(handle)\n","        except:\n","            results = []\n","        for _ in range(500):\n","            model = frozen.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","                    hidden_size = hidden_size, out_channels = out_channels,\n","                    center = \"keep\", activation_func = \"relu\", num_hidden_layers = num_hidden_layers)\n","            best_val_acc, param_dict, first_epoch_validate_accuracy = train.trainer(model = model)\n","            results.append(best_val_acc)\n","    elif run_mode == \"frozen_convolution_pretrained_relu\":\n","        \"\"\"\n","        \"\"\"\n","        filename = \"frozen_convolution_pretrained_relu.pl\"\n","        out_channels = 1\n","        try:\n","            with open(filename, \"rb\") as handle:\n","                results = pickle.load(handle)\n","        except:\n","            results = []\n","        results = []\n","        first_epoch_validate_accuracy_list = []\n","        for _ in range(500):\n","            model = frozen.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","                    hidden_size = hidden_size, out_channels = out_channels,\n","                    center = \"pre_trained\", first_activation = \"tanh\",\n","                    activation_func = \"relu\", num_hidden_layers = num_hidden_layers)\n","            model = model_to_cuda(model)\n","            best_val_acc, param_dict = train.trainer(model = model, batch_size = 5000, betas0=1- 0.20000000000000004, betas1=1- 1.0081196321129792e-5,\n","                                                    lr= 0.02564592414390474, n_epochs= 180, train_size= 5000, weight_decay= 6.21073259786956e-05, use_cuda = use_cuda)\n","            results.append(best_val_acc)\n","            if (_ % save_loops) == (0):\n","                save_progress(results, conv_params, filename, _)\n","    elif run_mode == \"unfrozen_convolution_many_channels\":\n","        \"\"\"\n","        check to make sure that out_channels below is not 1\n","        \"\"\"\n","        out_channels = 2\n","        filename = \"unfrozen_convolution_{}_channels.pl\".format(out_channels)\n","        print(\"filename\", filename)\n","        try:\n","            with open(filename, \"rb\") as handle:\n","                results = pickle.load(handle)\n","        except:\n","            results = []\n","        for _ in range(500):\n","            model = supervised_convnet.SupervisedConvNet(filter_size = 3, square_size = 3,\n","                    hidden_size = hidden_size, out_channels = out_channels,\n","                    activation_func = \"sigmoid\", num_hidden_layers = num_hidden_layers,\n","                    seed = time.time() + _)\n","            model = model_to_cuda(model)\n","            best_val_acc, param_dict = train.trainer(model = model, batch_size = 5000, betas0=1- 0.20000000000000004, betas1=1- 1.0081196321129792e-5,\n","                                                    lr= 0.02564592414390474, n_epochs= 180, train_size= 5000, weight_decay= 6.21073259786956e-05, use_cuda = use_cuda)\n","            results.append(best_val_acc)\n","            conv_params[\"weight\"].append(param_dict[\"conv1.weight\"])\n","            conv_params[\"bias\"].append(param_dict[\"conv1.bias\"])\n","            if (_ % save_loops) == (0):\n","                save_progress(results, conv_params, filename, _)\n","    elif run_mode == \"unfrozen_convolution_many_channels_relu\":\n","        \"\"\"\n","        check to make sure that out_channels below is not 1\n","        \"\"\"\n","        out_channels = 2\n","        filename = \"unfrozen_convolution_{}_channels_relu.pl\".format(out_channels)\n","        print(\"filename\", filename)\n","        try:\n","            with open(filename, \"rb\") as handle:\n","                results = pickle.load(handle)\n","        except:\n","            results = []\n","        for _ in range(500):\n","            model = supervised_convnet.SupervisedConvNet(filter_size = 3, square_size = 3,\n","                    hidden_size = hidden_size, out_channels = out_channels,\n","                    first_activation = \"tanh\", activation_func = \"relu\",\n","                    num_hidden_layers = num_hidden_layers, seed = time.time() + _)\n","            best_val_acc, param_dict = train.trainer(model = model)\n","            results.append(best_val_acc)\n","            conv_params[\"weight\"].append(param_dict[\"conv1.weight\"])\n","            conv_params[\"bias\"].append(param_dict[\"conv1.bias\"])\n","    elif run_mode == \"unfrozen_convolution_many_channel_many_hidden\":\n","        \"\"\"\n","        check to make sure that out_channels, num_hidden_layers above is not 1\n","        \"\"\"\n","        out_channels = 2\n","        num_hidden_layers = 2\n","        filename = \"unfrozen_convolution_{}_channels_{}_hidden.pl\".format(out_channels, num_hidden_layers)\n","        print(\"filename\", filename)\n","        try:\n","            with open(filename, \"rb\") as handle:\n","                results = pickle.load(handle)\n","        except:\n","            results = []\n","        for _ in range(500):\n","            model = supervised_convnet.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","                    hidden_size = hidden_size, out_channels = out_channels, num_hidden_layers = num_hidden_layers)\n","            best_val_acc, param_dict, first_epoch_validate_accuracy = train.trainer(model = model)\n","            results.append(best_val_acc)\n","            \n","\n","save_progress(results, conv_params, filename)\n","\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dNnF4m19AcOs","colab_type":"code","colab":{}},"source":["1# %%capture\n","import train, frozen\n","import sys\n","sys.path.insert(0, \"../../\")\n","import supervised_convnet\n","import pickle\n","from collections import defaultdict\n","import numpy as np\n","import time\n","import torch\n","import ray\n","\n","# Shut down previous ray\n","ray.shutdown()\n","\n","# Start Ray.\n","ray.init(ignore_reinit_error = True)\n","\n","mode = \"run\"\n","run_mode = \"frozen_convolution_pretrained_relu\"\n","save_loops = 50\n","use_cuda = True\n","results = []\n","conv_params = {}\n","filename = \"\"\n","def save_progress(results, conv_params, filename, epoch = 500):\n","    new_results = {}\n","    new_results[\"best_val_acc_hist\"] = results\n","    new_results[\"conv_params\"] = conv_params\n","    new_results[\"annotation\"] = \"bias + weights histogram saved\"\n","    new_results[\"epoch\"] = epoch\n","    # new_results[\"first_epo    ch_validate_accuracy_list\"] = first_epoch_validate_accuracy_list\n","    with open(filename, \"wb\") as handle:\n","        pickle.dump(new_results, handle, protocol = pickle.HIGHEST_PROTOCOL)\n","\"\"\"\n","Default activation function: sigmoid\n","\"\"\"\n","\n","@ray.remote(num_return_vals=2)\n","def init_model_and_train(model, batch_size, betas0, betas1, lr, n_epochs, train_size, weight_decay, use_cuda):\n","    best_val_acc, param_dict = train.trainer(model = model, batch_size = batch_size, betas0= betas0, betas1= betas1,\n","                                            lr= lr, n_epochs= n_epochs, train_size= train_size, weight_decay= weight_decay, use_cuda = use_cuda)\n","    return best_val_acc, param_dict\n","        \n","\n","# GPU for use in colab\n","def model_to_cuda(model):\n","    if use_cuda and torch.cuda.is_available():\n","        model = model.cuda()\n","    return model\n","\n","if mode == \"run\":\n","    hidden_size = 10\n","    out_channels = 1\n","    num_hidden_layers = 1\n","    conv_params = defaultdict(list)\n","\n","    if run_mode == \"unfrozen_convolution\":\n","        \"\"\"\n","        \"\"\"\n","        out_channels = 1\n","        filename = \"unfrozen_convolution.pl\"\n","        try:\n","            with open(filename, \"rb\") as handle:\n","                results = pickle.load(handle)\n","        except:\n","            results = []\n","        for _ in range(500):\n","            model = supervised_convnet.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","                    hidden_size = hidden_size, out_channels = out_channels,\n","                    activation_func = \"sigmoid\", num_hidden_layers = num_hidden_layers)\n","            best_val_acc, param_dict, first_epoch_validate_accuracy = train.trainer(model = model)\n","            results.append(best_val_acc)\n","            conv_params[\"weight\"].append(param_dict[\"conv1.weight\"])\n","            conv_params[\"bias\"].append(param_dict[\"conv1.bias\"])\n","    elif run_mode == \"unfrozen_convolution_relu\":\n","        \"\"\"\n","        \"\"\"\n","        out_channels = 1\n","        filename = \"unfrozen_convolution_relu.pl\"\n","        try:\n","            with open(filename, \"rb\") as handle:\n","                results = pickle.load(handle)\n","        except:\n","            results = []\n","        results = []\n","        for _ in range(1):\n","            result_ids = []\n","            for seed in range(4):\n","                model = supervised_convnet.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","                    hidden_size = hidden_size, out_channels = out_channels,\n","                    first_activation = \"tanh\", activation_func = \"relu\",\n","                    num_hidden_layers = num_hidden_layers, seed = time.time() + seed)\n","                model = model_to_cuda(model)\n","                result_ids.append(init_model_and_train.remote(model = model, batch_size = 86, betas0=1- 0.0018179320494754046, betas1= 1-0.001354073715524798,\n","                                                    lr= 0.004388469485690077, n_epochs= 250, train_size= 4277, weight_decay= 2.346792703571872e-05, use_cuda = use_cuda))\n","            \n","            # Wait for the tasks to complete and retrieve the results.\n","            # With at least 4 cores, this will take 1 second.\n","            results.append(ray.get(result_ids))  # [0, 1, 2, 3]\n","            \n","            best_val_acc, param_dictionaries = zip(*results)\n","            results.append(best_val_acc)\n","            for param_dict in param_dictionaries:\n","                conv_params[\"weight\"].append(param_dict[\"conv1.weight\"])\n","                conv_params[\"bias\"].append(param_dict[\"conv1.bias\"])\n","            print(\"best_val_acc\", best_val_acc)\n","            print(\"conv_params\", conv_params)\n","            if (_ % save_loops) == (0):\n","                save_progress(best_val_acc, conv_params, filename, _)\n","    elif run_mode == \"frozen_convolution_no_center\":\n","        \"\"\"\n","        \"\"\"\n","        out_channels = 1\n","        filename = \"frozen_convolution_no_center.pl\"\n","        try:\n","            with open(filename, \"rb\") as handle:\n","                results = pickle.load(handle)\n","        except:\n","            results = []\n","        for _ in range(500):\n","            model = frozen.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","                    hidden_size = hidden_size, out_channels = out_channels,\n","                    center = \"omit\", activation_func = \"sigmoid\", num_hidden_layers = num_hidden_layers)\n","            best_val_acc, param_dict, first_epoch_validate_accuracy = train.trainer(model = model)\n","            results.append(best_val_acc)\n","    elif run_mode == \"frozen_convolution_no_center_relu\":\n","        \"\"\"\n","        \"\"\"\n","        filename = \"frozen_convolution_no_center_relu.pl\"\n","        out_channels = 1\n","        try:\n","            with open(filename, \"rb\") as handle:\n","                results = pickle.load(handle)\n","        except:\n","            results = []\n","        results = []\n","        for _ in range(500):\n","            model = frozen.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","                    hidden_size = hidden_size, out_channels = out_channels,\n","                    center = \"omit\", first_activation = \"tanh\",\n","                    activation_func = \"relu\", num_hidden_layers = num_hidden_layers)\n","            best_val_acc, param_dict = train.trainer(model = model)\n","            # conv_params[\"weight\"].append(param_dict[\"conv1.weight\"])\n","            conv_params[\"bias\"].append(param_dict[\"conv1.bias\"])\n","            results.append(best_val_acc)\n","    elif run_mode == \"frozen_convolution_with_center\":\n","        \"\"\"\n","        \"\"\"\n","        filename = \"frozen_convolution_with_center.pl\"\n","        out_channels = 1\n","        try:\n","            with open(filename, \"rb\") as handle:\n","                results = pickle.load(handle)\n","        except:\n","            results = []\n","        for _ in range(500):\n","            model = frozen.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","                    hidden_size = hidden_size, out_channels = out_channels,\n","                    center = \"keep\", activation_func = \"sigmoid\", num_hidden_layers = num_hidden_layers)\n","            best_val_acc, param_dict, first_epoch_validate_accuracy = train.trainer(model = model)\n","            results.append(best_val_acc)\n","    elif run_mode == \"frozen_convolution_with_center_relu\":\n","        \"\"\"\n","        \"\"\"\n","        filename = \"frozen_convolution_with_center_relu.pl\"\n","        out_channels = 1\n","        try:\n","            with open(filename, \"rb\") as handle:\n","                results = pickle.load(handle)\n","        except:\n","            results = []\n","        for _ in range(500):\n","            model = frozen.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","                    hidden_size = hidden_size, out_channels = out_channels,\n","                    center = \"keep\", activation_func = \"relu\", num_hidden_layers = num_hidden_layers)\n","            best_val_acc, param_dict, first_epoch_validate_accuracy = train.trainer(model = model)\n","            results.append(best_val_acc)\n","    elif run_mode == \"frozen_convolution_pretrained_relu\":\n","        \"\"\"\n","        \"\"\"\n","        filename = \"frozen_convolution_pretrained_relu.pl\"\n","        out_channels = 1\n","        try:\n","            with open(filename, \"rb\") as handle:\n","                results = pickle.load(handle)\n","        except:\n","            results = []\n","        results = []\n","        for _ in range(1):\n","            result_ids = []\n","            for seed in range(4):\n","                model = frozen.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","                    hidden_size = hidden_size, out_channels = out_channels,\n","                    center = \"pre_trained\", first_activation = \"tanh\",\n","                    activation_func = \"relu\", num_hidden_layers = num_hidden_layers)\n","                model = model_to_cuda(model)\n","                result_ids.append(init_model_and_train.remote(model = model, batch_size = 5000, betas0=1- 0.20000000000000004, betas1= 1- 1.0081196321129792e-5,\n","                                                    lr= 0.02564592414390474, n_epochs= 180, train_size= 5000, weight_decay= 6.21073259786956e-05, use_cuda = use_cuda))\n","            \n","            # Wait for the tasks to complete and retrieve the results.\n","            # With at least 4 cores, this will take 1 second.\n","            results.append(ray.get(result_ids))  # [0, 1, 2, 3]\n","            \n","            best_val_acc, param_dictionaries = zip(*results)\n","            results.append(best_val_acc)\n","            for param_dict in param_dictionaries:\n","                conv_params[\"weight\"].append(param_dict[\"conv1.weight\"])\n","                conv_params[\"bias\"].append(param_dict[\"conv1.bias\"])\n","            print(\"best_val_acc\", best_val_acc)\n","            print(\"conv_params\", conv_params)\n","            if (_ % save_loops) == (0):\n","                save_progress(best_val_acc, conv_params, filename, _)\n","                \n","    elif run_mode == \"unfrozen_convolution_many_channels\":\n","        \"\"\"\n","        check to make sure that out_channels below is not 1\n","        \"\"\"\n","        out_channels = 2\n","        filename = \"unfrozen_convolution_{}_channels.pl\".format(out_channels)\n","        print(\"filename\", filename)\n","        try:\n","            with open(filename, \"rb\") as handle:\n","                results = pickle.load(handle)\n","        except:\n","            results = []\n","        for _ in range(500):\n","            model = supervised_convnet.SupervisedConvNet(filter_size = 3, square_size = 3,\n","                    hidden_size = hidden_size, out_channels = out_channels,\n","                    activation_func = \"sigmoid\", num_hidden_layers = num_hidden_layers,\n","                    seed = time.time() + _)\n","            best_val_acc, param_dict, first_epoch_validate_accuracy = train.trainer(model = model)\n","            results.append(best_val_acc)\n","            conv_params[\"weight\"].append(param_dict[\"conv1.weight\"])\n","            conv_params[\"bias\"].append(param_dict[\"conv1.bias\"])\n","    elif run_mode == \"unfrozen_convolution_many_channels_relu\":\n","        \"\"\"\n","        check to make sure that out_channels below is not 1\n","        \"\"\"\n","        out_channels = 2\n","        filename = \"unfrozen_convolution_{}_channels_relu.pl\".format(out_channels)\n","        print(\"filename\", filename)\n","        try:\n","            with open(filename, \"rb\") as handle:\n","                results = pickle.load(handle)\n","        except:\n","            results = []\n","        for _ in range(500):\n","            model = supervised_convnet.SupervisedConvNet(filter_size = 3, square_size = 3,\n","                    hidden_size = hidden_size, out_channels = out_channels,\n","                    first_activation = \"tanh\", activation_func = \"relu\",\n","                    num_hidden_layers = num_hidden_layers, seed = time.time() + _)\n","            best_val_acc, param_dict = train.trainer(model = model)\n","            results.append(best_val_acc)\n","            conv_params[\"weight\"].append(param_dict[\"conv1.weight\"])\n","            conv_params[\"bias\"].append(param_dict[\"conv1.bias\"])\n","    elif run_mode == \"unfrozen_convolution_many_channel_many_hidden\":\n","        \"\"\"\n","        check to make sure that out_channels, num_hidden_layers above is not 1\n","        \"\"\"\n","        out_channels = 2\n","        num_hidden_layers = 2\n","        filename = \"unfrozen_convolution_{}_channels_{}_hidden.pl\".format(out_channels, num_hidden_layers)\n","        print(\"filename\", filename)\n","        try:\n","            with open(filename, \"rb\") as handle:\n","                results = pickle.load(handle)\n","        except:\n","            results = []\n","        for _ in range(500):\n","            model = supervised_convnet.SupervisedConvNet(filter_size = 3, square_size = 3, \\\n","                    hidden_size = hidden_size, out_channels = out_channels, num_hidden_layers = num_hidden_layers)\n","            best_val_acc, param_dict, first_epoch_validate_accuracy = train.trainer(model = model)\n","            results.append(best_val_acc)\n","            \n","\n","save_progress(results, conv_params, filename)\n","\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tsm-T357mGzE","colab_type":"code","colab":{}},"source":["i = 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"C2A4h6JRga8I","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}