{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import supervised_convnet\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = np.ones((10000, 9))\n",
    "not_ones = np.random.choice([1, -1], (10000, 9))\n",
    "data = np.vstack((ones, not_ones))\n",
    "label = np.hstack((np.zeros(10000), np.ones(10000)))\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       [-1., -1., -1., ..., -1., -1., -1.],\n",
       "       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       ...,\n",
       "       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       [ 1., -1., -1., ..., -1., -1.,  1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class OnesDataset(Dataset):\n",
    "    def __init__(self, data, label):\n",
    "        self.X = data\n",
    "        self.y = label\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "   \n",
    "OnesDataset = OnesDataset(X_train, y_train)\n",
    "OnesDataset.X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedConvNet(nn.Module):\n",
    "    def __init__(self, filter_size, square_size):\n",
    "        super(SupervisedConvNet, self).__init__()\n",
    "        self.filter_size = filter_size\n",
    "        self.square_size = square_size\n",
    "        self.conv2d = nn.Conv2d(1, 1, filter_size, padding=0, stride = filter_size)  \n",
    "        self.linear = nn.Linear(filter_size ** 2, 1)\n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # add hidden layers with relu activation function\n",
    "        linear = self.linear(x)\n",
    "        output = F.sigmoid(linear)\n",
    "        # for row in x:\n",
    "        #     print(\"row\", row)\n",
    "        #     for el in row[0]:\n",
    "        #         print(\"el\", el)\n",
    "        # x = torch.tanh(self.decoder(x))\n",
    "        return output\n",
    "\n",
    "model = SupervisedConvNet(filter_size = 3, square_size = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 3.459421\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[0.0115, 0.0181, 0.0277, 0.0294, 0.0125, 0.0094, 0.0190, 0.0150, 0.0399]])\n",
      "linear.bias tensor([0.0062])\n",
      "Epoch: 2 \tTraining Loss: 1.638845\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[ 0.0042, -0.0071, -0.0355, -0.0080,  0.0451, -0.0440, -0.0058, -0.0455,\n",
      "         -0.0460]])\n",
      "linear.bias tensor([-0.0477])\n",
      "Epoch: 3 \tTraining Loss: 1.285370\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[ 0.0572, -0.0184, -0.0190, -0.0190, -0.0191, -0.0191, -0.0191, -0.0180,\n",
      "         -0.0184]])\n",
      "linear.bias tensor([-0.0202])\n",
      "Epoch: 4 \tTraining Loss: 1.111498\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[ 0.0232, -0.0036, -0.0004,  0.0036, -0.0057, -0.0055, -0.0040,  0.0003,\n",
      "          0.0321]])\n",
      "linear.bias tensor([-0.0057])\n",
      "Epoch: 5 \tTraining Loss: 0.996917\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[0.0116, 0.0034, 0.0110, 0.0119, 0.0038, 0.0077, 0.0097, 0.0068, 0.0144]])\n",
      "linear.bias tensor([0.0031])\n",
      "Epoch: 6 \tTraining Loss: 0.917281\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[0.0075, 0.0076, 0.0078, 0.0296, 0.0075, 0.0075, 0.0078, 0.0299, 0.0078]])\n",
      "linear.bias tensor([0.0075])\n",
      "Epoch: 7 \tTraining Loss: 0.857325\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[-0.0212, -0.0194, -0.0212, -0.0212, -0.0194, -0.0212, -0.0212, -0.0194,\n",
      "          0.0536]])\n",
      "linear.bias tensor([-0.0212])\n",
      "Epoch: 8 \tTraining Loss: 0.809240\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[-0.0635, -0.0651, -0.0646, -0.0651, -0.0646, -0.0662,  0.0111,  0.0112,\n",
      "         -0.0662]])\n",
      "linear.bias tensor([-0.0663])\n",
      "Epoch: 9 \tTraining Loss: 0.769334\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[-0.0154, -0.0323, -0.0323,  0.0409, -0.0322, -0.0323, -0.0324, -0.0154,\n",
      "         -0.0323]])\n",
      "linear.bias tensor([-0.0324])\n",
      "Epoch: 10 \tTraining Loss: 0.736677\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[0.0002, 0.0243, 0.0002, 0.0254, 0.0002, 0.0002, 0.0013, 0.0002, 0.0014]])\n",
      "linear.bias tensor([0.0002])\n",
      "Epoch: 11 \tTraining Loss: 0.707979\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[0.0022, 0.0022, 0.0022, 0.0022, 0.0170, 0.0021, 0.0022, 0.0022, 0.0171]])\n",
      "linear.bias tensor([0.0021])\n",
      "Epoch: 12 \tTraining Loss: 0.683105\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[0.0126, 0.0126, 0.0126, 0.0127, 0.0126, 0.0126, 0.0126, 0.0127, 0.0127]])\n",
      "linear.bias tensor([0.0126])\n",
      "Epoch: 13 \tTraining Loss: 0.661013\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[-0.0312, -0.0298, -0.0305, -0.0312, -0.0312, -0.0312,  0.0452, -0.0304,\n",
      "         -0.0298]])\n",
      "linear.bias tensor([-0.0312])\n",
      "Epoch: 14 \tTraining Loss: 0.642390\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[-0.0382, -0.0287, -0.0280,  0.0310, -0.0376, -0.0376, -0.0242, -0.0242,\n",
      "         -0.0382]])\n",
      "linear.bias tensor([-0.0383])\n",
      "Epoch: 15 \tTraining Loss: 0.624957\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[-0.0012, -0.0012,  0.0112,  0.0098, -0.0012, -0.0012,  0.0112,  0.0098,\n",
      "         -0.0012]])\n",
      "linear.bias tensor([-0.0012])\n",
      "Epoch: 16 \tTraining Loss: 0.608749\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[0.0079, 0.0156, 0.0080, 0.0079, 0.0079, 0.0156, 0.0079, 0.0079, 0.0079]])\n",
      "linear.bias tensor([0.0079])\n",
      "Epoch: 17 \tTraining Loss: 0.594510\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[0.0087, 0.0090, 0.0090, 0.0083, 0.0086, 0.0083, 0.0087, 0.0083, 0.0091]])\n",
      "linear.bias tensor([0.0082])\n",
      "Epoch: 18 \tTraining Loss: 0.582160\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[-0.0272, -0.0275,  0.0431, -0.0275, -0.0275, -0.0275, -0.0272, -0.0275,\n",
      "         -0.0272]])\n",
      "linear.bias tensor([-0.0276])\n",
      "Epoch: 19 \tTraining Loss: 0.569797\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[0.0087, 0.0087, 0.0090, 0.0090, 0.0087, 0.0090, 0.0087, 0.0087, 0.0087]])\n",
      "linear.bias tensor([0.0087])\n",
      "Epoch: 20 \tTraining Loss: 0.558539\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[-0.0309, -0.0309, -0.0309, -0.0309, -0.0241, -0.0241, -0.0309, -0.0309,\n",
      "          0.0400]])\n",
      "linear.bias tensor([-0.0309])\n",
      "Epoch: 21 \tTraining Loss: 0.548544\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[0.0061, 0.0061, 0.0061, 0.0061, 0.0061, 0.0061, 0.0160, 0.0160, 0.0061]])\n",
      "linear.bias tensor([0.0061])\n",
      "Epoch: 22 \tTraining Loss: 0.538523\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[0.0086, 0.0030, 0.0034, 0.0032, 0.0032, 0.0085, 0.0034, 0.0034, 0.0033]])\n",
      "linear.bias tensor([0.0030])\n",
      "Epoch: 23 \tTraining Loss: 0.529849\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[-0.0269, -0.0284, -0.0326, -0.0326, -0.0326, -0.0281, -0.0326, -0.0323,\n",
      "          0.0444]])\n",
      "linear.bias tensor([-0.0326])\n",
      "Epoch: 24 \tTraining Loss: 0.521038\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[ 0.0399, -0.0244, -0.0244, -0.0197, -0.0197, -0.0244, -0.0244, -0.0244,\n",
      "         -0.0192]])\n",
      "linear.bias tensor([-0.0244])\n",
      "Epoch: 25 \tTraining Loss: 0.512924\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[0.0053, 0.0050, 0.0097, 0.0021, 0.0021, 0.0021, 0.0020, 0.0097, 0.0021]])\n",
      "linear.bias tensor([0.0020])\n",
      "Epoch: 26 \tTraining Loss: 0.505118\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[0.0103, 0.0103, 0.0103, 0.0105, 0.0103, 0.0103, 0.0105, 0.0103, 0.0105]])\n",
      "linear.bias tensor([0.0103])\n",
      "Epoch: 27 \tTraining Loss: 0.498103\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[0.0097, 0.0063, 0.0062, 0.0063, 0.0097, 0.0062, 0.0062, 0.0063, 0.0062]])\n",
      "linear.bias tensor([0.0062])\n",
      "Epoch: 28 \tTraining Loss: 0.490635\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[0.0074, 0.0074, 0.0074, 0.0074, 0.0074, 0.0074, 0.0074, 0.0074, 0.0074]])\n",
      "linear.bias tensor([0.0074])\n",
      "Epoch: 29 \tTraining Loss: 0.484873\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[0.0075, 0.0075, 0.0075, 0.0111, 0.0111, 0.0075, 0.0075, 0.0075, 0.0075]])\n",
      "linear.bias tensor([0.0075])\n",
      "Epoch: 30 \tTraining Loss: 0.478208\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[0.0084, 0.0085, 0.0083, 0.0084, 0.0083, 0.0083, 0.0086, 0.0083, 0.0085]])\n",
      "linear.bias tensor([0.0083])\n",
      "Epoch: 31 \tTraining Loss: 0.472120\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[0.0073, 0.0106, 0.0073, 0.0071, 0.0073, 0.0073, 0.0106, 0.0073, 0.0073]])\n",
      "linear.bias tensor([0.0071])\n",
      "Epoch: 32 \tTraining Loss: 0.466003\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[0.0065, 0.0065, 0.0066, 0.0067, 0.0097, 0.0098, 0.0066, 0.0066, 0.0066]])\n",
      "linear.bias tensor([0.0065])\n",
      "Epoch: 33 \tTraining Loss: 0.461212\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[0.0091, 0.0092, 0.0091, 0.0092, 0.0092, 0.0091, 0.0092, 0.0092, 0.0091]])\n",
      "linear.bias tensor([0.0091])\n",
      "Epoch: 34 \tTraining Loss: 0.455857\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[0.0044, 0.0042, 0.0043, 0.0044, 0.0042, 0.0044, 0.0099, 0.0045, 0.0098]])\n",
      "linear.bias tensor([0.0042])\n",
      "Epoch: 35 \tTraining Loss: 0.450539\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[0.0061, 0.0061, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0061]])\n",
      "linear.bias tensor([0.0060])\n",
      "Epoch: 36 \tTraining Loss: 0.445621\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[0.0076, 0.0076, 0.0076, 0.0098, 0.0077, 0.0098, 0.0076, 0.0077, 0.0077]])\n",
      "linear.bias tensor([0.0076])\n",
      "Epoch: 37 \tTraining Loss: 0.441074\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[0.0047, 0.0047, 0.0048, 0.0072, 0.0047, 0.0071, 0.0048, 0.0048, 0.0048]])\n",
      "linear.bias tensor([0.0047])\n",
      "Epoch: 38 \tTraining Loss: 0.436805\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[0.0074, 0.0073, 0.0073, 0.0073, 0.0073, 0.0073, 0.0074, 0.0074, 0.0073]])\n",
      "linear.bias tensor([0.0073])\n",
      "Epoch: 39 \tTraining Loss: 0.431038\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[0.0070, 0.0070, 0.0071, 0.0070, 0.0070, 0.0070, 0.0070, 0.0071, 0.0072]])\n",
      "linear.bias tensor([0.0070])\n",
      "Epoch: 40 \tTraining Loss: 0.428323\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[-0.0335, -0.0335, -0.0334, -0.0336, -0.0336, -0.0263, -0.0335,  0.0429,\n",
      "         -0.0335]])\n",
      "linear.bias tensor([-0.0336])\n",
      "Epoch: 41 \tTraining Loss: 0.424247\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[ 0.0320, -0.0175, -0.0175, -0.0175, -0.0175, -0.0175, -0.0174, -0.0174,\n",
      "         -0.0174]])\n",
      "linear.bias tensor([-0.0175])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 \tTraining Loss: 0.420199\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[0.0070, 0.0070, 0.0071, 0.0070, 0.0070, 0.0070, 0.0070, 0.0071, 0.0071]])\n",
      "linear.bias tensor([0.0070])\n",
      "Epoch: 43 \tTraining Loss: 0.415837\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[0.0035, 0.0035, 0.0035, 0.0035, 0.0035, 0.0035, 0.0077, 0.0035, 0.0077]])\n",
      "linear.bias tensor([0.0035])\n",
      "Epoch: 44 \tTraining Loss: 0.412589\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[0.0057, 0.0076, 0.0057, 0.0057, 0.0057, 0.0057, 0.0057, 0.0057, 0.0076]])\n",
      "linear.bias tensor([0.0057])\n",
      "Epoch: 45 \tTraining Loss: 0.408654\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[0.0078, 0.0055, 0.0055, 0.0055, 0.0055, 0.0055, 0.0055, 0.0078, 0.0055]])\n",
      "linear.bias tensor([0.0055])\n",
      "Epoch: 46 \tTraining Loss: 0.405020\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[0.0047, 0.0047, 0.0047, 0.0077, 0.0047, 0.0047, 0.0047, 0.0077, 0.0047]])\n",
      "linear.bias tensor([0.0047])\n",
      "Epoch: 47 \tTraining Loss: 0.402095\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[-0.0202, -0.0202, -0.0202, -0.0202,  0.0368, -0.0202, -0.0202, -0.0202,\n",
      "         -0.0202]])\n",
      "linear.bias tensor([-0.0202])\n",
      "Epoch: 48 \tTraining Loss: 0.398485\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[ 0.0313, -0.0115, -0.0125, -0.0125, -0.0125, -0.0115, -0.0125, -0.0125,\n",
      "         -0.0125]])\n",
      "linear.bias tensor([-0.0125])\n",
      "Epoch: 49 \tTraining Loss: 0.395645\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[0.0033, 0.0033, 0.0033, 0.0056, 0.0033, 0.0034, 0.0033, 0.0033, 0.0056]])\n",
      "linear.bias tensor([0.0033])\n",
      "Epoch: 50 \tTraining Loss: 0.392881\n",
      "conv2d.weight None\n",
      "conv2d.bias None\n",
      "linear.weight tensor([[-0.0222, -0.0222,  0.0345, -0.0221, -0.0222, -0.0222, -0.0222, -0.0221,\n",
      "         -0.0221]])\n",
      "linear.bias tensor([-0.0222])\n"
     ]
    }
   ],
   "source": [
    "# specify loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# specify loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# Create training and test dataloaders\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 20\n",
    "# number of epochs to train the model\n",
    "n_epochs = 50\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(OnesDataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "\n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.unsqueeze(1).type('torch.FloatTensor')\n",
    "        target = target.type('torch.FloatTensor')\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # update running training loss\n",
    "        train_loss += loss.item() * batch_size\n",
    "    \n",
    "    # print avg training statistics \n",
    "    train_loss = train_loss/len(train_loader)\n",
    "    if epoch % 1 == 0:\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss\n",
    "            ))\n",
    "#         print(\"data\", data[:10])\n",
    "#         print(\"output\", (output)[:10])\n",
    "#         print(\"target\", (target)[:10])\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print (name, param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d.weight tensor([[[[-0.2395, -0.2458,  0.0759],\n",
      "          [ 0.2451, -0.0515,  0.0264],\n",
      "          [-0.0617, -0.1918,  0.1944]]]])\n",
      "conv2d.bias tensor([0.0959])\n",
      "linear.weight tensor([[-2.3003, -2.3589, -2.1069, -2.1754, -2.1448, -2.1971, -1.9458, -1.8449,\n",
      "         -1.9532]])\n",
      "linear.bias tensor([14.5680])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print (name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Untitled",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Renormalization",
   "language": "python",
   "name": "renormalization"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
