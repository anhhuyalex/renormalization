{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import importlib\n",
    "import utils\n",
    "import attention\n",
    "import glob\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.066\n",
      "[1,  4000] loss: 1.919\n",
      "[1,  6000] loss: 1.880\n",
      "[1,  8000] loss: 1.858\n",
      "[1, 10000] loss: 1.827\n",
      "[1, 12000] loss: 1.799\n",
      "[2,  2000] loss: 1.746\n",
      "[2,  4000] loss: 1.741\n",
      "[2,  6000] loss: 1.723\n",
      "[2,  8000] loss: 1.711\n",
      "[2, 10000] loss: 1.700\n",
      "[2, 12000] loss: 1.666\n",
      "[3,  2000] loss: 1.648\n",
      "[3,  4000] loss: 1.636\n",
      "[3,  6000] loss: 1.618\n",
      "[3,  8000] loss: 1.610\n",
      "[3, 10000] loss: 1.576\n",
      "[3, 12000] loss: 1.596\n",
      "[4,  2000] loss: 1.559\n",
      "[4,  4000] loss: 1.556\n",
      "[4,  6000] loss: 1.554\n",
      "[4,  8000] loss: 1.554\n",
      "[4, 10000] loss: 1.540\n",
      "[4, 12000] loss: 1.531\n",
      "[5,  2000] loss: 1.505\n",
      "[5,  4000] loss: 1.514\n",
      "[5,  6000] loss: 1.509\n",
      "[5,  8000] loss: 1.502\n",
      "[5, 10000] loss: 1.498\n",
      "[5, 12000] loss: 1.498\n",
      "[6,  2000] loss: 1.459\n",
      "[6,  4000] loss: 1.468\n",
      "[6,  6000] loss: 1.466\n",
      "[6,  8000] loss: 1.473\n",
      "[6, 10000] loss: 1.473\n",
      "[6, 12000] loss: 1.469\n",
      "[7,  2000] loss: 1.424\n",
      "[7,  4000] loss: 1.427\n",
      "[7,  6000] loss: 1.447\n",
      "[7,  8000] loss: 1.430\n",
      "[7, 10000] loss: 1.447\n",
      "[7, 12000] loss: 1.441\n",
      "[8,  2000] loss: 1.400\n",
      "[8,  4000] loss: 1.414\n",
      "[8,  6000] loss: 1.401\n",
      "[8,  8000] loss: 1.402\n",
      "[8, 10000] loss: 1.418\n",
      "[8, 12000] loss: 1.419\n",
      "[9,  2000] loss: 1.362\n",
      "[9,  4000] loss: 1.382\n",
      "[9,  6000] loss: 1.378\n",
      "[9,  8000] loss: 1.375\n",
      "[9, 10000] loss: 1.391\n",
      "[9, 12000] loss: 1.384\n",
      "[10,  2000] loss: 1.333\n",
      "[10,  4000] loss: 1.349\n",
      "[10,  6000] loss: 1.369\n",
      "[10,  8000] loss: 1.360\n",
      "[10, 10000] loss: 1.336\n",
      "[10, 12000] loss: 1.362\n",
      "[11,  2000] loss: 1.321\n",
      "[11,  4000] loss: 1.337\n",
      "[11,  6000] loss: 1.326\n",
      "[11,  8000] loss: 1.324\n",
      "[11, 10000] loss: 1.335\n",
      "[11, 12000] loss: 1.321\n",
      "[12,  2000] loss: 1.278\n",
      "[12,  4000] loss: 1.309\n",
      "[12,  6000] loss: 1.308\n",
      "[12,  8000] loss: 1.321\n",
      "[12, 10000] loss: 1.319\n",
      "[12, 12000] loss: 1.304\n",
      "[13,  2000] loss: 1.279\n",
      "[13,  4000] loss: 1.272\n",
      "[13,  6000] loss: 1.267\n",
      "[13,  8000] loss: 1.291\n",
      "[13, 10000] loss: 1.269\n",
      "[13, 12000] loss: 1.295\n",
      "[14,  2000] loss: 1.242\n",
      "[14,  4000] loss: 1.246\n",
      "[14,  6000] loss: 1.271\n",
      "[14,  8000] loss: 1.269\n",
      "[14, 10000] loss: 1.272\n",
      "[14, 12000] loss: 1.261\n",
      "[15,  2000] loss: 1.229\n",
      "[15,  4000] loss: 1.264\n",
      "[15,  6000] loss: 1.231\n",
      "[15,  8000] loss: 1.240\n",
      "[15, 10000] loss: 1.237\n",
      "[15, 12000] loss: 1.216\n",
      "[16,  2000] loss: 1.216\n",
      "[16,  4000] loss: 1.204\n",
      "[16,  6000] loss: 1.213\n",
      "[16,  8000] loss: 1.225\n",
      "[16, 10000] loss: 1.226\n",
      "[16, 12000] loss: 1.234\n",
      "[17,  2000] loss: 1.183\n",
      "[17,  4000] loss: 1.181\n",
      "[17,  6000] loss: 1.195\n",
      "[17,  8000] loss: 1.199\n",
      "[17, 10000] loss: 1.197\n",
      "[17, 12000] loss: 1.213\n",
      "[18,  2000] loss: 1.142\n",
      "[18,  4000] loss: 1.158\n",
      "[18,  6000] loss: 1.185\n",
      "[18,  8000] loss: 1.183\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(utils)\n",
    "importlib.reload(attention)\n",
    "\n",
    "shuffled_transformer = []\n",
    "for _ in range(20):\n",
    "    \n",
    "    net = attention.SimpleViT(image_size = 32,\n",
    "        patch_size = 4,\n",
    "        num_classes = 10,\n",
    "        dim = 1024,\n",
    "        depth = 1,\n",
    "        heads = 16,\n",
    "        mlp_dim = 2048\n",
    "    ).cuda()\n",
    "        \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=1e-4)\n",
    "    trainer = utils.CIFAR_trainer(data_params = dict(\n",
    "                                    pixel_shuffled = True\n",
    "                                 ),\n",
    "                                  train_params = dict(batch_size = 4,\n",
    "                                      num_epochs = 20),\n",
    "                model_optim_params = dict(model = net, criterion = criterion, optimizer = optimizer))\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "\n",
    "def get_record(model_name, shuffled):\n",
    "    outdir = \"/scratch/gpfs/qanguyen/renorm\"\n",
    "    test_losses = []\n",
    "    lrs = []\n",
    "    itrs = []\n",
    "    train_loss_progs = []\n",
    "    testlosses_dict = []\n",
    "    for f in glob.glob(f\"{outdir}/{model_name}_shuffled_{shuffled}_*_rep_*\"):\n",
    "        record = utils.load_file_pickle(f)\n",
    "        itr, train_loss_prog = list(zip(*enumerate(record[\"train_loss_prog\"])))\n",
    "        if len(itr) > 500:\n",
    "            test_losses.append(record[\"test_loss\"])\n",
    "            itrs.extend(itr)\n",
    "            train_loss_progs.extend(train_loss_prog)\n",
    "            testlosses_dict.extend([record[\"test_loss\"]] * len(itr))\n",
    "    print(\"Number of runs\", model_name, shuffled, len(test_losses))\n",
    "    return test_losses, lrs, pd.DataFrame.from_dict(dict(itrs = itrs, \n",
    "                                                         train_loss_progs = train_loss_progs, \n",
    "                                                         testlosses_dict = testlosses_dict))\n",
    "    \n",
    "    \n",
    "def plot(model_name):\n",
    "    model_True_test_losses, _, shuffletrainloss  = get_record(model_name = model_name, shuffled = \"True\")\n",
    "    model_False_test_losses, _, non_shuffletrainloss = get_record(model_name = model_name, shuffled = \"False\")\n",
    "    model_True_test_losses = [i for i in model_True_test_losses if not np.isnan(i)]\n",
    "    \n",
    "    model_True_test_losses = [i for i in model_True_test_losses if i < np.sort(model_True_test_losses)[25]]\n",
    "    model_False_test_losses = [i for i in model_False_test_losses if i < np.sort(model_False_test_losses)[25]]\n",
    "    print(model_True_test_losses, len(model_True_test_losses))\n",
    "    print(model_False_test_losses, len(model_False_test_losses))\n",
    "    shuffletrainloss = shuffletrainloss[shuffletrainloss[\"testlosses_dict\"] < shuffletrainloss[\"testlosses_dict\"].quantile(0.5)]\n",
    "    non_shuffletrainloss = non_shuffletrainloss[non_shuffletrainloss[\"testlosses_dict\"] < non_shuffletrainloss[\"testlosses_dict\"].quantile(0.5)]\n",
    "    sns.lineplot(x = \"itrs\", y=\"train_loss_progs\", data=shuffletrainloss, label=\"Shuffled\")\n",
    "    sns.lineplot(x = \"itrs\", y=\"train_loss_progs\", data=non_shuffletrainloss, label=\"Non-Shuffled\")\n",
    "    plt.legend()\n",
    "    plt.ylim(0, 3)\n",
    "    plt.show()\n",
    "    print(\"model_True_test_losses\", model_True_test_losses)\n",
    "    print(\"model_False_test_losses\", model_False_test_losses)\n",
    "    plt.hist(model_True_test_losses, bins=np.linspace(0, 2, 50), alpha=0.6)\n",
    "    plt.hist(model_False_test_losses, bins=np.linspace(0, 2, 50), alpha=0.6)\n",
    "    plt.xlim(0, 2)\n",
    "    plt.show()\n",
    "\n",
    "plot(\"attn\")\n",
    "\n",
    "plot(\"attn_no_pe\")\n",
    "\n",
    "plot(\"cnn\")\n",
    "\n",
    "plot(\"cnn_chan_1-1\")\n",
    "\n",
    "plot(\"cnn_chan_1-16\")\n",
    "\n",
    "plot(\"mlp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (renormalization)",
   "language": "python",
   "name": "renormalization"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
