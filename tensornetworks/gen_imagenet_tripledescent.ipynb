{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7f2c0d9",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "493988a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import importlib\n",
    "import utils\n",
    "import attention\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3aec97",
   "metadata": {},
   "source": [
    "# Heat map for regression exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af06ab1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from scipy import interpolate\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "\n",
    "def in_notebook():\n",
    "    try:\n",
    "        from IPython import get_ipython\n",
    "        if 'IPKernelApp' not in get_ipython().config:  # pragma: no cover\n",
    "            return False\n",
    "    except ImportError:\n",
    "        return False\n",
    "    except AttributeError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def show_plt_if_in_notebook(title=None):\n",
    "    if in_notebook():\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(title)\n",
    "def get_record(  is_online, extra = \"\", title = None,  \n",
    "               zero_out_list = None,\n",
    "               image_transform_loader_list = None,\n",
    "               tiling_orientation_ablation_list = None,\n",
    "               tiling_list = None,\n",
    "               outdir = \"/scratch/gpfs/qanguyen/poly1/\",\n",
    "              palette = sns.color_palette(\"Set3\", 10),\n",
    "               hue_variable = \"data_rescale\",\n",
    "               num_hidden_features_list = None,\n",
    "               max_epoch = 0\n",
    "):\n",
    "     \n",
    "    warnings.filterwarnings(action='once')\n",
    "    train_pars = defaultdict(list)\n",
    "    val_pars = defaultdict(list)\n",
    "    #record_names = ['resnet18_rep_1673625625.387933.pkl', 'resnet18_rep_1673618285.140812.pkl', \n",
    "    #               'resnet18_rep_1673618285.124871.pkl', 'resnet18_rep_1673618315.142802.pkl',\n",
    "    #               'resnet18_rep_1673618403.386129.pkl', 'resnet18_rep_1673618403.386123.pkl',\n",
    "    #               'resnet18_rep_1673618381.887423.pkl', 'resnet18_rep_1673618474.561327.pkl',\n",
    "    #               'resnet18_rep_1673625654.48548.pkl', 'resnet18_rep_1673614260.528039.pkl']\n",
    "    \n",
    "#     record_names = ['resnet18_rep_1673873160.304721.pkl', 'resnet18_rep_1673873238.133468.pkl',\n",
    "#                   'resnet18_rep_1673873238.273423.pkl', 'resnet18_rep_1673873237.417957.pkl',\n",
    "#                   'resnet18_rep_1673873267.69003.pkl', 'resnet18_rep_1673873267.029088.pkl',\n",
    "#                   'resnet18_rep_1673873267.064156.pkl', 'resnet18_rep_1673873329.711897.pkl',\n",
    "#                   'resnet18_rep_1673873329.711921.pkl', 'resnet18_rep_1673873376.545421.pkl']\n",
    "    record_names = ['resnet18_rep_1674056611.865267.pkl', 'resnet18_rep_1674056612.392694.pkl',\n",
    "                  'resnet18_rep_1674056625.227239.pkl', 'resnet18_rep_1674057094.9487.pkl',\n",
    "                  'resnet18_rep_1674058958.82337.pkl', 'resnet18_rep_1674059096.368824.pkl',\n",
    "                  'resnet18_rep_1674059129.166538.pkl']#, \n",
    "#                     'resnet18_rep_1673873329.711897.pkl',\n",
    "#                   'resnet18_rep_1673873329.711921.pkl', 'resnet18_rep_1673873376.545421.pkl']\n",
    "    \n",
    "    record_names = glob.glob(f\"{outdir}/random_noisyJUN15*pth.tar\")\n",
    "    #record_included = [int(r.split(\"_\")[-1].split(\".\")[0]) for r in record_names]\n",
    "    #record_included = [((r > 1675853450) and (r < 1675912720)) for r in record_included]\n",
    "    #record_names = [ r for i,r in enumerate(record_names) if record_included[i] == True]\n",
    "    #print(record_names, len(record_names))\n",
    "    for _, f in enumerate(record_names) :\n",
    "        #print(f)\n",
    "        try:\n",
    "            \n",
    "            record = torch.load(f, map_location=\"cpu\") \n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "        \n",
    "        try:\n",
    "            #if record.curr_epoch > 27:\n",
    "            #    continue\n",
    "            #print(w)\n",
    "              \n",
    "            #print( record.args )\n",
    "\n",
    "            #if (zero_out_list is not None) and (record.args.zero_out not in zero_out_list):\n",
    "            #    continue\n",
    "            \n",
    "            if (num_hidden_features_list is not None) and (record.args.num_hidden_features not in num_hidden_features_list):   \n",
    "                continue\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            print(f, \"continue\", record.curr_epoch )\n",
    "            continue\n",
    "        \n",
    "        #print(f, \"plotting\" )\n",
    "        for epoch in [max_epoch]:\n",
    "        #for epoch in range( 1):\n",
    "            #print(epoch, f)\n",
    "            \n",
    "            #pars[\"data_rescale\"].append(record.data_rescale)\n",
    "            #pars[\"data_rescale\"].append(record.args.growth_factor)\n",
    "            #pars[\"tiling_imagenet\"].append(record.args.tiling_imagenet)\n",
    "            val_pars[\"block_size\"].append(f'{record.args.coarsegrain_blocksize}')\n",
    "            train_pars[\"block_size\"].extend( [record.args.coarsegrain_blocksize]) \n",
    "            #val_pars[\"lr\"].append(f'{record.args.lr}')\n",
    "            #train_pars[\"lr\"].extend([ record.args.lr]  * len(record.metrics.train_losses[epoch]))\n",
    "            val_pars[\"P\"].append(record.args.num_hidden_features)\n",
    "            train_pars[\"P\"].extend([ record.args.num_hidden_features ])\n",
    "            width_after_pool = math.floor((224 - record.args.coarsegrain_blocksize) / record.args.coarsegrain_blocksize + 1)\n",
    "            D = 3*(width_after_pool)*(width_after_pool)\n",
    "            val_pars[\"D\"].append( D)\n",
    "            train_pars[\"D\"].extend([D]) \n",
    "            N =  record.args.num_train_samples\n",
    "            val_pars[\"N\"].append(N)\n",
    "            train_pars[\"N\"].extend([N])\n",
    "            val_pars[\"logP/D\"].append( np.log( record.args.num_hidden_features / D ))\n",
    "            train_pars[\"logP/D\"].extend([np.log( record.args.num_hidden_features / D) ])\n",
    "            val_pars[\"logN/D\"].append( np.log( N / D ))\n",
    "            train_pars[\"logN/D\"].extend([np.log( N / D) ])\n",
    "            #val_pars[\"P\"].append(f'{record.args.num_hidden_features}')\n",
    "            #train_pars[\"P\"].extend([ record.args.num_hidden_features ])\n",
    "            val_pars[\"epoch\"].append(epoch)\n",
    "            train_pars[\"epoch\"].append(epoch)\n",
    "            #mean_train_loss = np.mean([i  for i in record.metrics.train_losses[\"default\"][epoch] if i != 0.0])\n",
    "            train_pars[\"train_loss\"].append( (record.metrics.train_mse ) )\n",
    "            #print( record.metrics.train_losses)\n",
    "            \n",
    "            val_pars[\"test_loss\"].append( (record.metrics.test_mse ) )\n",
    "             \n",
    "        #if _ > 40: break  \n",
    "        #print(\"record.args.coarsegrain_blocksize, record.args.num_hidden_features,  record.args.train_fraction\", record.args.coarsegrain_blocksize, record.args.num_hidden_features,  record.args.train_fraction,   record.metrics.val_losses[epoch])\n",
    "    line_kwargs    = dict(linewidth=0.5, alpha=0.7, style=hue_variable,\n",
    "             markers=False, markersize=8, markeredgecolor='white',\n",
    "             dashes=False)\n",
    "    figheight, figwidth = (12, 8)\n",
    "    fig, ax = plt.subplots(figsize=(figheight, figwidth))\n",
    "    train_pars = pd.DataFrame.from_dict(train_pars) \n",
    "    #display(train_pars) \n",
    "    train_pars = train_pars.sort_values(by=\"block_size\", ascending=True)[train_pars[\"epoch\"] == max_epoch ]\n",
    "    train_loss = pd.pivot_table(train_pars, columns=\"logP/D\", index=\"logN/D\", values=\"train_loss\",\n",
    "                               aggfunc='mean'\n",
    "                               )\n",
    "   \n",
    "    # Interpolate \n",
    "    x = np.array(train_pars[\"logN/D\"])\n",
    "    y = np.array(train_pars[\"logP/D\"])\n",
    "    z = np.array(train_pars[\"train_loss\"])\n",
    "    xx = np.array(train_loss.columns)\n",
    "    yy = np.array(train_loss.index.values.tolist())\n",
    "    xx, yy = np.meshgrid(xx, yy)\n",
    "    points = np.vstack([xx.flatten(), yy.flatten()]).T\n",
    "    \n",
    "    plt.contourf(xx, yy, \n",
    "                 interpolate.griddata(np.vstack((x, y)).T, z, points).reshape(xx.shape), \n",
    "              #   vmin=-25,vmax=30,\n",
    "                 cmap='Spectral_r')\n",
    "    plt.colorbar()\n",
    "    plt.scatter(x, y, \n",
    "               c = z,\n",
    "                 cmap='Spectral_r',\n",
    "            #   vmin=-25,vmax=30,\n",
    "               )\n",
    "    plt.scatter(x, y, \n",
    "               c = \"blue\",\n",
    "                marker=\"+\",\n",
    "                alpha=0.1\n",
    "               )\n",
    "    plt.plot(x, x, '-')\n",
    "    plt.xlabel(\"logN/D\")\n",
    "    plt.ylabel(\"logP/D\")\n",
    "    \n",
    "  \n",
    "    plt.title(f\"Train loss block_size vs. num_hidden_features heatmap\")\n",
    "    show_plt_if_in_notebook(\"train_loss_vs_epochs.png\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(figheight, figwidth))\n",
    "    val_pars = pd.DataFrame.from_dict(val_pars) \n",
    "    val_pars = val_pars.sort_values(by=hue_variable, ascending=True)[val_pars[\"epoch\"] == max_epoch ]\n",
    "#     val_loss = val_pars.pivot(\"logP/D\", \"logN/D\", \"test_loss\")\n",
    "    val_loss = pd.pivot_table(val_pars, columns=\"logP/D\", index=\"logN/D\", values=\"test_loss\",\n",
    "                               aggfunc='mean'\n",
    "                               )\n",
    "    display(val_pars.sort_values(by=\"test_loss\", ascending=True))\n",
    "    x = np.array(val_pars[\"logN/D\"])\n",
    "    y = np.array(val_pars[\"logP/D\"])\n",
    "    z = np.array(val_pars[\"test_loss\"])\n",
    "    xx = np.array(val_loss.columns)\n",
    "    yy = np.array(val_loss.index.values.tolist())\n",
    "    xx, yy = np.meshgrid(xx, yy)\n",
    "    points = np.vstack([xx.flatten(), yy.flatten()]).T\n",
    "    \n",
    "    plt.contourf(xx, yy, \n",
    "                 interpolate.griddata(np.vstack((x, y)).T, z, points).reshape(xx.shape), \n",
    "        #     vmin=-25,vmax=30,\n",
    "                 cmap='Spectral_r')\n",
    "    plt.colorbar()\n",
    "    plt.scatter(x, y, \n",
    "               c = z,\n",
    "                 cmap='Spectral_r',\n",
    "              #  vmin=-25,vmax=30,\n",
    "               )\n",
    "    plt.scatter(x, y, \n",
    "               c = \"blue\",\n",
    "                marker=\"+\",\n",
    "                alpha= 0.1\n",
    "               )\n",
    "    plt.plot(x, x, '-')\n",
    "    plt.xlabel(\"logN/D\")\n",
    "    plt.ylabel(\"logP/D\")\n",
    "    plt.title(f\"Test loss block_size vs. num_hidden_features heatmap\")\n",
    "    show_plt_if_in_notebook(\"test_loss_vs_epochs.png\")\n",
    "    \n",
    "    # LOG TRAIN & TEST LOSSES\n",
    "    figheight, figwidth = (12, 8)\n",
    "    fig, ax = plt.subplots(figsize=(figheight, figwidth))\n",
    "    train_pars = pd.DataFrame.from_dict(train_pars) \n",
    "    #display(train_pars) \n",
    "    train_pars = train_pars.sort_values(by=\"block_size\", ascending=True)[train_pars[\"epoch\"] == max_epoch ]\n",
    "    train_loss = pd.pivot_table(train_pars, columns=\"logP/D\", index=\"logN/D\", values=\"train_loss\",\n",
    "                               aggfunc='mean'\n",
    "                               )\n",
    "    display(train_loss)\n",
    "    # Interpolate \n",
    "    x = np.array(train_pars[\"logN/D\"])\n",
    "    y = np.array(train_pars[\"logP/D\"])\n",
    "    z = np.log(np.array(train_pars[\"train_loss\"]))\n",
    "    xx = np.array(train_loss.columns)\n",
    "    yy = np.array(train_loss.index.values.tolist())\n",
    "    xx, yy = np.meshgrid(xx, yy)\n",
    "    points = np.vstack([xx.flatten(), yy.flatten()]).T\n",
    "    \n",
    "    plt.contourf(xx, yy, \n",
    "                 interpolate.griddata(np.vstack((x, y)).T, z, points).reshape(xx.shape), \n",
    "              #   vmin=-25,vmax=30,\n",
    "                 cmap='Spectral_r')\n",
    "    plt.colorbar()\n",
    "    plt.scatter(x, y, \n",
    "               c = z,\n",
    "                 cmap='Spectral_r',\n",
    "            #   vmin=-25,vmax=30,\n",
    "               )\n",
    "    plt.scatter(x, y, \n",
    "               c = \"blue\",\n",
    "                marker=\"+\",\n",
    "                alpha=0.1\n",
    "               )\n",
    "    plt.plot(x, x, '-')\n",
    "    plt.xlabel(\"logN/D\")\n",
    "    plt.ylabel(\"logP/D\")\n",
    "    \n",
    "  \n",
    "    plt.title(f\"Train log loss block_size vs. num_hidden_features heatmap\")\n",
    "    show_plt_if_in_notebook(\"log_train_loss_vs_epochs.png\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(figheight, figwidth))\n",
    "    val_pars = pd.DataFrame.from_dict(val_pars) \n",
    "    val_pars = val_pars.sort_values(by=hue_variable, ascending=True)[val_pars[\"epoch\"] == max_epoch ]\n",
    "    #val_loss = val_pars.pivot(\"logP/D\", \"logN/D\", \"test_loss\")\n",
    "    val_loss = pd.pivot_table(val_pars, columns=\"logP/D\", index=\"logN/D\", values=\"test_loss\",\n",
    "                               aggfunc='mean'\n",
    "                               )\n",
    "    x = np.array(val_pars[\"logN/D\"])\n",
    "    y = np.array(val_pars[\"logP/D\"])\n",
    "    z = np.log(np.array(val_pars[\"test_loss\"]))\n",
    "    xx = np.array(val_loss.columns)\n",
    "    yy = np.array(val_loss.index.values.tolist())\n",
    "    xx, yy = np.meshgrid(xx, yy)\n",
    "    points = np.vstack([xx.flatten(), yy.flatten()]).T\n",
    "    \n",
    "    plt.contourf(xx, yy, \n",
    "                 interpolate.griddata(np.vstack((x, y)).T, z, points).reshape(xx.shape), \n",
    "        #     vmin=-25,vmax=30,\n",
    "                 cmap='Spectral_r')\n",
    "    plt.colorbar()\n",
    "    plt.scatter(x, y, \n",
    "               c = z,\n",
    "                 cmap='Spectral_r',\n",
    "              #  vmin=-25,vmax=30,\n",
    "               )\n",
    "    plt.scatter(x, y, \n",
    "               c = \"blue\",\n",
    "                marker=\"+\",\n",
    "                alpha= 0.1\n",
    "               )\n",
    "    plt.plot(x, x, '-')\n",
    "    plt.xlabel(\"logN/D\")\n",
    "    plt.ylabel(\"logP/D\")\n",
    "    plt.title(f\"Test log loss block_size vs. num_hidden_features heatmap\")\n",
    "    show_plt_if_in_notebook(\"log_test_loss_vs_epochs.png\")\n",
    "     \n",
    "import warnings\n",
    " \n",
    "workdir = \"/scratch/gpfs/qanguyen\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6e141e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#for num_hidden_features in (5, 10, 100, 1000, 5000, 10000, 50000, 100000):\n",
    "get_record(   \n",
    "           is_online=False, title = f\"Imagenet loss, loss vs. data_rescale\",\n",
    "           palette = sns.color_palette(\"deep\", 15),\n",
    "           outdir = f\"{workdir}/imagenet_info\",\n",
    "           image_transform_loader_list = ['SubsampleImagenet'],\n",
    "           hue_variable = \"block_size\",\n",
    "           num_hidden_features_list = None,\n",
    "    max_epoch =  0\n",
    ") \n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f64a53",
   "metadata": {},
   "source": [
    "## Diagonal slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e577b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "\n",
    "def in_notebook():\n",
    "    try:\n",
    "        from IPython import get_ipython\n",
    "        if 'IPKernelApp' not in get_ipython().config:  # pragma: no cover\n",
    "            return False\n",
    "    except ImportError:\n",
    "        return False\n",
    "    except AttributeError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def show_plt_if_in_notebook(title=None):\n",
    "    if in_notebook():\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(title)\n",
    "def get_record(  is_online, extra = \"\", title = None,  \n",
    "               zero_out_list = None,\n",
    "               image_transform_loader_list = None,\n",
    "               tiling_orientation_ablation_list = None,\n",
    "               tiling_list = None,\n",
    "               outdir = \"/scratch/gpfs/qanguyen/poly1/\",\n",
    "              palette = sns.color_palette(\"Set3\", 10),\n",
    "               hue_variable = \"data_rescale\",\n",
    "               num_hidden_features_list = None,\n",
    "               max_epoch = 0\n",
    "):\n",
    "     \n",
    "    warnings.filterwarnings(action='once')\n",
    "    train_pars = defaultdict(list)\n",
    "    val_pars = defaultdict(list)\n",
    "    #record_names = ['resnet18_rep_1673625625.387933.pkl', 'resnet18_rep_1673618285.140812.pkl', \n",
    "    #               'resnet18_rep_1673618285.124871.pkl', 'resnet18_rep_1673618315.142802.pkl',\n",
    "    #               'resnet18_rep_1673618403.386129.pkl', 'resnet18_rep_1673618403.386123.pkl',\n",
    "    #               'resnet18_rep_1673618381.887423.pkl', 'resnet18_rep_1673618474.561327.pkl',\n",
    "    #               'resnet18_rep_1673625654.48548.pkl', 'resnet18_rep_1673614260.528039.pkl']\n",
    "    \n",
    "#     record_names = ['resnet18_rep_1673873160.304721.pkl', 'resnet18_rep_1673873238.133468.pkl',\n",
    "#                   'resnet18_rep_1673873238.273423.pkl', 'resnet18_rep_1673873237.417957.pkl',\n",
    "#                   'resnet18_rep_1673873267.69003.pkl', 'resnet18_rep_1673873267.029088.pkl',\n",
    "#                   'resnet18_rep_1673873267.064156.pkl', 'resnet18_rep_1673873329.711897.pkl',\n",
    "#                   'resnet18_rep_1673873329.711921.pkl', 'resnet18_rep_1673873376.545421.pkl']\n",
    "    record_names = ['resnet18_rep_1674056611.865267.pkl', 'resnet18_rep_1674056612.392694.pkl',\n",
    "                  'resnet18_rep_1674056625.227239.pkl', 'resnet18_rep_1674057094.9487.pkl',\n",
    "                  'resnet18_rep_1674058958.82337.pkl', 'resnet18_rep_1674059096.368824.pkl',\n",
    "                  'resnet18_rep_1674059129.166538.pkl']#, \n",
    "#                     'resnet18_rep_1673873329.711897.pkl',\n",
    "#                   'resnet18_rep_1673873329.711921.pkl', 'resnet18_rep_1673873376.545421.pkl']\n",
    "    \n",
    "    record_names = glob.glob(f\"{outdir}/random_noisyJUN15*pth.tar\")\n",
    "    #record_included = [int(r.split(\"_\")[-1].split(\".\")[0]) for r in record_names]\n",
    "    #record_included = [((r > 1675853450) and (r < 1675912720)) for r in record_included]\n",
    "    #record_names = [ r for i,r in enumerate(record_names) if record_included[i] == True]\n",
    "    #print(record_names, len(record_names))\n",
    "    for _, f in enumerate(record_names) :\n",
    "        #print(f)\n",
    "        try:\n",
    "            \n",
    "            record = torch.load(f, map_location=\"cpu\") \n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "        \n",
    "        try:\n",
    "            #if record.curr_epoch > 27:\n",
    "            #    continue\n",
    "            #print(w)\n",
    "              \n",
    "            #print( record.args )\n",
    "\n",
    "            #if (zero_out_list is not None) and (record.args.zero_out not in zero_out_list):\n",
    "            #    continue\n",
    "            \n",
    "            if (num_hidden_features_list is not None) and (record.args.num_hidden_features not in num_hidden_features_list):   \n",
    "                continue\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            print(f, \"continue\", record.curr_epoch )\n",
    "            continue\n",
    "        \n",
    "        #print(f, \"plotting\" )\n",
    "        for epoch in [max_epoch]:\n",
    "        #for epoch in range( 1):\n",
    "            #print(epoch, f)\n",
    "            \n",
    "            #pars[\"data_rescale\"].append(record.data_rescale)\n",
    "            #pars[\"data_rescale\"].append(record.args.growth_factor)\n",
    "            #pars[\"tiling_imagenet\"].append(record.args.tiling_imagenet)\n",
    "            val_pars[\"block_size\"].append(f'{record.args.coarsegrain_blocksize}')\n",
    "            train_pars[\"block_size\"].extend( [record.args.coarsegrain_blocksize]) \n",
    "            #val_pars[\"lr\"].append(f'{record.args.lr}')\n",
    "            #train_pars[\"lr\"].extend([ record.args.lr]  * len(record.metrics.train_losses[epoch]))\n",
    "            val_pars[\"P\"].append(record.args.num_hidden_features)\n",
    "            train_pars[\"P\"].extend([ record.args.num_hidden_features ])\n",
    "            width_after_pool = math.floor((224 - record.args.coarsegrain_blocksize) / record.args.coarsegrain_blocksize + 1)\n",
    "            D = 3*(width_after_pool)*(width_after_pool)\n",
    "            val_pars[\"D\"].append( D)\n",
    "            train_pars[\"D\"].extend([D]) \n",
    "            N =  record.args.num_train_samples\n",
    "            val_pars[\"N\"].append(N)\n",
    "            train_pars[\"N\"].extend([N])\n",
    "            val_pars[\"logP/D\"].append( np.log( record.args.num_hidden_features / D ))\n",
    "            train_pars[\"logP/D\"].extend([np.log( record.args.num_hidden_features / D) ])\n",
    "            val_pars[\"logN/D\"].append( np.log( N / D ))\n",
    "            train_pars[\"logN/D\"].extend([np.log( N / D) ])\n",
    "            #val_pars[\"P\"].append(f'{record.args.num_hidden_features}')\n",
    "            #train_pars[\"P\"].extend([ record.args.num_hidden_features ])\n",
    "            val_pars[\"epoch\"].append(epoch)\n",
    "            train_pars[\"epoch\"].append(epoch)\n",
    "            #mean_train_loss = np.mean([i  for i in record.metrics.train_losses[\"default\"][epoch] if i != 0.0])\n",
    "            train_pars[\"train_loss\"].append( (record.metrics.train_mse.item() ) )\n",
    "            #print( record.metrics.train_losses)\n",
    "            train_pars[\"test_loss\"].append( (record.metrics.test_mse.item() ) )\n",
    "            val_pars[\"test_loss\"].append( (record.metrics.test_mse ) )\n",
    "             \n",
    "        #if _ > 40: break  \n",
    "        #print(\"record.args.coarsegrain_blocksize, record.args.num_hidden_features,  record.args.train_fraction\", record.args.coarsegrain_blocksize, record.args.num_hidden_features,  record.args.train_fraction,   record.metrics.val_losses[epoch])\n",
    "    line_kwargs    = dict(linewidth=0.5, alpha=0.7, style=hue_variable,\n",
    "             markers=False, markersize=8, markeredgecolor='white',\n",
    "             dashes=False)\n",
    "    figheight, figwidth = (12, 8)\n",
    "    fig, ax = plt.subplots(figsize=(figheight, figwidth))\n",
    "    train_pars = pd.DataFrame.from_dict(train_pars) \n",
    "    #display(train_pars) \n",
    "    train_pars = train_pars.sort_values(by=\"block_size\", ascending=True)[train_pars[\"epoch\"] == max_epoch ]\n",
    "    train_loss = pd.pivot_table(train_pars, columns=\"logP/D\", index=\"logN/D\", values=\"train_loss\",\n",
    "                               aggfunc='mean'\n",
    "                               )\n",
    "    grouped = train_pars.groupby([\"P\", \"N\"])\n",
    "    for name, group in grouped:\n",
    "        if name not in [(100, 10), (1000, 100), (10000, 1000), (10000, 100)]:\n",
    "            continue\n",
    "        #display(grouped)\n",
    "        group = group.sort_values(by=\"D\", ascending=True)\n",
    "        sns.lineplot(x=\"D\",y= \"test_loss\", data=group, label=name)\n",
    "    ax.set(xscale=\"log\", yscale=\"log\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "   \n",
    "    # Interpolate \n",
    "    x = np.array(train_pars[\"logN/D\"])\n",
    "    y = np.array(train_pars[\"logP/D\"])\n",
    "    z = np.array(train_pars[\"train_loss\"])\n",
    "    xx = np.array(train_loss.columns)\n",
    "    yy = np.array(train_loss.index.values.tolist())\n",
    "    xx, yy = np.meshgrid(xx, yy)\n",
    "    points = np.vstack([xx.flatten(), yy.flatten()]).T\n",
    "    \n",
    "    plt.contourf(xx, yy, \n",
    "                 interpolate.griddata(np.vstack((x, y)).T, z, points).reshape(xx.shape), \n",
    "              #   vmin=-25,vmax=30,\n",
    "                 cmap='Spectral_r')\n",
    "    plt.colorbar()\n",
    "    plt.scatter(x, y, \n",
    "               c = z,\n",
    "                 cmap='Spectral_r',\n",
    "            #   vmin=-25,vmax=30,\n",
    "               )\n",
    "    plt.scatter(x, y, \n",
    "               c = \"blue\",\n",
    "                marker=\"+\",\n",
    "                alpha=0.1\n",
    "               )\n",
    "    plt.plot(x, x, '-')\n",
    "    plt.xlabel(\"logN/D\")\n",
    "    plt.ylabel(\"logP/D\")\n",
    "    \n",
    "  \n",
    "    plt.title(f\"Train loss block_size vs. num_hidden_features heatmap\")\n",
    "    show_plt_if_in_notebook(\"train_loss_vs_epochs.png\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(figheight, figwidth))\n",
    "    val_pars = pd.DataFrame.from_dict(val_pars) \n",
    "    val_pars = val_pars.sort_values(by=hue_variable, ascending=True)[val_pars[\"epoch\"] == max_epoch ]\n",
    "#     val_loss = val_pars.pivot(\"logP/D\", \"logN/D\", \"test_loss\")\n",
    "    val_loss = pd.pivot_table(val_pars, columns=\"logP/D\", index=\"logN/D\", values=\"test_loss\",\n",
    "                               aggfunc='mean'\n",
    "                               )\n",
    "    display(val_pars.sort_values(by=\"test_loss\", ascending=True))\n",
    "    x = np.array(val_pars[\"logN/D\"])\n",
    "    y = np.array(val_pars[\"logP/D\"])\n",
    "    z = np.array(val_pars[\"test_loss\"])\n",
    "    xx = np.array(val_loss.columns)\n",
    "    yy = np.array(val_loss.index.values.tolist())\n",
    "    xx, yy = np.meshgrid(xx, yy)\n",
    "    points = np.vstack([xx.flatten(), yy.flatten()]).T\n",
    "    \n",
    "    plt.contourf(xx, yy, \n",
    "                 interpolate.griddata(np.vstack((x, y)).T, z, points).reshape(xx.shape), \n",
    "        #     vmin=-25,vmax=30,\n",
    "                 cmap='Spectral_r')\n",
    "    plt.colorbar()\n",
    "    plt.scatter(x, y, \n",
    "               c = z,\n",
    "                 cmap='Spectral_r',\n",
    "              #  vmin=-25,vmax=30,\n",
    "               )\n",
    "    plt.scatter(x, y, \n",
    "               c = \"blue\",\n",
    "                marker=\"+\",\n",
    "                alpha= 0.1\n",
    "               )\n",
    "    plt.plot(x, x, '-')\n",
    "    plt.xlabel(\"logN/D\")\n",
    "    plt.ylabel(\"logP/D\")\n",
    "    plt.title(f\"Test loss block_size vs. num_hidden_features heatmap\")\n",
    "    show_plt_if_in_notebook(\"test_loss_vs_epochs.png\")\n",
    "    \n",
    "    # LOG TRAIN & TEST LOSSES\n",
    "    figheight, figwidth = (12, 8)\n",
    "    fig, ax = plt.subplots(figsize=(figheight, figwidth))\n",
    "    train_pars = pd.DataFrame.from_dict(train_pars) \n",
    "    #display(train_pars) \n",
    "    train_pars = train_pars.sort_values(by=\"block_size\", ascending=True)[train_pars[\"epoch\"] == max_epoch ]\n",
    "    train_loss = pd.pivot_table(train_pars, columns=\"logP/D\", index=\"logN/D\", values=\"train_loss\",\n",
    "                               aggfunc='mean'\n",
    "                               )\n",
    "    display(train_loss)\n",
    "    # Interpolate \n",
    "    x = np.array(train_pars[\"logN/D\"])\n",
    "    y = np.array(train_pars[\"logP/D\"])\n",
    "    z = np.log(np.array(train_pars[\"train_loss\"]))\n",
    "    xx = np.array(train_loss.columns)\n",
    "    yy = np.array(train_loss.index.values.tolist())\n",
    "    xx, yy = np.meshgrid(xx, yy)\n",
    "    points = np.vstack([xx.flatten(), yy.flatten()]).T\n",
    "    \n",
    "    plt.contourf(xx, yy, \n",
    "                 interpolate.griddata(np.vstack((x, y)).T, z, points).reshape(xx.shape), \n",
    "              #   vmin=-25,vmax=30,\n",
    "                 cmap='Spectral_r')\n",
    "    plt.colorbar()\n",
    "    plt.scatter(x, y, \n",
    "               c = z,\n",
    "                 cmap='Spectral_r',\n",
    "            #   vmin=-25,vmax=30,\n",
    "               )\n",
    "    plt.scatter(x, y, \n",
    "               c = \"blue\",\n",
    "                marker=\"+\",\n",
    "                alpha=0.1\n",
    "               )\n",
    "    plt.plot(x, x, '-')\n",
    "    plt.xlabel(\"logN/D\")\n",
    "    plt.ylabel(\"logP/D\")\n",
    "    \n",
    "  \n",
    "    plt.title(f\"Train log loss block_size vs. num_hidden_features heatmap\")\n",
    "    show_plt_if_in_notebook(\"log_train_loss_vs_epochs.png\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(figheight, figwidth))\n",
    "    val_pars = pd.DataFrame.from_dict(val_pars) \n",
    "    val_pars = val_pars.sort_values(by=hue_variable, ascending=True)[val_pars[\"epoch\"] == max_epoch ]\n",
    "    #val_loss = val_pars.pivot(\"logP/D\", \"logN/D\", \"test_loss\")\n",
    "    val_loss = pd.pivot_table(val_pars, columns=\"logP/D\", index=\"logN/D\", values=\"test_loss\",\n",
    "                               aggfunc='mean'\n",
    "                               )\n",
    "    x = np.array(val_pars[\"logN/D\"])\n",
    "    y = np.array(val_pars[\"logP/D\"])\n",
    "    z = np.log(np.array(val_pars[\"test_loss\"]))\n",
    "    xx = np.array(val_loss.columns)\n",
    "    yy = np.array(val_loss.index.values.tolist())\n",
    "    xx, yy = np.meshgrid(xx, yy)\n",
    "    points = np.vstack([xx.flatten(), yy.flatten()]).T\n",
    "    \n",
    "    plt.contourf(xx, yy, \n",
    "                 interpolate.griddata(np.vstack((x, y)).T, z, points).reshape(xx.shape), \n",
    "        #     vmin=-25,vmax=30,\n",
    "                 cmap='Spectral_r')\n",
    "    plt.colorbar()\n",
    "    plt.scatter(x, y, \n",
    "               c = z,\n",
    "                 cmap='Spectral_r',\n",
    "              #  vmin=-25,vmax=30,\n",
    "               )\n",
    "    plt.scatter(x, y, \n",
    "               c = \"blue\",\n",
    "                marker=\"+\",\n",
    "                alpha= 0.1\n",
    "               )\n",
    "    plt.plot(x, x, '-')\n",
    "    plt.xlabel(\"logN/D\")\n",
    "    plt.ylabel(\"logP/D\")\n",
    "    plt.title(f\"Test log loss block_size vs. num_hidden_features heatmap\")\n",
    "    show_plt_if_in_notebook(\"log_test_loss_vs_epochs.png\")\n",
    "     \n",
    "import warnings\n",
    " \n",
    "workdir = \"/scratch/gpfs/qanguyen\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc796f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#for num_hidden_features in (5, 10, 100, 1000, 5000, 10000, 50000, 100000):\n",
    "get_record(   \n",
    "           is_online=False, title = f\"Imagenet loss, loss vs. data_rescale\",\n",
    "           palette = sns.color_palette(\"deep\", 15),\n",
    "           outdir = f\"{workdir}/imagenet_info\",\n",
    "           image_transform_loader_list = ['SubsampleImagenet'],\n",
    "           hue_variable = \"block_size\",\n",
    "           num_hidden_features_list = None,\n",
    "    max_epoch =  0\n",
    ") \n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5709ab04",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49da864f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6aaaaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bf093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 3000)\n",
    "from scipy import interpolate\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "\n",
    "def in_notebook():\n",
    "    try:\n",
    "        from IPython import get_ipython\n",
    "        if 'IPKernelApp' not in get_ipython().config:  # pragma: no cover\n",
    "            return False\n",
    "    except ImportError:\n",
    "        return False\n",
    "    except AttributeError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def show_plt_if_in_notebook(title=None):\n",
    "    if in_notebook():\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(title)\n",
    "def get_record(  is_online, extra = \"\", title = None,  \n",
    "               zero_out_list = None,\n",
    "               image_transform_loader_list = None,\n",
    "               tiling_orientation_ablation_list = None,\n",
    "               tiling_list = None,\n",
    "               outdir = \"/scratch/gpfs/qanguyen/poly1/\",\n",
    "              palette = sns.color_palette(\"Set3\", 10),\n",
    "               hue_variable = \"data_rescale\",\n",
    "               num_hidden_features_list = None,\n",
    "               max_epoch = 0\n",
    "):\n",
    "     \n",
    "    warnings.filterwarnings(action='once')\n",
    "    train_pars = defaultdict(list)\n",
    "    val_pars = defaultdict(list)\n",
    "    #record_names = ['resnet18_rep_1673625625.387933.pkl', 'resnet18_rep_1673618285.140812.pkl', \n",
    "    #               'resnet18_rep_1673618285.124871.pkl', 'resnet18_rep_1673618315.142802.pkl',\n",
    "    #               'resnet18_rep_1673618403.386129.pkl', 'resnet18_rep_1673618403.386123.pkl',\n",
    "    #               'resnet18_rep_1673618381.887423.pkl', 'resnet18_rep_1673618474.561327.pkl',\n",
    "    #               'resnet18_rep_1673625654.48548.pkl', 'resnet18_rep_1673614260.528039.pkl']\n",
    "    \n",
    "#     record_names = ['resnet18_rep_1673873160.304721.pkl', 'resnet18_rep_1673873238.133468.pkl',\n",
    "#                   'resnet18_rep_1673873238.273423.pkl', 'resnet18_rep_1673873237.417957.pkl',\n",
    "#                   'resnet18_rep_1673873267.69003.pkl', 'resnet18_rep_1673873267.029088.pkl',\n",
    "#                   'resnet18_rep_1673873267.064156.pkl', 'resnet18_rep_1673873329.711897.pkl',\n",
    "#                   'resnet18_rep_1673873329.711921.pkl', 'resnet18_rep_1673873376.545421.pkl']\n",
    "    record_names = ['resnet18_rep_1674056611.865267.pkl', 'resnet18_rep_1674056612.392694.pkl',\n",
    "                  'resnet18_rep_1674056625.227239.pkl', 'resnet18_rep_1674057094.9487.pkl',\n",
    "                  'resnet18_rep_1674058958.82337.pkl', 'resnet18_rep_1674059096.368824.pkl',\n",
    "                  'resnet18_rep_1674059129.166538.pkl']#, \n",
    "#                     'resnet18_rep_1673873329.711897.pkl',\n",
    "#                   'resnet18_rep_1673873329.711921.pkl', 'resnet18_rep_1673873376.545421.pkl']\n",
    "    \n",
    "    record_names = glob.glob(f\"{outdir}/*gradient_descent_noisyJUN15*pth.tar\")\n",
    "    #record_included = [int(r.split(\"_\")[-1].split(\".\")[0]) for r in record_names]\n",
    "    #record_included = [((r > 1675853450) and (r < 1675912720)) for r in record_included]\n",
    "    #record_names = [ r for i,r in enumerate(record_names) if record_included[i] == True]\n",
    "    #print(record_names, len(record_names))\n",
    "    for _, f in enumerate(record_names) :\n",
    "        #print(f)\n",
    "        try:\n",
    "            \n",
    "            record = torch.load(f, map_location=\"cpu\") \n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "        \n",
    "        try:\n",
    "            #if record.curr_epoch > 27:\n",
    "            #    continue\n",
    "            #print(w)\n",
    "              \n",
    "            #print( record.args )\n",
    "\n",
    "            #if (zero_out_list is not None) and (record.args.zero_out not in zero_out_list):\n",
    "            #    continue\n",
    "            \n",
    "            if (num_hidden_features_list is not None) and (record.args.num_hidden_features not in num_hidden_features_list):   \n",
    "                continue\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            print(f, \"continue\", record.curr_epoch )\n",
    "            continue\n",
    "        \n",
    "        #print(f, \"plotting\" )\n",
    "        for epoch in [max_epoch]:\n",
    "        #for epoch in range( 1):\n",
    "            #print(epoch, f)\n",
    "            \n",
    "            #pars[\"data_rescale\"].append(record.data_rescale)\n",
    "            #pars[\"data_rescale\"].append(record.args.growth_factor)\n",
    "            #pars[\"tiling_imagenet\"].append(record.args.tiling_imagenet)\n",
    "            val_pars[\"block_size\"].append(f'{record.args.coarsegrain_blocksize}')\n",
    "            train_pars[\"block_size\"].extend( [record.args.coarsegrain_blocksize]) \n",
    "            train_pars[\"lr\"].append( (record.args.lr ) )\n",
    "            #val_pars[\"lr\"].append(f'{record.args.lr}')\n",
    "            #train_pars[\"lr\"].extend([ record.args.lr]  * len(record.metrics.train_losses[epoch]))\n",
    "            val_pars[\"P\"].append(record.args.num_hidden_features)\n",
    "            train_pars[\"P\"].extend([ record.args.num_hidden_features ])\n",
    "            width_after_pool = math.floor((224 - record.args.coarsegrain_blocksize) / record.args.coarsegrain_blocksize + 1)\n",
    "            D = 3*(width_after_pool)*(width_after_pool)\n",
    "            val_pars[\"D\"].append( D)\n",
    "            train_pars[\"D\"].extend([D]) \n",
    "            N =  record.args.num_train_samples\n",
    "            val_pars[\"N\"].append(N)\n",
    "            train_pars[\"N\"].extend([N])\n",
    "            val_pars[\"logP/D\"].append( np.log( record.args.num_hidden_features / D ))\n",
    "            train_pars[\"logP/D\"].extend([np.log( record.args.num_hidden_features / D) ])\n",
    "            val_pars[\"logN/D\"].append( np.log( N / D ))\n",
    "            train_pars[\"logN/D\"].extend([np.log( N / D) ])\n",
    "            #val_pars[\"P\"].append(f'{record.args.num_hidden_features}')\n",
    "            #train_pars[\"P\"].extend([ record.args.num_hidden_features ])\n",
    "            val_pars[\"epoch\"].append(epoch)\n",
    "            train_pars[\"epoch\"].append(epoch)\n",
    "            #mean_train_loss = np.mean([i  for i in record.metrics.train_losses[\"default\"][epoch] if i != 0.0])\n",
    "            train_pars[\"train_loss\"].append( (record.metrics.train_mse[epoch] ) )\n",
    "            #print( record.metrics.train_losses)\n",
    "            \n",
    "            train_pars[\"test_loss\"].append( (record.metrics.test_mse ) )\n",
    "            train_pars[\"log_train_loss\"].append( np.log(record.metrics.train_mse[epoch] ) )\n",
    "             \n",
    "            \n",
    "            train_pars[\"log_test_loss\"].append(  np.log(record.metrics.test_mse ) )\n",
    "             \n",
    "        #if _ > 40: break  \n",
    "        #print(\"record.args.coarsegrain_blocksize, record.args.num_hidden_features,  record.args.train_fraction\", record.args.coarsegrain_blocksize, record.args.num_hidden_features,  record.args.train_fraction,   record.metrics.val_losses[epoch])\n",
    "    line_kwargs    = dict(linewidth=0.5, alpha=0.7, style=hue_variable,\n",
    "             markers=False, markersize=8, markeredgecolor='white',\n",
    "             dashes=False)\n",
    "    vmin_kwargs = dict(vmin=4, vmax=11)\n",
    "    figheight, figwidth = (12, 8)\n",
    "    fig, ax = plt.subplots(figsize=(figheight, figwidth))\n",
    "    train_pars = pd.DataFrame.from_dict(train_pars) \n",
    "    #display(train_pars) \n",
    "    train_pars = train_pars.sort_values(by=\"block_size\", ascending=True)[train_pars[\"epoch\"] == max_epoch ]\n",
    "    train_loss = pd.pivot_table(train_pars, columns=\"logP/D\", index=\"logN/D\", values=\"train_loss\",\n",
    "                               aggfunc='mean'\n",
    "                               )\n",
    "    train_pars = train_pars.sort_values('test_loss', ascending=True).drop_duplicates(['P','N', 'D']).dropna()\n",
    "    \n",
    "    #display(train_pars)\n",
    "    # Interpolate \n",
    "    x = np.array(train_pars[\"logN/D\"])\n",
    "    y = np.array(train_pars[\"logP/D\"])\n",
    "    z = np.array(train_pars[\"train_loss\"])\n",
    "    #xx = np.array(train_loss.columns)\n",
    "    #yy = np.array(train_loss.index.values.tolist())\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    points = np.vstack([xx.flatten(), yy.flatten()]).T\n",
    "    print(\"points\", interpolate.RBFInterpolator(list(zip(x, y)), z, kernel=\"gaussian\", \n",
    "                                            epsilon = 0.1 )(points).reshape(xx.shape))\n",
    "    plt.contourf(xx, yy, \n",
    "                 interpolate.griddata(np.vstack((x, y)).T, z, points).reshape(xx.shape), \n",
    "\n",
    "                 cmap='Spectral_r', **vmin_kwargs)\n",
    "    plt.colorbar()\n",
    "    plt.scatter(x, y, \n",
    "               c = z,\n",
    "                 cmap='Spectral_r',\n",
    "               **vmin_kwargs\n",
    "               )\n",
    "    plt.scatter(x, y, \n",
    "               c = \"blue\",\n",
    "                marker=\"+\",\n",
    "                alpha=0.1,\n",
    "               )\n",
    "    plt.plot(x, x, '-')\n",
    "    plt.xlabel(\"logN/D\")\n",
    "    plt.ylabel(\"logP/D\")\n",
    "    \n",
    "  \n",
    "    plt.title(f\"Train loss block_size vs. num_hidden_features heatmap\")\n",
    "    show_plt_if_in_notebook(\"train_loss_vs_epochs.png\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(figheight, figwidth))\n",
    "   \n",
    "    val_loss = pd.pivot_table(train_pars, columns=\"logP/D\", index=\"logN/D\", values=\"test_loss\",\n",
    "                               aggfunc='mean'\n",
    "                               )\n",
    "    x = np.array(train_pars[\"logN/D\"])\n",
    "    y = np.array(train_pars[\"logP/D\"])\n",
    "    z = np.array(train_pars[\"test_loss\"])\n",
    "    xx = np.array(val_loss.columns)\n",
    "    yy = np.array(val_loss.index.values.tolist())\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    points = np.vstack([xx.flatten(), yy.flatten()]).T\n",
    "    \n",
    "    plt.contourf(xx, yy, \n",
    "                 interpolate.griddata(np.vstack((x, y)).T, z, points).reshape(xx.shape), \n",
    "        #     vmin=-25,vmax=30,\n",
    "                 cmap='Spectral_r')\n",
    "    plt.colorbar()\n",
    "    plt.scatter(x, y, \n",
    "               c = z,\n",
    "                 cmap='Spectral_r',\n",
    "              #  vmin=-25,vmax=30,\n",
    "               )\n",
    "    plt.scatter(x, y, \n",
    "               c = \"blue\",\n",
    "                marker=\"+\",\n",
    "                alpha= 0.1\n",
    "               )\n",
    "    plt.plot(x, x, '-')\n",
    "    plt.xlabel(\"logN/D\")\n",
    "    plt.ylabel(\"logP/D\")\n",
    "    plt.title(f\"Test loss block_size vs. num_hidden_features heatmap\")\n",
    "    show_plt_if_in_notebook(\"test_loss_vs_epochs.png\")\n",
    "    \n",
    "    # LOG TRAIN & TEST LOSSES\n",
    "    figheight, figwidth = (12, 8)\n",
    "    fig, ax = plt.subplots(figsize=(figheight, figwidth))\n",
    "    train_pars = pd.DataFrame.from_dict(train_pars) \n",
    "    #display(train_pars) \n",
    "    train_pars = train_pars.sort_values(by=\"block_size\", ascending=True)[train_pars[\"epoch\"] == max_epoch ]\n",
    "    train_loss = pd.pivot_table(train_pars, columns=\"logP/D\", index=\"logN/D\", values=\"train_loss\",\n",
    "                               aggfunc='mean'\n",
    "                               )\n",
    "    display(train_loss)\n",
    "    # Interpolate \n",
    "    x = np.array(train_pars[\"logN/D\"])\n",
    "    y = np.array(train_pars[\"logP/D\"])\n",
    "    z =  (np.array(train_pars[\"log_train_loss\"]))\n",
    "    xx = np.array(train_loss.columns)\n",
    "    yy = np.array(train_loss.index.values.tolist())\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    points = np.vstack([xx.flatten(), yy.flatten()]).T\n",
    "    \n",
    "    plt.contourf(xx, yy, \n",
    "                 interpolate.griddata(np.vstack((x, y)).T, z, points).reshape(xx.shape), \n",
    "              #   vmin=-25,vmax=30,\n",
    "                 cmap='Spectral_r')\n",
    "    plt.colorbar()\n",
    "    plt.scatter(x, y, \n",
    "               c = z,\n",
    "                 cmap='Spectral_r',\n",
    "            #   vmin=-25,vmax=30,\n",
    "               )\n",
    "    plt.scatter(x, y, \n",
    "               c = \"blue\",\n",
    "                marker=\"+\",\n",
    "                alpha=0.1\n",
    "               )\n",
    "    plt.plot(x, x, '-')\n",
    "    plt.xlabel(\"logN/D\")\n",
    "    plt.ylabel(\"logP/D\")\n",
    "    \n",
    "  \n",
    "    plt.title(f\"Train log loss block_size vs. num_hidden_features heatmap\")\n",
    "    show_plt_if_in_notebook(\"log_train_loss_vs_epochs.png\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(figheight, figwidth))\n",
    "    \n",
    "    val_loss = pd.pivot_table(train_pars, columns=\"logP/D\", index=\"logN/D\", values=\"test_loss\",\n",
    "                               aggfunc='mean'\n",
    "                               )\n",
    "    x = np.array(train_pars[\"logN/D\"])\n",
    "    y = np.array(train_pars[\"logP/D\"])\n",
    "    z = (np.array(train_pars[\"log_test_loss\"]))\n",
    "    xx = np.array(val_loss.columns)\n",
    "    yy = np.array(val_loss.index.values.tolist())\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    points = np.vstack([xx.flatten(), yy.flatten()]).T\n",
    "    \n",
    "    plt.contourf(xx, yy, \n",
    "                 interpolate.griddata(np.vstack((x, y)).T, z, points).reshape(xx.shape), \n",
    "        #     vmin=-25,vmax=30,\n",
    "                 cmap='Spectral_r')\n",
    "    plt.colorbar()\n",
    "    plt.scatter(x, y, \n",
    "               c = z,\n",
    "                 cmap='Spectral_r',\n",
    "              #  vmin=-25,vmax=30,\n",
    "               )\n",
    "    plt.scatter(x, y, \n",
    "               c = \"blue\",\n",
    "                marker=\"+\",\n",
    "                alpha= 0.1\n",
    "               )\n",
    "    plt.plot(x, x, '-')\n",
    "    plt.xlabel(\"logN/D\")\n",
    "    plt.ylabel(\"logP/D\")\n",
    "    plt.title(f\"Test log loss block_size vs. num_hidden_features heatmap\")\n",
    "    show_plt_if_in_notebook(\"log_test_loss_vs_epochs.png\")\n",
    "     \n",
    "import warnings\n",
    " \n",
    "workdir = \"/scratch/gpfs/qanguyen\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5023817c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#for num_hidden_features in (5, 10, 100, 1000, 5000, 10000, 50000, 100000):\n",
    "get_record(   \n",
    "           is_online=False, title = f\"Imagenet loss, loss vs. data_rescale\",\n",
    "           palette = sns.color_palette(\"deep\", 15),\n",
    "           outdir = f\"{workdir}/imagenet_info\",\n",
    "           image_transform_loader_list = ['SubsampleImagenet'],\n",
    "           hue_variable = \"block_size\",\n",
    "           num_hidden_features_list = None,\n",
    "    max_epoch = 99\n",
    ") \n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d369ba",
   "metadata": {},
   "source": [
    "## Diagonal slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271262f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "\n",
    "def in_notebook():\n",
    "    try:\n",
    "        from IPython import get_ipython\n",
    "        if 'IPKernelApp' not in get_ipython().config:  # pragma: no cover\n",
    "            return False\n",
    "    except ImportError:\n",
    "        return False\n",
    "    except AttributeError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def show_plt_if_in_notebook(title=None):\n",
    "    if in_notebook():\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(title)\n",
    "def get_record(  is_online, extra = \"\", title = None,  \n",
    "               zero_out_list = None,\n",
    "               image_transform_loader_list = None,\n",
    "               tiling_orientation_ablation_list = None,\n",
    "               tiling_list = None,\n",
    "               outdir = \"/scratch/gpfs/qanguyen/poly1/\",\n",
    "              palette = sns.color_palette(\"Set3\", 10),\n",
    "               hue_variable = \"data_rescale\",\n",
    "               num_hidden_features_list = None,\n",
    "               max_epoch = 0\n",
    "):\n",
    "     \n",
    "    warnings.filterwarnings(action='once')\n",
    "    train_pars = defaultdict(list)\n",
    "    val_pars = defaultdict(list)\n",
    "    #record_names = ['resnet18_rep_1673625625.387933.pkl', 'resnet18_rep_1673618285.140812.pkl', \n",
    "    #               'resnet18_rep_1673618285.124871.pkl', 'resnet18_rep_1673618315.142802.pkl',\n",
    "    #               'resnet18_rep_1673618403.386129.pkl', 'resnet18_rep_1673618403.386123.pkl',\n",
    "    #               'resnet18_rep_1673618381.887423.pkl', 'resnet18_rep_1673618474.561327.pkl',\n",
    "    #               'resnet18_rep_1673625654.48548.pkl', 'resnet18_rep_1673614260.528039.pkl']\n",
    "    \n",
    "#     record_names = ['resnet18_rep_1673873160.304721.pkl', 'resnet18_rep_1673873238.133468.pkl',\n",
    "#                   'resnet18_rep_1673873238.273423.pkl', 'resnet18_rep_1673873237.417957.pkl',\n",
    "#                   'resnet18_rep_1673873267.69003.pkl', 'resnet18_rep_1673873267.029088.pkl',\n",
    "#                   'resnet18_rep_1673873267.064156.pkl', 'resnet18_rep_1673873329.711897.pkl',\n",
    "#                   'resnet18_rep_1673873329.711921.pkl', 'resnet18_rep_1673873376.545421.pkl']\n",
    "    record_names = ['resnet18_rep_1674056611.865267.pkl', 'resnet18_rep_1674056612.392694.pkl',\n",
    "                  'resnet18_rep_1674056625.227239.pkl', 'resnet18_rep_1674057094.9487.pkl',\n",
    "                  'resnet18_rep_1674058958.82337.pkl', 'resnet18_rep_1674059096.368824.pkl',\n",
    "                  'resnet18_rep_1674059129.166538.pkl']#, \n",
    "#                     'resnet18_rep_1673873329.711897.pkl',\n",
    "#                   'resnet18_rep_1673873329.711921.pkl', 'resnet18_rep_1673873376.545421.pkl']\n",
    "    \n",
    "    record_names = glob.glob(f\"{outdir}/*gradient_descent_noisyJUN15*pth.tar\")\n",
    "    #record_included = [int(r.split(\"_\")[-1].split(\".\")[0]) for r in record_names]\n",
    "    #record_included = [((r > 1675853450) and (r < 1675912720)) for r in record_included]\n",
    "    #record_names = [ r for i,r in enumerate(record_names) if record_included[i] == True]\n",
    "    #print(record_names, len(record_names))\n",
    "    for _, f in enumerate(record_names) :\n",
    "        #print(f)\n",
    "        try:\n",
    "            \n",
    "            record = torch.load(f, map_location=\"cpu\") \n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "        \n",
    "        try:\n",
    "            #if record.curr_epoch > 27:\n",
    "            #    continue\n",
    "            #print(w)\n",
    "              \n",
    "            #print( record.args )\n",
    "\n",
    "            #if (zero_out_list is not None) and (record.args.zero_out not in zero_out_list):\n",
    "            #    continue\n",
    "            \n",
    "            if (num_hidden_features_list is not None) and (record.args.num_hidden_features not in num_hidden_features_list):   \n",
    "                continue\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            print(f, \"continue\", record.curr_epoch )\n",
    "            continue\n",
    "        \n",
    "        #print(f, \"plotting\" )\n",
    "        for epoch in [max_epoch]:\n",
    "        #for epoch in range( 1):\n",
    "            #print(epoch, f)\n",
    "            \n",
    "            #pars[\"data_rescale\"].append(record.data_rescale)\n",
    "            #pars[\"data_rescale\"].append(record.args.growth_factor)\n",
    "            #pars[\"tiling_imagenet\"].append(record.args.tiling_imagenet)\n",
    "            val_pars[\"block_size\"].append(f'{record.args.coarsegrain_blocksize}')\n",
    "            train_pars[\"block_size\"].extend( [record.args.coarsegrain_blocksize]) \n",
    "            #val_pars[\"lr\"].append(f'{record.args.lr}')\n",
    "            #train_pars[\"lr\"].extend([ record.args.lr]  * len(record.metrics.train_losses[epoch]))\n",
    "            val_pars[\"P\"].append(record.args.num_hidden_features)\n",
    "            train_pars[\"P\"].extend([ record.args.num_hidden_features ])\n",
    "            width_after_pool = math.floor((224 - record.args.coarsegrain_blocksize) / record.args.coarsegrain_blocksize + 1)\n",
    "            D = 3*(width_after_pool)*(width_after_pool)\n",
    "            val_pars[\"D\"].append( D)\n",
    "            train_pars[\"D\"].extend([D]) \n",
    "            N =  record.args.num_train_samples\n",
    "            val_pars[\"N\"].append(N)\n",
    "            train_pars[\"N\"].extend([N])\n",
    "            val_pars[\"logP/D\"].append( np.log( record.args.num_hidden_features / D ))\n",
    "            train_pars[\"logP/D\"].extend([np.log( record.args.num_hidden_features / D) ])\n",
    "            val_pars[\"logN/D\"].append( np.log( N / D ))\n",
    "            train_pars[\"logN/D\"].extend([np.log( N / D) ])\n",
    "            #val_pars[\"P\"].append(f'{record.args.num_hidden_features}')\n",
    "            #train_pars[\"P\"].extend([ record.args.num_hidden_features ])\n",
    "            val_pars[\"epoch\"].append(epoch)\n",
    "            train_pars[\"epoch\"].append(epoch)\n",
    "            #mean_train_loss = np.mean([i  for i in record.metrics.train_losses[\"default\"][epoch] if i != 0.0])\n",
    "            train_pars[\"train_loss\"].append( (record.metrics.train_mse[epoch]) )\n",
    "            #print( record.metrics.train_losses)\n",
    "            train_pars[\"test_loss\"].append( (record.metrics.test_mse  ) )\n",
    "            val_pars[\"test_loss\"].append( (record.metrics.test_mse ) )\n",
    "             \n",
    "        #if _ > 40: break  \n",
    "        #print(\"record.args.coarsegrain_blocksize, record.args.num_hidden_features,  record.args.train_fraction\", record.args.coarsegrain_blocksize, record.args.num_hidden_features,  record.args.train_fraction,   record.metrics.val_losses[epoch])\n",
    "    line_kwargs    = dict(linewidth=0.5, alpha=0.7, style=hue_variable,\n",
    "             markers=False, markersize=8, markeredgecolor='white',\n",
    "             dashes=False)\n",
    "    figheight, figwidth = (12, 8)\n",
    "    fig, ax = plt.subplots(figsize=(figheight, figwidth))\n",
    "    train_pars = pd.DataFrame.from_dict(train_pars) \n",
    "    #display(train_pars) \n",
    "    train_pars = train_pars.sort_values('test_loss', ascending=True).drop_duplicates(['P','N', 'D']).dropna()\n",
    "    train_loss = pd.pivot_table(train_pars, columns=\"logP/D\", index=\"logN/D\", values=\"train_loss\",\n",
    "                               aggfunc='mean'\n",
    "                               )\n",
    "    grouped = train_pars.groupby([\"P\", \"N\"])\n",
    "    for name, group in grouped:\n",
    "        #if name not in [(100, 10), (1000, 100), (10000, 1000), (10000, 100)]:\n",
    "        #    continue\n",
    "        #display(grouped)\n",
    "        group = group.sort_values(by=\"D\", ascending=True)\n",
    "        sns.lineplot(x=\"D\",y= \"test_loss\", data=group, label=name)\n",
    "    ax.set(xscale=\"log\", yscale=\"log\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "   \n",
    "    # Interpolate \n",
    "    x = np.array(train_pars[\"logN/D\"])\n",
    "    y = np.array(train_pars[\"logP/D\"])\n",
    "    z = np.array(train_pars[\"train_loss\"])\n",
    "    xx = np.array(train_loss.columns)\n",
    "    yy = np.array(train_loss.index.values.tolist())\n",
    "    xx, yy = np.meshgrid(xx, yy)\n",
    "    points = np.vstack([xx.flatten(), yy.flatten()]).T\n",
    "    \n",
    "    plt.contourf(xx, yy, \n",
    "                 interpolate.griddata(np.vstack((x, y)).T, z, points).reshape(xx.shape), \n",
    "              #   vmin=-25,vmax=30,\n",
    "                 cmap='Spectral_r')\n",
    "    plt.colorbar()\n",
    "    plt.scatter(x, y, \n",
    "               c = z,\n",
    "                 cmap='Spectral_r',\n",
    "            #   vmin=-25,vmax=30,\n",
    "               )\n",
    "    plt.scatter(x, y, \n",
    "               c = \"blue\",\n",
    "                marker=\"+\",\n",
    "                alpha=0.1\n",
    "               )\n",
    "    plt.plot(x, x, '-')\n",
    "    plt.xlabel(\"logN/D\")\n",
    "    plt.ylabel(\"logP/D\")\n",
    "    \n",
    "  \n",
    "    plt.title(f\"Train loss block_size vs. num_hidden_features heatmap\")\n",
    "    show_plt_if_in_notebook(\"train_loss_vs_epochs.png\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(figheight, figwidth))\n",
    "    val_pars = pd.DataFrame.from_dict(val_pars) \n",
    "    val_pars = val_pars.sort_values(by=hue_variable, ascending=True)[val_pars[\"epoch\"] == max_epoch ]\n",
    "#     val_loss = val_pars.pivot(\"logP/D\", \"logN/D\", \"test_loss\")\n",
    "    val_loss = pd.pivot_table(val_pars, columns=\"logP/D\", index=\"logN/D\", values=\"test_loss\",\n",
    "                               aggfunc='mean'\n",
    "                               )\n",
    "    display(val_pars.sort_values(by=\"test_loss\", ascending=True))\n",
    "    x = np.array(val_pars[\"logN/D\"])\n",
    "    y = np.array(val_pars[\"logP/D\"])\n",
    "    z = np.array(val_pars[\"test_loss\"])\n",
    "    xx = np.array(val_loss.columns)\n",
    "    yy = np.array(val_loss.index.values.tolist())\n",
    "    xx, yy = np.meshgrid(xx, yy)\n",
    "    points = np.vstack([xx.flatten(), yy.flatten()]).T\n",
    "    \n",
    "    plt.contourf(xx, yy, \n",
    "                 interpolate.griddata(np.vstack((x, y)).T, z, points).reshape(xx.shape), \n",
    "        #     vmin=-25,vmax=30,\n",
    "                 cmap='Spectral_r')\n",
    "    plt.colorbar()\n",
    "    plt.scatter(x, y, \n",
    "               c = z,\n",
    "                 cmap='Spectral_r',\n",
    "              #  vmin=-25,vmax=30,\n",
    "               )\n",
    "    plt.scatter(x, y, \n",
    "               c = \"blue\",\n",
    "                marker=\"+\",\n",
    "                alpha= 0.1\n",
    "               )\n",
    "    plt.plot(x, x, '-')\n",
    "    plt.xlabel(\"logN/D\")\n",
    "    plt.ylabel(\"logP/D\")\n",
    "    plt.title(f\"Test loss block_size vs. num_hidden_features heatmap\")\n",
    "    show_plt_if_in_notebook(\"test_loss_vs_epochs.png\")\n",
    "    \n",
    "    # LOG TRAIN & TEST LOSSES\n",
    "    figheight, figwidth = (12, 8)\n",
    "    fig, ax = plt.subplots(figsize=(figheight, figwidth))\n",
    "    train_pars = pd.DataFrame.from_dict(train_pars) \n",
    "    #display(train_pars) \n",
    "    train_pars = train_pars.sort_values(by=\"block_size\", ascending=True)[train_pars[\"epoch\"] == max_epoch ]\n",
    "    train_loss = pd.pivot_table(train_pars, columns=\"logP/D\", index=\"logN/D\", values=\"train_loss\",\n",
    "                               aggfunc='mean'\n",
    "                               )\n",
    "    display(train_loss)\n",
    "    # Interpolate \n",
    "    x = np.array(train_pars[\"logN/D\"])\n",
    "    y = np.array(train_pars[\"logP/D\"])\n",
    "    z = np.log(np.array(train_pars[\"train_loss\"]))\n",
    "    xx = np.array(train_loss.columns)\n",
    "    yy = np.array(train_loss.index.values.tolist())\n",
    "    xx, yy = np.meshgrid(xx, yy)\n",
    "    points = np.vstack([xx.flatten(), yy.flatten()]).T\n",
    "    \n",
    "    plt.contourf(xx, yy, \n",
    "                 interpolate.griddata(np.vstack((x, y)).T, z, points).reshape(xx.shape), \n",
    "              #   vmin=-25,vmax=30,\n",
    "                 cmap='Spectral_r')\n",
    "    plt.colorbar()\n",
    "    plt.scatter(x, y, \n",
    "               c = z,\n",
    "                 cmap='Spectral_r',\n",
    "            #   vmin=-25,vmax=30,\n",
    "               )\n",
    "    plt.scatter(x, y, \n",
    "               c = \"blue\",\n",
    "                marker=\"+\",\n",
    "                alpha=0.1\n",
    "               )\n",
    "    plt.plot(x, x, '-')\n",
    "    plt.xlabel(\"logN/D\")\n",
    "    plt.ylabel(\"logP/D\")\n",
    "    \n",
    "  \n",
    "    plt.title(f\"Train log loss block_size vs. num_hidden_features heatmap\")\n",
    "    show_plt_if_in_notebook(\"log_train_loss_vs_epochs.png\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(figheight, figwidth))\n",
    "    val_pars = pd.DataFrame.from_dict(val_pars) \n",
    "    val_pars = val_pars.sort_values(by=hue_variable, ascending=True)[val_pars[\"epoch\"] == max_epoch ]\n",
    "    #val_loss = val_pars.pivot(\"logP/D\", \"logN/D\", \"test_loss\")\n",
    "    val_loss = pd.pivot_table(val_pars, columns=\"logP/D\", index=\"logN/D\", values=\"test_loss\",\n",
    "                               aggfunc='mean'\n",
    "                               )\n",
    "    x = np.array(val_pars[\"logN/D\"])\n",
    "    y = np.array(val_pars[\"logP/D\"])\n",
    "    z = np.log(np.array(val_pars[\"test_loss\"]))\n",
    "    xx = np.array(val_loss.columns)\n",
    "    yy = np.array(val_loss.index.values.tolist())\n",
    "    xx, yy = np.meshgrid(xx, yy)\n",
    "    points = np.vstack([xx.flatten(), yy.flatten()]).T\n",
    "    \n",
    "    plt.contourf(xx, yy, \n",
    "                 interpolate.griddata(np.vstack((x, y)).T, z, points).reshape(xx.shape), \n",
    "        #     vmin=-25,vmax=30,\n",
    "                 cmap='Spectral_r')\n",
    "    plt.colorbar()\n",
    "    plt.scatter(x, y, \n",
    "               c = z,\n",
    "                 cmap='Spectral_r',\n",
    "              #  vmin=-25,vmax=30,\n",
    "               )\n",
    "    plt.scatter(x, y, \n",
    "               c = \"blue\",\n",
    "                marker=\"+\",\n",
    "                alpha= 0.1\n",
    "               )\n",
    "    plt.plot(x, x, '-')\n",
    "    plt.xlabel(\"logN/D\")\n",
    "    plt.ylabel(\"logP/D\")\n",
    "    plt.title(f\"Test log loss block_size vs. num_hidden_features heatmap\")\n",
    "    show_plt_if_in_notebook(\"log_test_loss_vs_epochs.png\")\n",
    "     \n",
    "import warnings\n",
    " \n",
    "workdir = \"/scratch/gpfs/qanguyen\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3aec4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#for num_hidden_features in (5, 10, 100, 1000, 5000, 10000, 50000, 100000):\n",
    "get_record(   \n",
    "           is_online=False, title = f\"Imagenet loss, loss vs. data_rescale\",\n",
    "           palette = sns.color_palette(\"deep\", 15),\n",
    "           outdir = f\"{workdir}/imagenet_info\",\n",
    "           image_transform_loader_list = ['SubsampleImagenet'],\n",
    "           hue_variable = \"block_size\",\n",
    "           num_hidden_features_list = None,\n",
    "    max_epoch =  99\n",
    ") \n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d56e8dd",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562f2e36",
   "metadata": {},
   "source": [
    "## Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1db854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "pd.set_option('display.max_rows', 30000)\n",
    "\n",
    "def in_notebook():\n",
    "    try:\n",
    "        from IPython import get_ipython\n",
    "        if 'IPKernelApp' not in get_ipython().config:  # pragma: no cover\n",
    "            return False\n",
    "    except ImportError:\n",
    "        return False\n",
    "    except AttributeError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def show_plt_if_in_notebook(title=None):\n",
    "    if in_notebook():\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(title)\n",
    "def get_record(  is_online, extra = \"\", title = None,  \n",
    "               zero_out_list = None,\n",
    "               image_transform_loader_list = None,\n",
    "               tiling_orientation_ablation_list = None,\n",
    "               tiling_list = None,\n",
    "               outdir = \"/scratch/gpfs/qanguyen/poly1/\",\n",
    "              palette = sns.color_palette(\"Set3\", 10),\n",
    "               hue_variable = \"data_rescale\",\n",
    "               num_hidden_features_list = None,\n",
    "               max_epoch = 0\n",
    "):\n",
    "     \n",
    "    warnings.filterwarnings(action='once')\n",
    "    train_pars = defaultdict(list)\n",
    "    val_pars = defaultdict(list)\n",
    "    palette = palette.as_hex()\n",
    "    print(palette, len(palette))\n",
    "    #record_names = ['resnet18_rep_1673625625.387933.pkl', 'resnet18_rep_1673618285.140812.pkl', \n",
    "    #               'resnet18_rep_1673618285.124871.pkl', 'resnet18_rep_1673618315.142802.pkl',\n",
    "    #               'resnet18_rep_1673618403.386129.pkl', 'resnet18_rep_1673618403.386123.pkl',\n",
    "    #               'resnet18_rep_1673618381.887423.pkl', 'resnet18_rep_1673618474.561327.pkl',\n",
    "    #               'resnet18_rep_1673625654.48548.pkl', 'resnet18_rep_1673614260.528039.pkl']\n",
    "    \n",
    "#     record_names = ['resnet18_rep_1673873160.304721.pkl', 'resnet18_rep_1673873238.133468.pkl',\n",
    "#                   'resnet18_rep_1673873238.273423.pkl', 'resnet18_rep_1673873237.417957.pkl',\n",
    "#                   'resnet18_rep_1673873267.69003.pkl', 'resnet18_rep_1673873267.029088.pkl',\n",
    "#                   'resnet18_rep_1673873267.064156.pkl', 'resnet18_rep_1673873329.711897.pkl',\n",
    "#                   'resnet18_rep_1673873329.711921.pkl', 'resnet18_rep_1673873376.545421.pkl']\n",
    "    record_names = ['resnet18_rep_1674056611.865267.pkl', 'resnet18_rep_1674056612.392694.pkl',\n",
    "                  'resnet18_rep_1674056625.227239.pkl', 'resnet18_rep_1674057094.9487.pkl',\n",
    "                  'resnet18_rep_1674058958.82337.pkl', 'resnet18_rep_1674059096.368824.pkl',\n",
    "                  'resnet18_rep_1674059129.166538.pkl']#, \n",
    "#                     'resnet18_rep_1673873329.711897.pkl',\n",
    "#                   'resnet18_rep_1673873329.711921.pkl', 'resnet18_rep_1673873376.545421.pkl']\n",
    "    \n",
    "    record_names = glob.glob(f\"{outdir}/randomfeatures_JUN18*pth.tar\")\n",
    "    #record_included = [int(r.split(\"_\")[-1].split(\".\")[0]) for r in record_names]\n",
    "    #record_included = [((r > 1675853450) and (r < 1675912720)) for r in record_included]\n",
    "    #record_names = [ r for i,r in enumerate(record_names) if record_included[i] == True]\n",
    "    #print(record_names, len(record_names))\n",
    "    for _, f in enumerate(record_names) :\n",
    "        #print(f)\n",
    "        try:\n",
    "            \n",
    "            record = torch.load(f, map_location=\"cpu\") \n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "        \n",
    "        try:\n",
    "            pass\n",
    "            #if record.curr_epoch > 27:\n",
    "            #    continue\n",
    "            #print(w)\n",
    "              \n",
    "            #print( record.args )\n",
    "\n",
    "            #if (zero_out_list is not None) and (record.args.zero_out not in zero_out_list):\n",
    "            #    continue\n",
    "            \n",
    "            #if (num_hidden_features_list is not None) and (record.args.num_hidden_features not in num_hidden_features_list):   \n",
    "            #    continue\n",
    "            #if record.args.lr != 0.01:\n",
    "            #    continue\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            print(f, \"continue\", record.curr_epoch )\n",
    "            continue\n",
    "        \n",
    "        #print(f, \"plotting\" )\n",
    "        for epoch in [max_epoch]:\n",
    "        #for epoch in range( 1):\n",
    "            #print(epoch, f)\n",
    "            \n",
    "            #pars[\"data_rescale\"].append(record.data_rescale)\n",
    "            #pars[\"data_rescale\"].append(record.args.growth_factor)\n",
    "            #pars[\"tiling_imagenet\"].append(record.args.tiling_imagenet)\n",
    "            val_pars[\"block_size\"].append(f'{record.args.coarsegrain_blocksize}')\n",
    "            train_pars[\"block_size\"].extend( [record.args.coarsegrain_blocksize]) \n",
    "            train_pars[\"lr\"].extend( [record.args.lr]) \n",
    "            #val_pars[\"lr\"].append(f'{record.args.lr}')\n",
    "            #train_pars[\"lr\"].extend([ record.args.lr]  * len(record.metrics.train_losses[epoch]))\n",
    "            val_pars[\"P\"].append(record.args.num_hidden_features)\n",
    "            train_pars[\"P\"].extend([ record.args.num_hidden_features ])\n",
    "            width_after_pool = math.floor((224 - record.args.coarsegrain_blocksize) / record.args.coarsegrain_blocksize + 1)\n",
    "            D = 3*(width_after_pool)*(width_after_pool)\n",
    "            val_pars[\"D\"].append( D)\n",
    "            train_pars[\"D\"].extend([D]) \n",
    "            N =  record.args.num_train_samples\n",
    "            val_pars[\"N\"].append(N)\n",
    "            train_pars[\"N\"].extend([N])\n",
    "            val_pars[\"logP/D\"].append( np.log( record.args.num_hidden_features / D ))\n",
    "            train_pars[\"logP/D\"].extend([np.log( record.args.num_hidden_features / D) ])\n",
    "            val_pars[\"logN/D\"].append( np.log( N / D ))\n",
    "            train_pars[\"logN/D\"].extend([np.log( N / D) ])\n",
    "            #val_pars[\"P\"].append(f'{record.args.num_hidden_features}')\n",
    "            #train_pars[\"P\"].extend([ record.args.num_hidden_features ])\n",
    "            val_pars[\"epoch\"].append(epoch)\n",
    "            train_pars[\"epoch\"].append(epoch)\n",
    "            #mean_train_loss = np.mean([i  for i in record.metrics.train_losses[\"default\"][epoch] if i != 0.0])\n",
    "            train_pars[\"train_loss\"].append( (record.metrics.train_losses[epoch] ) )\n",
    "            train_pars[\"train_acc5\"].append( (record.metrics.train_acc5[epoch].item()) )\n",
    "            train_pars[\"train_acc1\"].append( (record.metrics.train_acc1[epoch].item()) )\n",
    "            #print( record.metrics.train_losses)\n",
    "            train_pars[\"test_loss\"].append( (record.metrics.val_losses[epoch]  ) )\n",
    "            train_pars[\"val_acc5\"].append( (record.metrics.val_acc5[epoch].item()) )\n",
    "            train_pars[\"val_acc1\"].append( (record.metrics.val_acc1[epoch].item()) )\n",
    "             \n",
    "             \n",
    "        #if _ > 40: break  \n",
    "        #print(\"record.args.coarsegrain_blocksize, record.args.num_hidden_features,  record.args.train_fraction\", record.args.coarsegrain_blocksize, record.args.num_hidden_features,  record.args.train_fraction,   record.metrics.val_losses[epoch])\n",
    "    line_kwargs    = dict(linewidth=0.5, alpha=0.7, style=hue_variable,\n",
    "             markers=False, markersize=8, markeredgecolor='white',\n",
    "             dashes=False)\n",
    "    figheight, figwidth = (12, 8)\n",
    "    fig, ax = plt.subplots(figsize=(figheight, figwidth))\n",
    "    print([(k, len(train_pars[k]) ) for k in train_pars])\n",
    "    train_pars = pd.DataFrame.from_dict(train_pars) \n",
    "    \n",
    "    #train_pars = train_pars.sort_values(['P','N','D',\"lr\"], ascending=True)#.drop_duplicates(['P','N', 'D']).dropna()\n",
    "    train_pars = train_pars.sort_values([\"test_loss\"], ascending=True).drop_duplicates(['P','N', 'D']).dropna()\n",
    "    train_loss = pd.pivot_table(train_pars, columns=\"logP/D\", index=\"logN/D\", values=\"train_loss\",\n",
    "                               aggfunc='mean'\n",
    "                               )\n",
    "   \n",
    "    # Interpolate \n",
    "    x = np.array(train_pars[\"logN/D\"])\n",
    "    y = np.array(train_pars[\"logP/D\"])\n",
    "    z = np.log(np.array(train_pars[\"train_loss\"]))\n",
    "    xx = np.array(train_loss.columns)\n",
    "    yy = np.array(train_loss.index.values.tolist())\n",
    "    xx, yy = np.meshgrid(xx, yy)\n",
    "    points = np.vstack([xx.flatten(), yy.flatten()]).T\n",
    "    \n",
    "    plt.contourf(xx, yy, \n",
    "                 interpolate.griddata(np.vstack((x, y)).T, z, points).reshape(xx.shape), \n",
    "              #   vmin=-25,vmax=30,\n",
    "                 cmap='Spectral_r')\n",
    "    plt.colorbar()\n",
    "    plt.scatter(x, y, \n",
    "               c = z,\n",
    "                 cmap='Spectral_r',\n",
    "            #   vmin=-25,vmax=30,\n",
    "               )\n",
    "    plt.scatter(x, y, \n",
    "               c = \"blue\",\n",
    "                marker=\"+\",\n",
    "                alpha=0.1\n",
    "               )\n",
    "    plt.plot(x, x, '-')\n",
    "    plt.xlabel(\"logN/D\")\n",
    "    plt.ylabel(\"logP/D\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Interpolate \n",
    "    fig, ax = plt.subplots(figsize=(figheight, figwidth))\n",
    "    x = np.array(train_pars[\"logN/D\"])\n",
    "    y = np.array(train_pars[\"logP/D\"])\n",
    "    z =np.log(np.array(train_pars[\"test_loss\"]))\n",
    "    xx = np.array(train_loss.columns)\n",
    "    yy = np.array(train_loss.index.values.tolist())\n",
    "    xx, yy = np.meshgrid(xx, yy)\n",
    "    points = np.vstack([xx.flatten(), yy.flatten()]).T\n",
    "    \n",
    "    plt.contourf(xx, yy, \n",
    "                 interpolate.griddata(np.vstack((x, y)).T, z, points).reshape(xx.shape), \n",
    "              #   vmin=-25,vmax=30,\n",
    "                 cmap='Spectral_r')\n",
    "    plt.colorbar()\n",
    "    plt.scatter(x, y, \n",
    "               c = z,\n",
    "                 cmap='Spectral_r',\n",
    "            #   vmin=-25,vmax=30,\n",
    "               )\n",
    "    plt.scatter(x, y, \n",
    "               c = \"blue\",\n",
    "                marker=\"+\",\n",
    "                alpha=0.1\n",
    "               )\n",
    "    plt.plot(x, x, '-')\n",
    "    plt.xlabel(\"logN/D\")\n",
    "    plt.ylabel(\"logP/D\")\n",
    "    plt.show()\n",
    "    \n",
    "     \n",
    "     \n",
    "import warnings\n",
    " \n",
    "workdir = \"/scratch/gpfs/qanguyen\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57944ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for num_hidden_features in (5, 10, 100, 1000, 5000, 10000, 50000, 100000):\n",
    "get_record(   \n",
    "           is_online=False, title = f\"Imagenet loss, loss vs. data_rescale\",\n",
    "           palette = sns.color_palette(\"deep\", 15),\n",
    "           outdir = f\"{workdir}/imagenet_info\",\n",
    "           image_transform_loader_list = ['SubsampleImagenet'],\n",
    "           hue_variable = \"block_size\",\n",
    "           num_hidden_features_list = None,\n",
    "    max_epoch =  99\n",
    ") \n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4245ff9d",
   "metadata": {},
   "source": [
    "## Diagonal slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be38ceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "pd.set_option('display.max_rows', 30000)\n",
    "\n",
    "def in_notebook():\n",
    "    try:\n",
    "        from IPython import get_ipython\n",
    "        if 'IPKernelApp' not in get_ipython().config:  # pragma: no cover\n",
    "            return False\n",
    "    except ImportError:\n",
    "        return False\n",
    "    except AttributeError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def show_plt_if_in_notebook(title=None):\n",
    "    if in_notebook():\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(title)\n",
    "def get_record(  is_online, extra = \"\", title = None,  \n",
    "               zero_out_list = None,\n",
    "               image_transform_loader_list = None,\n",
    "               tiling_orientation_ablation_list = None,\n",
    "               tiling_list = None,\n",
    "               outdir = \"/scratch/gpfs/qanguyen/poly1/\",\n",
    "              palette = sns.color_palette(\"Set3\", 10),\n",
    "               hue_variable = \"data_rescale\",\n",
    "               num_hidden_features_list = None,\n",
    "               max_epoch = 0\n",
    "):\n",
    "     \n",
    "    warnings.filterwarnings(action='once')\n",
    "    train_pars = defaultdict(list)\n",
    "    val_pars = defaultdict(list)\n",
    "    palette = palette.as_hex()\n",
    "    print(palette, len(palette))\n",
    "    #record_names = ['resnet18_rep_1673625625.387933.pkl', 'resnet18_rep_1673618285.140812.pkl', \n",
    "    #               'resnet18_rep_1673618285.124871.pkl', 'resnet18_rep_1673618315.142802.pkl',\n",
    "    #               'resnet18_rep_1673618403.386129.pkl', 'resnet18_rep_1673618403.386123.pkl',\n",
    "    #               'resnet18_rep_1673618381.887423.pkl', 'resnet18_rep_1673618474.561327.pkl',\n",
    "    #               'resnet18_rep_1673625654.48548.pkl', 'resnet18_rep_1673614260.528039.pkl']\n",
    "    \n",
    "#     record_names = ['resnet18_rep_1673873160.304721.pkl', 'resnet18_rep_1673873238.133468.pkl',\n",
    "#                   'resnet18_rep_1673873238.273423.pkl', 'resnet18_rep_1673873237.417957.pkl',\n",
    "#                   'resnet18_rep_1673873267.69003.pkl', 'resnet18_rep_1673873267.029088.pkl',\n",
    "#                   'resnet18_rep_1673873267.064156.pkl', 'resnet18_rep_1673873329.711897.pkl',\n",
    "#                   'resnet18_rep_1673873329.711921.pkl', 'resnet18_rep_1673873376.545421.pkl']\n",
    "    record_names = ['resnet18_rep_1674056611.865267.pkl', 'resnet18_rep_1674056612.392694.pkl',\n",
    "                  'resnet18_rep_1674056625.227239.pkl', 'resnet18_rep_1674057094.9487.pkl',\n",
    "                  'resnet18_rep_1674058958.82337.pkl', 'resnet18_rep_1674059096.368824.pkl',\n",
    "                  'resnet18_rep_1674059129.166538.pkl']#, \n",
    "#                     'resnet18_rep_1673873329.711897.pkl',\n",
    "#                   'resnet18_rep_1673873329.711921.pkl', 'resnet18_rep_1673873376.545421.pkl']\n",
    "    \n",
    "    record_names = glob.glob(f\"{outdir}/randomfeatures_JUN18*pth.tar\")\n",
    "    #record_included = [int(r.split(\"_\")[-1].split(\".\")[0]) for r in record_names]\n",
    "    #record_included = [((r > 1675853450) and (r < 1675912720)) for r in record_included]\n",
    "    #record_names = [ r for i,r in enumerate(record_names) if record_included[i] == True]\n",
    "    #print(record_names, len(record_names))\n",
    "    for _, f in enumerate(record_names) :\n",
    "        #print(f)\n",
    "        try:\n",
    "            \n",
    "            record = torch.load(f, map_location=\"cpu\") \n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "        \n",
    "        try:\n",
    "            pass\n",
    "            #if record.curr_epoch > 27:\n",
    "            #    continue\n",
    "            #print(w)\n",
    "              \n",
    "            #print( record.args )\n",
    "\n",
    "            #if (zero_out_list is not None) and (record.args.zero_out not in zero_out_list):\n",
    "            #    continue\n",
    "            \n",
    "            #if (num_hidden_features_list is not None) and (record.args.num_hidden_features not in num_hidden_features_list):   \n",
    "            #    continue\n",
    "            #if record.args.lr != 0.01:\n",
    "            #    continue\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            print(f, \"continue\", record.curr_epoch )\n",
    "            continue\n",
    "        \n",
    "        #print(f, \"plotting\" )\n",
    "        for epoch in [max_epoch]:\n",
    "        #for epoch in range( 1):\n",
    "            #print(epoch, f)\n",
    "            \n",
    "            #pars[\"data_rescale\"].append(record.data_rescale)\n",
    "            #pars[\"data_rescale\"].append(record.args.growth_factor)\n",
    "            #pars[\"tiling_imagenet\"].append(record.args.tiling_imagenet)\n",
    "            val_pars[\"block_size\"].append(f'{record.args.coarsegrain_blocksize}')\n",
    "            train_pars[\"block_size\"].extend( [record.args.coarsegrain_blocksize]) \n",
    "            train_pars[\"lr\"].extend( [record.args.lr]) \n",
    "            #val_pars[\"lr\"].append(f'{record.args.lr}')\n",
    "            #train_pars[\"lr\"].extend([ record.args.lr]  * len(record.metrics.train_losses[epoch]))\n",
    "            val_pars[\"P\"].append(record.args.num_hidden_features)\n",
    "            train_pars[\"P\"].extend([ record.args.num_hidden_features ])\n",
    "            width_after_pool = math.floor((224 - record.args.coarsegrain_blocksize) / record.args.coarsegrain_blocksize + 1)\n",
    "            D = 3*(width_after_pool)*(width_after_pool)\n",
    "            val_pars[\"D\"].append( D)\n",
    "            train_pars[\"D\"].extend([D]) \n",
    "            N =  record.args.num_train_samples\n",
    "            val_pars[\"N\"].append(N)\n",
    "            train_pars[\"N\"].extend([N])\n",
    "            val_pars[\"logP/D\"].append( np.log( record.args.num_hidden_features / D ))\n",
    "            train_pars[\"logP/D\"].extend([np.log( record.args.num_hidden_features / D) ])\n",
    "            val_pars[\"logN/D\"].append( np.log( N / D ))\n",
    "            train_pars[\"logN/D\"].extend([np.log( N / D) ])\n",
    "            #val_pars[\"P\"].append(f'{record.args.num_hidden_features}')\n",
    "            #train_pars[\"P\"].extend([ record.args.num_hidden_features ])\n",
    "            val_pars[\"epoch\"].append(epoch)\n",
    "            train_pars[\"epoch\"].append(epoch)\n",
    "            #mean_train_loss = np.mean([i  for i in record.metrics.train_losses[\"default\"][epoch] if i != 0.0])\n",
    "            train_pars[\"train_loss\"].append( (record.metrics.train_losses[epoch] ) )\n",
    "            train_pars[\"train_acc5\"].append( (record.metrics.train_acc5[epoch].item()) )\n",
    "            train_pars[\"train_acc1\"].append( (record.metrics.train_acc1[epoch].item()) )\n",
    "            #print( record.metrics.train_losses)\n",
    "            train_pars[\"test_loss\"].append( (record.metrics.val_losses[epoch]  ) )\n",
    "            train_pars[\"val_acc5\"].append( (record.metrics.val_acc5[epoch].item()) )\n",
    "            train_pars[\"val_acc1\"].append( (record.metrics.val_acc1[epoch].item()) )\n",
    "             \n",
    "             \n",
    "        #if _ > 40: break  \n",
    "        #print(\"record.args.coarsegrain_blocksize, record.args.num_hidden_features,  record.args.train_fraction\", record.args.coarsegrain_blocksize, record.args.num_hidden_features,  record.args.train_fraction,   record.metrics.val_losses[epoch])\n",
    "    line_kwargs    = dict(linewidth=0.5, alpha=0.7, style=hue_variable,\n",
    "             markers=False, markersize=8, markeredgecolor='white',\n",
    "             dashes=False)\n",
    "    figheight, figwidth = (12, 8)\n",
    "    \n",
    "    print([(k, len(train_pars[k]) ) for k in train_pars])\n",
    "    train_pars = pd.DataFrame.from_dict(train_pars) \n",
    "    \n",
    "    train_pars = train_pars.sort_values(['P','N','D',\"lr\"], ascending=True)#.drop_duplicates(['P','N', 'D']).dropna()\n",
    "    \n",
    "    #display(train_pars) \n",
    "    train_loss = pd.pivot_table(train_pars, columns=\"logP/D\", index=\"logN/D\", values=\"train_loss\",\n",
    "                               aggfunc='mean'\n",
    "                               )\n",
    "    \n",
    "    grouped = train_pars.groupby([\"P\", \"N\"])\n",
    "    fig, ax = plt.subplots(figsize=(figheight, figwidth))\n",
    "    idx=0\n",
    "    for (name, group) in (grouped):\n",
    "        l = (10, 100, 1000, 10000, 20000, 50000)\n",
    "        #if (name[0] not in l) or (name[1] not in l):\n",
    "        #    continue\n",
    "        if name[1] < 100:\n",
    "            continue\n",
    "        if name[0] < name[1] :\n",
    "            continue\n",
    "        #print(\"pre drop\", name)\n",
    "        group = group.sort_values(by=\"D\", ascending=True)\n",
    "        #display(group)\n",
    "        group = group.sort_values('test_loss', ascending=True).drop_duplicates(['P','N', 'D']).dropna()\n",
    "        #print(\"post drop\", name) \n",
    "        display(group.sort_values(by=\"D\", ascending=True))\n",
    "        #print(\"idx\",idx)\n",
    "        sns.lineplot(x=\"D\",y= \"test_loss\", data=group, label=f\"P={name[0]},N={name[1]}\", color=palette[idx])\n",
    "        idx += 1\n",
    "        \n",
    "    ax.set(xscale=\"log\" )\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(figheight, figwidth))\n",
    "    idx=0\n",
    "    for (name, group) in (grouped):\n",
    "        l = (10, 100, 1000, 10000, 20000, 50000)\n",
    "        #if (name[0] not in l) or (name[1] not in l):\n",
    "        #    continue\n",
    "        if name[1] < 100:\n",
    "            continue\n",
    "        if name[0] < name[1] :\n",
    "            continue\n",
    "        \n",
    "        group = group.sort_values(by=\"D\", ascending=True)\n",
    "        #display(group)\n",
    "        group = group.sort_values('val_acc5', ascending=True).drop_duplicates(['P','N', 'D']).dropna()\n",
    "        \n",
    "        #display(group.sort_values(by=\"D\", ascending=True))\n",
    "        \n",
    "        sns.lineplot(x=\"D\",y= \"val_acc5\", data=group, label=f\"P={name[0]},N={name[1]}\", color=palette[idx])\n",
    "        idx += 1\n",
    "    ax.set(xscale=\"log\" )\n",
    "    plt.legend()\n",
    "    plt.show() \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(figheight, figwidth))\n",
    "    idx=0\n",
    "    for (name, group) in (grouped):\n",
    "        l = (10, 100, 1000, 10000, 20000, 50000)\n",
    "        #if (name[0] not in l) or (name[1] not in l):\n",
    "        #    continue\n",
    "        if name[1] < 100:\n",
    "            continue\n",
    "        if name[0] < name[1] :\n",
    "            continue\n",
    "        #print(name)\n",
    "        group = group.sort_values(by=\"D\", ascending=True)\n",
    "        #display(group)\n",
    "        group = group.sort_values('val_acc1', ascending=True).drop_duplicates(['P','N', 'D']).dropna()\n",
    "        #display(group.sort_values(by=\"D\", ascending=True))\n",
    "        sns.lineplot(x=\"D\",y= \"val_acc1\", data=group, label=f\"P={name[0]},N={name[1]}\", color=palette[idx]) \n",
    "        idx += 1\n",
    "    ax.set(xscale=\"log\" )\n",
    "    plt.legend()\n",
    "    plt.show() \n",
    "    \n",
    "     \n",
    "import warnings\n",
    " \n",
    "workdir = \"/scratch/gpfs/qanguyen\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0678fccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b12eb33",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#for num_hidden_features in (5, 10, 100, 1000, 5000, 10000, 50000, 100000):\n",
    "get_record(   \n",
    "           is_online=False, title = f\"Imagenet loss, loss vs. data_rescale\",\n",
    "           palette = sns.color_palette(\"RdBu\", 15),\n",
    "           outdir = f\"{workdir}/imagenet_info\",\n",
    "           image_transform_loader_list = ['SubsampleImagenet'],\n",
    "           hue_variable = \"block_size\",\n",
    "           num_hidden_features_list = None,\n",
    "    max_epoch =  99\n",
    ") \n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5ea5fd",
   "metadata": {},
   "source": [
    "## Diagonal slices noisy class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0590b6d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddef0e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "pd.set_option('display.max_rows', 30000)\n",
    "\n",
    "def in_notebook():\n",
    "    try:\n",
    "        from IPython import get_ipython\n",
    "        if 'IPKernelApp' not in get_ipython().config:  # pragma: no cover\n",
    "            return False\n",
    "    except ImportError:\n",
    "        return False\n",
    "    except AttributeError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def show_plt_if_in_notebook(title=None):\n",
    "    if in_notebook():\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(title)\n",
    "def get_record(  is_online, extra = \"\", title = None,  \n",
    "               zero_out_list = None,\n",
    "               image_transform_loader_list = None,\n",
    "               tiling_orientation_ablation_list = None,\n",
    "               tiling_list = None,\n",
    "               outdir = \"/scratch/gpfs/qanguyen/poly1/\",\n",
    "              palette = sns.color_palette(\"Set3\", 10),\n",
    "               hue_variable = \"data_rescale\",\n",
    "               num_hidden_features_list = None,\n",
    "               max_epoch = 0\n",
    "):\n",
    "     \n",
    "    warnings.filterwarnings(action='once')\n",
    "    train_pars = defaultdict(list)\n",
    "    val_pars = defaultdict(list)\n",
    "    palette = palette.as_hex()\n",
    "    print(palette, len(palette))\n",
    "    #record_names = ['resnet18_rep_1673625625.387933.pkl', 'resnet18_rep_1673618285.140812.pkl', \n",
    "    #               'resnet18_rep_1673618285.124871.pkl', 'resnet18_rep_1673618315.142802.pkl',\n",
    "    #               'resnet18_rep_1673618403.386129.pkl', 'resnet18_rep_1673618403.386123.pkl',\n",
    "    #               'resnet18_rep_1673618381.887423.pkl', 'resnet18_rep_1673618474.561327.pkl',\n",
    "    #               'resnet18_rep_1673625654.48548.pkl', 'resnet18_rep_1673614260.528039.pkl']\n",
    "    \n",
    "#     record_names = ['resnet18_rep_1673873160.304721.pkl', 'resnet18_rep_1673873238.133468.pkl',\n",
    "#                   'resnet18_rep_1673873238.273423.pkl', 'resnet18_rep_1673873237.417957.pkl',\n",
    "#                   'resnet18_rep_1673873267.69003.pkl', 'resnet18_rep_1673873267.029088.pkl',\n",
    "#                   'resnet18_rep_1673873267.064156.pkl', 'resnet18_rep_1673873329.711897.pkl',\n",
    "#                   'resnet18_rep_1673873329.711921.pkl', 'resnet18_rep_1673873376.545421.pkl']\n",
    "    record_names = ['resnet18_rep_1674056611.865267.pkl', 'resnet18_rep_1674056612.392694.pkl',\n",
    "                  'resnet18_rep_1674056625.227239.pkl', 'resnet18_rep_1674057094.9487.pkl',\n",
    "                  'resnet18_rep_1674058958.82337.pkl', 'resnet18_rep_1674059096.368824.pkl',\n",
    "                  'resnet18_rep_1674059129.166538.pkl']#, \n",
    "#                     'resnet18_rep_1673873329.711897.pkl',\n",
    "#                   'resnet18_rep_1673873329.711921.pkl', 'resnet18_rep_1673873376.545421.pkl']\n",
    "    \n",
    "    record_names = glob.glob(f\"{outdir}/randomfeatures_JUN25*pth.tar\")\n",
    "    #record_included = [int(r.split(\"_\")[-1].split(\".\")[0]) for r in record_names]\n",
    "    #record_included = [((r > 1675853450) and (r < 1675912720)) for r in record_included]\n",
    "    #record_names = [ r for i,r in enumerate(record_names) if record_included[i] == True]\n",
    "    #print(record_names, len(record_names))\n",
    "    for _, f in enumerate(record_names) :\n",
    "        #print(f)\n",
    "        try:\n",
    "            \n",
    "            record = torch.load(f, map_location=\"cpu\") \n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "        \n",
    "        try:\n",
    "            pass\n",
    "            #if record.curr_epoch > 27:\n",
    "            #    continue\n",
    "            #print(w)\n",
    "              \n",
    "            #print( record.args )\n",
    "\n",
    "            #if (zero_out_list is not None) and (record.args.zero_out not in zero_out_list):\n",
    "            #    continue\n",
    "            \n",
    "            #if (num_hidden_features_list is not None) and (record.args.num_hidden_features not in num_hidden_features_list):   \n",
    "            #    continue\n",
    "            #if record.args.lr != 0.01:\n",
    "            #    continue\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            print(f, \"continue\", record.curr_epoch )\n",
    "            continue\n",
    "        \n",
    "        #print(f, \"plotting\" )\n",
    "        for epoch in [max_epoch]:\n",
    "        #for epoch in range( 1):\n",
    "            #print(epoch, f)\n",
    "            \n",
    "            #pars[\"data_rescale\"].append(record.data_rescale)\n",
    "            #pars[\"data_rescale\"].append(record.args.growth_factor)\n",
    "            #pars[\"tiling_imagenet\"].append(record.args.tiling_imagenet)\n",
    "            val_pars[\"block_size\"].append(f'{record.args.coarsegrain_blocksize}')\n",
    "            train_pars[\"block_size\"].extend( [record.args.coarsegrain_blocksize]) \n",
    "            train_pars[\"lr\"].extend( [record.args.lr]) \n",
    "            #val_pars[\"lr\"].append(f'{record.args.lr}')\n",
    "            #train_pars[\"lr\"].extend([ record.args.lr]  * len(record.metrics.train_losses[epoch]))\n",
    "            val_pars[\"P\"].append(record.args.num_hidden_features)\n",
    "            train_pars[\"P\"].extend([ record.args.num_hidden_features ])\n",
    "            width_after_pool = math.floor((224 - record.args.coarsegrain_blocksize) / record.args.coarsegrain_blocksize + 1)\n",
    "            D = 3*(width_after_pool)*(width_after_pool)\n",
    "            val_pars[\"D\"].append( D)\n",
    "            train_pars[\"D\"].extend([D]) \n",
    "            N =  record.args.num_train_samples\n",
    "            val_pars[\"N\"].append(N)\n",
    "            train_pars[\"N\"].extend([N])\n",
    "            val_pars[\"logP/D\"].append( np.log( record.args.num_hidden_features / D ))\n",
    "            train_pars[\"logP/D\"].extend([np.log( record.args.num_hidden_features / D) ])\n",
    "            val_pars[\"logN/D\"].append( np.log( N / D ))\n",
    "            train_pars[\"logN/D\"].extend([np.log( N / D) ])\n",
    "            #val_pars[\"P\"].append(f'{record.args.num_hidden_features}')\n",
    "            #train_pars[\"P\"].extend([ record.args.num_hidden_features ])\n",
    "            val_pars[\"epoch\"].append(epoch)\n",
    "            train_pars[\"epoch\"].append(epoch)\n",
    "            #mean_train_loss = np.mean([i  for i in record.metrics.train_losses[\"default\"][epoch] if i != 0.0])\n",
    "            train_pars[\"train_loss\"].append( (record.metrics.train_losses[epoch] ) )\n",
    "            train_pars[\"train_acc5\"].append( (record.metrics.train_acc5[epoch].item()) )\n",
    "            train_pars[\"train_acc1\"].append( (record.metrics.train_acc1[epoch].item()) )\n",
    "            #print( record.metrics.train_losses)\n",
    "            train_pars[\"test_loss\"].append( (record.metrics.val_losses[epoch]  ) )\n",
    "            train_pars[\"val_acc5\"].append( (record.metrics.val_acc5[epoch].item()) )\n",
    "            train_pars[\"val_acc1\"].append( (record.metrics.val_acc1[epoch].item()) )\n",
    "             \n",
    "             \n",
    "        #if _ > 40: break  \n",
    "        #print(\"record.args.coarsegrain_blocksize, record.args.num_hidden_features,  record.args.train_fraction\", record.args.coarsegrain_blocksize, record.args.num_hidden_features,  record.args.train_fraction,   record.metrics.val_losses[epoch])\n",
    "    line_kwargs    = dict(linewidth=0.5, alpha=0.7, style=hue_variable,\n",
    "             markers=False, markersize=8, markeredgecolor='white',\n",
    "             dashes=False)\n",
    "    figheight, figwidth = (12, 8)\n",
    "    \n",
    "    print([(k, len(train_pars[k]) ) for k in train_pars])\n",
    "    train_pars = pd.DataFrame.from_dict(train_pars) \n",
    "    \n",
    "    train_pars = train_pars.sort_values(['P','N','D',\"lr\"], ascending=True)#.drop_duplicates(['P','N', 'D']).dropna()\n",
    "    \n",
    "    #display(train_pars) \n",
    "    train_loss = pd.pivot_table(train_pars, columns=\"logP/D\", index=\"logN/D\", values=\"train_loss\",\n",
    "                               aggfunc='mean'\n",
    "                               )\n",
    "    \n",
    "    grouped = train_pars.groupby([\"P\", \"N\"])\n",
    "    fig, ax = plt.subplots(figsize=(figheight, figwidth))\n",
    "    idx=0\n",
    "    for (name, group) in (grouped):\n",
    "        l = (10, 100, 1000, 10000, 20000, 50000)\n",
    "        #if (name[0] not in l) or (name[1] not in l):\n",
    "        #    continue\n",
    "        if name[1] < 100:\n",
    "            continue\n",
    "        if name[0] < name[1] :\n",
    "            continue\n",
    "        print(\"pre drop\", name)\n",
    "        group = group.sort_values(by=\"D\", ascending=True)\n",
    "        display(group)\n",
    "        group = group.sort_values('test_loss', ascending=True).drop_duplicates(['P','N', 'D']).dropna()\n",
    "        print(\"post drop\", name) \n",
    "        display(group.sort_values(by=\"D\", ascending=True))\n",
    "        print(\"idx\",idx)\n",
    "        sns.lineplot(x=\"D\",y= \"test_loss\", data=group, label=f\"P={name[0]},N={name[1]}\", color=palette[idx])\n",
    "        idx += 1\n",
    "        \n",
    "    ax.set(xscale=\"log\" )\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(figheight, figwidth))\n",
    "    idx=0\n",
    "    for (name, group) in (grouped):\n",
    "        l = (10, 100, 1000, 10000, 20000, 50000)\n",
    "        #if (name[0] not in l) or (name[1] not in l):\n",
    "        #    continue\n",
    "        if name[1] < 100:\n",
    "            continue\n",
    "        if name[0] < name[1] :\n",
    "            continue\n",
    "        \n",
    "        group = group.sort_values(by=\"D\", ascending=True)\n",
    "        #display(group)\n",
    "        group = group.sort_values('val_acc5', ascending=True).drop_duplicates(['P','N', 'D']).dropna()\n",
    "        \n",
    "        #display(group.sort_values(by=\"D\", ascending=True))\n",
    "        \n",
    "        sns.lineplot(x=\"D\",y= \"val_acc5\", data=group, label=f\"P={name[0]},N={name[1]}\", color=palette[idx])\n",
    "        idx += 1\n",
    "    ax.set(xscale=\"log\" )\n",
    "    plt.legend()\n",
    "    plt.show() \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(figheight, figwidth))\n",
    "    idx=0\n",
    "    for (name, group) in (grouped):\n",
    "        l = (10, 100, 1000, 10000, 20000, 50000)\n",
    "        #if (name[0] not in l) or (name[1] not in l):\n",
    "        #    continue\n",
    "        if name[1] < 100:\n",
    "            continue\n",
    "        if name[0] < name[1] :\n",
    "            continue\n",
    "        #print(name)\n",
    "        group = group.sort_values(by=\"D\", ascending=True)\n",
    "        #display(group)\n",
    "        group = group.sort_values('val_acc1', ascending=True).drop_duplicates(['P','N', 'D']).dropna()\n",
    "        #display(group.sort_values(by=\"D\", ascending=True))\n",
    "        sns.lineplot(x=\"D\",y= \"val_acc1\", data=group, label=f\"P={name[0]},N={name[1]}\", color=palette[idx]) \n",
    "        idx += 1\n",
    "    ax.set(xscale=\"log\" )\n",
    "    plt.legend()\n",
    "    plt.show() \n",
    "    \n",
    "     \n",
    "import warnings\n",
    " \n",
    "workdir = \"/scratch/gpfs/qanguyen\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22df041",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for num_hidden_features in (5, 10, 100, 1000, 5000, 10000, 50000, 100000):\n",
    "get_record(   \n",
    "           is_online=False, title = f\"Imagenet loss, loss vs. data_rescale\",\n",
    "           palette = sns.color_palette(\"RdBu\", 15),\n",
    "           outdir = f\"{workdir}/imagenet_info\",\n",
    "           image_transform_loader_list = ['SubsampleImagenet'],\n",
    "           hue_variable = \"block_size\",\n",
    "           num_hidden_features_list = None,\n",
    "    max_epoch =  99\n",
    ") \n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bf56bc",
   "metadata": {},
   "source": [
    "## Loss as a function of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad1ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "\n",
    "def in_notebook():\n",
    "    try:\n",
    "        from IPython import get_ipython\n",
    "        if 'IPKernelApp' not in get_ipython().config:  # pragma: no cover\n",
    "            return False\n",
    "    except ImportError:\n",
    "        return False\n",
    "    except AttributeError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def show_plt_if_in_notebook(title=None):\n",
    "    if in_notebook():\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(title)\n",
    "def get_record(  is_online, extra = \"\", title = None,  \n",
    "               zero_out_list = None,\n",
    "               image_transform_loader_list = None,\n",
    "               tiling_orientation_ablation_list = None,\n",
    "               tiling_list = None,\n",
    "               outdir = \"/scratch/gpfs/qanguyen/poly1/\",\n",
    "              palette = sns.color_palette(\"Set3\", 10),\n",
    "               hue_variable = \"data_rescale\",\n",
    "               num_hidden_features_list = None,\n",
    "               max_epoch = 0\n",
    "):\n",
    "     \n",
    "    warnings.filterwarnings(action='once')\n",
    "    train_pars = defaultdict(list)\n",
    "    val_pars = defaultdict(list)\n",
    "    #record_names = ['resnet18_rep_1673625625.387933.pkl', 'resnet18_rep_1673618285.140812.pkl', \n",
    "    #               'resnet18_rep_1673618285.124871.pkl', 'resnet18_rep_1673618315.142802.pkl',\n",
    "    #               'resnet18_rep_1673618403.386129.pkl', 'resnet18_rep_1673618403.386123.pkl',\n",
    "    #               'resnet18_rep_1673618381.887423.pkl', 'resnet18_rep_1673618474.561327.pkl',\n",
    "    #               'resnet18_rep_1673625654.48548.pkl', 'resnet18_rep_1673614260.528039.pkl']\n",
    "    \n",
    "#     record_names = ['resnet18_rep_1673873160.304721.pkl', 'resnet18_rep_1673873238.133468.pkl',\n",
    "#                   'resnet18_rep_1673873238.273423.pkl', 'resnet18_rep_1673873237.417957.pkl',\n",
    "#                   'resnet18_rep_1673873267.69003.pkl', 'resnet18_rep_1673873267.029088.pkl',\n",
    "#                   'resnet18_rep_1673873267.064156.pkl', 'resnet18_rep_1673873329.711897.pkl',\n",
    "#                   'resnet18_rep_1673873329.711921.pkl', 'resnet18_rep_1673873376.545421.pkl']\n",
    "    record_names = ['resnet18_rep_1674056611.865267.pkl', 'resnet18_rep_1674056612.392694.pkl',\n",
    "                  'resnet18_rep_1674056625.227239.pkl', 'resnet18_rep_1674057094.9487.pkl',\n",
    "                  'resnet18_rep_1674058958.82337.pkl', 'resnet18_rep_1674059096.368824.pkl',\n",
    "                  'resnet18_rep_1674059129.166538.pkl']#, \n",
    "#                     'resnet18_rep_1673873329.711897.pkl',\n",
    "#                   'resnet18_rep_1673873329.711921.pkl', 'resnet18_rep_1673873376.545421.pkl']\n",
    "    \n",
    "    record_names = glob.glob(f\"{outdir}/randomfeatures_JUN18*pth.tar\")\n",
    "    #record_included = [int(r.split(\"_\")[-1].split(\".\")[0]) for r in record_names]\n",
    "    #record_included = [((r > 1675853450) and (r < 1675912720)) for r in record_included]\n",
    "    #record_names = [ r for i,r in enumerate(record_names) if record_included[i] == True]\n",
    "    #print(record_names, len(record_names))\n",
    "    for _, f in enumerate(record_names) :\n",
    "        #print(f)\n",
    "        try:\n",
    "            \n",
    "            record = torch.load(f, map_location=\"cpu\") \n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "        \n",
    "        try:\n",
    "             \n",
    "              \n",
    "            #print( record.args )\n",
    "\n",
    "           \n",
    "            if  (record.args.num_hidden_features != 10000) or (record.args.num_train_samples != 1000):   \n",
    "                continue\n",
    "            if  (record.args.lr != 0.001):\n",
    "                continue\n",
    "#             if (num_hidden_features_list is not None) and (record.args.num_hidden_features not in num_hidden_features_list):   \n",
    "#                 continue\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            print(f, \"continue\", record.curr_epoch )\n",
    "            continue\n",
    "        \n",
    "        print(  \"plotting\" ,record.args.num_hidden_features ,record.args.num_train_samples ,record.args.lr )\n",
    "        for epoch in range(max_epoch) :\n",
    "        #for epoch in range( 1):\n",
    "            #print(epoch, f)\n",
    "            \n",
    "            #pars[\"data_rescale\"].append(record.data_rescale)\n",
    "            #pars[\"data_rescale\"].append(record.args.growth_factor)\n",
    "            #pars[\"tiling_imagenet\"].append(record.args.tiling_imagenet)\n",
    "            val_pars[\"block_size\"].append(f'{record.args.coarsegrain_blocksize}')\n",
    "            train_pars[\"block_size\"].extend( [record.args.coarsegrain_blocksize]) \n",
    "            train_pars[\"lr\"].extend( [record.args.lr]) \n",
    "            #val_pars[\"lr\"].append(f'{record.args.lr}')\n",
    "            #train_pars[\"lr\"].extend([ record.args.lr]  * len(record.metrics.train_losses[epoch]))\n",
    "            val_pars[\"P\"].append(record.args.num_hidden_features)\n",
    "            train_pars[\"P\"].extend([ record.args.num_hidden_features ])\n",
    "            width_after_pool = math.floor((224 - record.args.coarsegrain_blocksize) / record.args.coarsegrain_blocksize + 1)\n",
    "            D = 3*(width_after_pool)*(width_after_pool)\n",
    "            val_pars[\"D\"].append( D)\n",
    "            train_pars[\"D\"].extend([D]) \n",
    "            N =  record.args.num_train_samples\n",
    "            val_pars[\"N\"].append(N)\n",
    "            train_pars[\"N\"].extend([N])\n",
    "            val_pars[\"logP/D\"].append( np.log( record.args.num_hidden_features / D ))\n",
    "            train_pars[\"logP/D\"].extend([np.log( record.args.num_hidden_features / D) ])\n",
    "            val_pars[\"logN/D\"].append( np.log( N / D ))\n",
    "            train_pars[\"logN/D\"].extend([np.log( N / D) ])\n",
    "            #val_pars[\"P\"].append(f'{record.args.num_hidden_features}')\n",
    "            #train_pars[\"P\"].extend([ record.args.num_hidden_features ])\n",
    "            val_pars[\"epoch\"].append(epoch)\n",
    "            train_pars[\"epoch\"].append(epoch)\n",
    "            #mean_train_loss = np.mean([i  for i in record.metrics.train_losses[\"default\"][epoch] if i != 0.0])\n",
    "            train_pars[\"train_loss\"].append( (record.metrics.train_losses[epoch]) )\n",
    "            #print( record.metrics.train_losses)\n",
    "            #train_pars[\"test_loss\"].append( (record.metrics.val_losses[epoch]  ) )\n",
    "             \n",
    "             \n",
    "        #if _ > 40: break  \n",
    "        #print(\"record.args.coarsegrain_blocksize, record.args.num_hidden_features,  record.args.train_fraction\", record.args.coarsegrain_blocksize, record.args.num_hidden_features,  record.args.train_fraction,   record.metrics.val_losses[epoch])\n",
    "    line_kwargs    = dict(linewidth=0.7, alpha=1.0, \n",
    "             markers=True, markersize=8, markeredgecolor='white',\n",
    "             dashes=False, palette=palette)\n",
    "    figheight, figwidth = (12, 8)\n",
    "    fig, ax = plt.subplots(figsize=(figheight, figwidth))\n",
    "    train_pars = pd.DataFrame.from_dict(train_pars)  \n",
    "    display(train_pars) \n",
    "    \n",
    "    sns.lineplot(x=\"epoch\",y= \"train_loss\", hue=\"D\", data=train_pars, **line_kwargs )\n",
    "    ax.set(  yscale=\"log\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "     \n",
    "import warnings\n",
    " \n",
    "workdir = \"/scratch/gpfs/qanguyen\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363d901f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59de266e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#for num_hidden_features in (5, 10, 100, 1000, 5000, 10000, 50000, 100000):\n",
    "get_record(   \n",
    "           is_online=False, title = f\"Imagenet loss, loss vs. data_rescale\",\n",
    "           palette = sns.color_palette(\"deep\", 15),\n",
    "           outdir = f\"{workdir}/imagenet_info\",\n",
    "           image_transform_loader_list = ['SubsampleImagenet'],\n",
    "           hue_variable = \"block_size\",\n",
    "           num_hidden_features_list = None,\n",
    "    max_epoch =  99\n",
    ") \n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4833bc",
   "metadata": {},
   "source": [
    "## Convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "699f41d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "\n",
    "def in_notebook():\n",
    "    try:\n",
    "        from IPython import get_ipython\n",
    "        if 'IPKernelApp' not in get_ipython().config:  # pragma: no cover\n",
    "            return False\n",
    "    except ImportError:\n",
    "        return False\n",
    "    except AttributeError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def show_plt_if_in_notebook(title=None):\n",
    "    if in_notebook():\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(title)\n",
    "def get_record(  is_online, extra = \"\", title = None,  \n",
    "               zero_out_list = None,\n",
    "               image_transform_loader_list = None,\n",
    "               tiling_orientation_ablation_list = None,\n",
    "               tiling_list = None,\n",
    "               outdir = \"/scratch/gpfs/qanguyen/poly1/\",\n",
    "              palette = sns.color_palette(\"Set3\", 10),\n",
    "               hue_variable = \"data_rescale\",\n",
    "               num_hidden_features_list = None,\n",
    "               max_epoch = 0\n",
    "):\n",
    "     \n",
    "    warnings.filterwarnings(action='once')\n",
    "    train_pars = defaultdict(list)\n",
    "    val_pars = defaultdict(list)\n",
    "    #record_names = ['resnet18_rep_1673625625.387933.pkl', 'resnet18_rep_1673618285.140812.pkl', \n",
    "    #               'resnet18_rep_1673618285.124871.pkl', 'resnet18_rep_1673618315.142802.pkl',\n",
    "    #               'resnet18_rep_1673618403.386129.pkl', 'resnet18_rep_1673618403.386123.pkl',\n",
    "    #               'resnet18_rep_1673618381.887423.pkl', 'resnet18_rep_1673618474.561327.pkl',\n",
    "    #               'resnet18_rep_1673625654.48548.pkl', 'resnet18_rep_1673614260.528039.pkl']\n",
    "    \n",
    "#     record_names = ['resnet18_rep_1673873160.304721.pkl', 'resnet18_rep_1673873238.133468.pkl',\n",
    "#                   'resnet18_rep_1673873238.273423.pkl', 'resnet18_rep_1673873237.417957.pkl',\n",
    "#                   'resnet18_rep_1673873267.69003.pkl', 'resnet18_rep_1673873267.029088.pkl',\n",
    "#                   'resnet18_rep_1673873267.064156.pkl', 'resnet18_rep_1673873329.711897.pkl',\n",
    "#                   'resnet18_rep_1673873329.711921.pkl', 'resnet18_rep_1673873376.545421.pkl']\n",
    "    record_names = ['resnet18_rep_1674056611.865267.pkl', 'resnet18_rep_1674056612.392694.pkl',\n",
    "                  'resnet18_rep_1674056625.227239.pkl', 'resnet18_rep_1674057094.9487.pkl',\n",
    "                  'resnet18_rep_1674058958.82337.pkl', 'resnet18_rep_1674059096.368824.pkl',\n",
    "                  'resnet18_rep_1674059129.166538.pkl']#, \n",
    "#                     'resnet18_rep_1673873329.711897.pkl',\n",
    "#                   'resnet18_rep_1673873329.711921.pkl', 'resnet18_rep_1673873376.545421.pkl']\n",
    "    \n",
    "    record_names = glob.glob(f\"{outdir}/conv_superclass_JUN27*pth.tar\")\n",
    "    #record_included = [int(r.split(\"_\")[-1].split(\".\")[0]) for r in record_names]\n",
    "    #record_included = [((r > 1675853450) and (r < 1675912720)) for r in record_included]\n",
    "    #record_names = [ r for i,r in enumerate(record_names) if record_included[i] == True]\n",
    "    #print(record_names, len(record_names))\n",
    "    for _, f in enumerate(record_names) :\n",
    "        #print(f)\n",
    "        try:\n",
    "            \n",
    "            record = torch.load(f, map_location=\"cpu\") \n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "        \n",
    "        try:\n",
    "            pass\n",
    "              \n",
    "            #print( record.args )\n",
    "\n",
    "           \n",
    "            #if  (record.args.num_hidden_features != 10000) or (record.args.num_train_samples != 1000):   \n",
    "            #    continue\n",
    "            #if  (record.args.lr != 0.001):\n",
    "            #    continue\n",
    "#             if (num_hidden_features_list is not None) and (record.args.num_hidden_features not in num_hidden_features_list):   \n",
    "#                 continue\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            print(f, \"continue\", record.curr_epoch )\n",
    "            continue\n",
    "        \n",
    "        print(  \"plotting\" ,record.args.num_hidden_features ,record.args.num_train_samples ,record.args.lr )\n",
    "        for epoch in [max_epoch] :\n",
    "        #for epoch in range( 1):\n",
    "            #print(epoch, f)\n",
    "            \n",
    "            #pars[\"data_rescale\"].append(record.data_rescale)\n",
    "            #pars[\"data_rescale\"].append(record.args.growth_factor)\n",
    "            #pars[\"tiling_imagenet\"].append(record.args.tiling_imagenet)\n",
    "            val_pars[\"block_size\"].append(f'{record.args.coarsegrain_blocksize}')\n",
    "            train_pars[\"block_size\"].extend( [record.args.coarsegrain_blocksize]) \n",
    "            train_pars[\"lr\"].extend( [record.args.lr]) \n",
    "            #val_pars[\"lr\"].append(f'{record.args.lr}')\n",
    "            #train_pars[\"lr\"].extend([ record.args.lr]  * len(record.metrics.train_losses[epoch]))\n",
    "            val_pars[\"P\"].append(record.args.num_hidden_features)\n",
    "            train_pars[\"P\"].extend([ record.args.num_hidden_features ])\n",
    "            width_after_pool = math.floor((224 - record.args.coarsegrain_blocksize) / record.args.coarsegrain_blocksize + 1)\n",
    "            D = 3*(width_after_pool)*(width_after_pool)\n",
    "            val_pars[\"D\"].append( D)\n",
    "            train_pars[\"D\"].extend([D]) \n",
    "            N =  record.args.num_train_samples\n",
    "            val_pars[\"N\"].append(N)\n",
    "            train_pars[\"N\"].extend([N])\n",
    "            val_pars[\"logP/D\"].append( np.log( record.args.num_hidden_features / D ))\n",
    "            train_pars[\"logP/D\"].extend([np.log( record.args.num_hidden_features / D) ])\n",
    "            val_pars[\"logN/D\"].append( np.log( N / D ))\n",
    "            train_pars[\"logN/D\"].extend([np.log( N / D) ])\n",
    "            #val_pars[\"P\"].append(f'{record.args.num_hidden_features}')\n",
    "            #train_pars[\"P\"].extend([ record.args.num_hidden_features ])\n",
    "            val_pars[\"epoch\"].append(epoch)\n",
    "            train_pars[\"epoch\"].append(epoch)\n",
    "            #mean_train_loss = np.mean([i  for i in record.metrics.train_losses[\"default\"][epoch] if i != 0.0])\n",
    "            train_pars[\"train_loss\"].append( (record.metrics.train_losses[epoch]) )\n",
    "            #print( record.metrics.train_losses)\n",
    "            train_pars[\"test_loss\"].append( (record.metrics.val_losses[epoch]  ) )\n",
    "            train_pars[\"train_acc5\"].append( (record.metrics.train_acc5[epoch]  ) )\n",
    "            train_pars[\"train_acc1\"].append( (record.metrics.train_acc1[epoch]  ) )\n",
    "             \n",
    "            train_pars[\"val_acc5\"].append( (record.metrics.val_acc5[epoch]  ) )\n",
    "            train_pars[\"val_acc1\"].append( (record.metrics.val_acc1[epoch]  ) )\n",
    "             \n",
    "        #if _ > 40: break  \n",
    "        #print(\"record.args.coarsegrain_blocksize, record.args.num_hidden_features,  record.args.train_fraction\", record.args.coarsegrain_blocksize, record.args.num_hidden_features,  record.args.train_fraction,   record.metrics.val_losses[epoch])\n",
    "    line_kwargs    = dict(linewidth=0.7, alpha=1.0, \n",
    "             markers=True, markersize=8, markeredgecolor='white',\n",
    "             dashes=False, palette=palette)\n",
    "    figheight, figwidth = (12, 8)\n",
    "    fig, ax = plt.subplots(figsize=(figheight, figwidth))\n",
    "    train_pars = pd.DataFrame.from_dict(train_pars)  \n",
    "    train_pars = train_pars.sort_values(\"N\", ascending=True)\n",
    "    display(train_pars) \n",
    "    \n",
    "    sns.lineplot(x=\"N\",y= \"train_loss\", hue=\"D\", data=train_pars, **line_kwargs )\n",
    "    ax.set(  yscale=\"log\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    figheight, figwidth = (12, 8)\n",
    "    fig, ax = plt.subplots(figsize=(figheight, figwidth))\n",
    "    train_pars = pd.DataFrame.from_dict(train_pars)  \n",
    "    display(train_pars) \n",
    "    \n",
    "    sns.lineplot(x=\"N\",y= \"test_loss\", hue=\"D\", data=train_pars, **line_kwargs )\n",
    "    ax.set(  yscale=\"log\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "     \n",
    "import warnings\n",
    " \n",
    "workdir = \"/scratch/gpfs/qanguyen\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30546dc5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotting 0 1000 0.1\n",
      "plotting 0 10 0.1\n",
      "plotting 0 10000 0.01\n",
      "plotting 0 100 0.01\n",
      "plotting 0 10 0.01\n",
      "plotting 0 10000 0.1\n",
      "plotting 0 10 0.1\n",
      "plotting 0 5000 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qanguyen/anaconda3/envs/renormalization/lib/python3.7/site-packages/ipykernel_launcher.py:107: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotting 0 10 0.01\n",
      "plotting 0 100 0.1\n",
      "plotting 0 50000 0.01\n",
      "plotting 0 5000 0.1\n",
      "plotting 0 50000 0.1\n",
      "plotting 0 100000 0.1\n",
      "plotting 0 1000 0.01\n",
      "plotting 0 100000 0.01\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>P</th>\n",
       "      <th>D</th>\n",
       "      <th>N</th>\n",
       "      <th>logP/D</th>\n",
       "      <th>logN/D</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>train_acc5</th>\n",
       "      <th>train_acc1</th>\n",
       "      <th>val_acc5</th>\n",
       "      <th>val_acc1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>150528</td>\n",
       "      <td>10</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-9.619319</td>\n",
       "      <td>99</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>42.705785</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(56.7820)</td>\n",
       "      <td>tensor(13.9940)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>150528</td>\n",
       "      <td>10</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-9.619319</td>\n",
       "      <td>99</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>8.492419</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(58.1260)</td>\n",
       "      <td>tensor(13.4000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>150528</td>\n",
       "      <td>10</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-9.619319</td>\n",
       "      <td>99</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>32.670654</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(56.9440)</td>\n",
       "      <td>tensor(11.6320)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>150528</td>\n",
       "      <td>10</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-9.619319</td>\n",
       "      <td>99</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>9.265911</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(57.8200)</td>\n",
       "      <td>tensor(13.5580)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>150528</td>\n",
       "      <td>100</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-7.316734</td>\n",
       "      <td>99</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>3.829030</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(57.5460)</td>\n",
       "      <td>tensor(17.9200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>150528</td>\n",
       "      <td>100</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-7.316734</td>\n",
       "      <td>99</td>\n",
       "      <td>1.327262</td>\n",
       "      <td>3.726766</td>\n",
       "      <td>tensor(93.)</td>\n",
       "      <td>tensor(54.)</td>\n",
       "      <td>tensor(54.4480)</td>\n",
       "      <td>tensor(12.8860)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>150528</td>\n",
       "      <td>1000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-5.014149</td>\n",
       "      <td>99</td>\n",
       "      <td>0.428273</td>\n",
       "      <td>3.951138</td>\n",
       "      <td>tensor(99.8000)</td>\n",
       "      <td>tensor(87.7000)</td>\n",
       "      <td>tensor(63.8060)</td>\n",
       "      <td>tensor(19.5240)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>150528</td>\n",
       "      <td>1000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-5.014149</td>\n",
       "      <td>99</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>3.089814</td>\n",
       "      <td>tensor(100.0000)</td>\n",
       "      <td>tensor(100.0000)</td>\n",
       "      <td>tensor(72.8800)</td>\n",
       "      <td>tensor(25.6700)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>150528</td>\n",
       "      <td>5000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-3.404711</td>\n",
       "      <td>99</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>3.380503</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(77.1220)</td>\n",
       "      <td>tensor(28.8880)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>150528</td>\n",
       "      <td>5000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-3.404711</td>\n",
       "      <td>99</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>4.168438</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(78.4180)</td>\n",
       "      <td>tensor(29.6140)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>150528</td>\n",
       "      <td>10000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-2.711564</td>\n",
       "      <td>99</td>\n",
       "      <td>0.003034</td>\n",
       "      <td>4.439668</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(99.9900)</td>\n",
       "      <td>tensor(76.8040)</td>\n",
       "      <td>tensor(28.8860)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>150528</td>\n",
       "      <td>10000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-2.711564</td>\n",
       "      <td>99</td>\n",
       "      <td>0.003872</td>\n",
       "      <td>3.957560</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(99.9700)</td>\n",
       "      <td>tensor(81.2220)</td>\n",
       "      <td>tensor(33.8160)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>150528</td>\n",
       "      <td>50000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-1.102126</td>\n",
       "      <td>99</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>3.098319</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(86.3460)</td>\n",
       "      <td>tensor(41.3480)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>150528</td>\n",
       "      <td>50000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-1.102126</td>\n",
       "      <td>99</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>2.175500</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(86.4560)</td>\n",
       "      <td>tensor(43.2020)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>150528</td>\n",
       "      <td>100000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-0.408979</td>\n",
       "      <td>99</td>\n",
       "      <td>0.083440</td>\n",
       "      <td>3.318907</td>\n",
       "      <td>tensor(99.9870)</td>\n",
       "      <td>tensor(97.1790)</td>\n",
       "      <td>tensor(88.0160)</td>\n",
       "      <td>tensor(43.0540)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>150528</td>\n",
       "      <td>100000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-0.408979</td>\n",
       "      <td>99</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>2.655457</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(99.9930)</td>\n",
       "      <td>tensor(88.9120)</td>\n",
       "      <td>tensor(46.9200)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    block_size    lr  P       D       N  logP/D    logN/D  epoch  train_loss  \\\n",
       "1            1  0.10  0  150528      10    -inf -9.619319     99    0.000150   \n",
       "4            1  0.01  0  150528      10    -inf -9.619319     99    0.000290   \n",
       "6            1  0.10  0  150528      10    -inf -9.619319     99    0.000329   \n",
       "8            1  0.01  0  150528      10    -inf -9.619319     99    0.000261   \n",
       "3            1  0.01  0  150528     100    -inf -7.316734     99    0.002632   \n",
       "9            1  0.10  0  150528     100    -inf -7.316734     99    1.327262   \n",
       "0            1  0.10  0  150528    1000    -inf -5.014149     99    0.428273   \n",
       "14           1  0.01  0  150528    1000    -inf -5.014149     99    0.001529   \n",
       "7            1  0.01  0  150528    5000    -inf -3.404711     99    0.000358   \n",
       "11           1  0.10  0  150528    5000    -inf -3.404711     99    0.000196   \n",
       "2            1  0.01  0  150528   10000    -inf -2.711564     99    0.003034   \n",
       "5            1  0.10  0  150528   10000    -inf -2.711564     99    0.003872   \n",
       "10           1  0.01  0  150528   50000    -inf -1.102126     99    0.000217   \n",
       "12           1  0.10  0  150528   50000    -inf -1.102126     99    0.000469   \n",
       "13           1  0.10  0  150528  100000    -inf -0.408979     99    0.083440   \n",
       "15           1  0.01  0  150528  100000    -inf -0.408979     99    0.000504   \n",
       "\n",
       "    test_loss        train_acc5        train_acc1         val_acc5  \\\n",
       "1   42.705785      tensor(100.)      tensor(100.)  tensor(56.7820)   \n",
       "4    8.492419      tensor(100.)      tensor(100.)  tensor(58.1260)   \n",
       "6   32.670654      tensor(100.)      tensor(100.)  tensor(56.9440)   \n",
       "8    9.265911      tensor(100.)      tensor(100.)  tensor(57.8200)   \n",
       "3    3.829030      tensor(100.)      tensor(100.)  tensor(57.5460)   \n",
       "9    3.726766       tensor(93.)       tensor(54.)  tensor(54.4480)   \n",
       "0    3.951138   tensor(99.8000)   tensor(87.7000)  tensor(63.8060)   \n",
       "14   3.089814  tensor(100.0000)  tensor(100.0000)  tensor(72.8800)   \n",
       "7    3.380503      tensor(100.)      tensor(100.)  tensor(77.1220)   \n",
       "11   4.168438      tensor(100.)      tensor(100.)  tensor(78.4180)   \n",
       "2    4.439668      tensor(100.)   tensor(99.9900)  tensor(76.8040)   \n",
       "5    3.957560      tensor(100.)   tensor(99.9700)  tensor(81.2220)   \n",
       "10   3.098319      tensor(100.)      tensor(100.)  tensor(86.3460)   \n",
       "12   2.175500      tensor(100.)      tensor(100.)  tensor(86.4560)   \n",
       "13   3.318907   tensor(99.9870)   tensor(97.1790)  tensor(88.0160)   \n",
       "15   2.655457      tensor(100.)   tensor(99.9930)  tensor(88.9120)   \n",
       "\n",
       "           val_acc1  \n",
       "1   tensor(13.9940)  \n",
       "4   tensor(13.4000)  \n",
       "6   tensor(11.6320)  \n",
       "8   tensor(13.5580)  \n",
       "3   tensor(17.9200)  \n",
       "9   tensor(12.8860)  \n",
       "0   tensor(19.5240)  \n",
       "14  tensor(25.6700)  \n",
       "7   tensor(28.8880)  \n",
       "11  tensor(29.6140)  \n",
       "2   tensor(28.8860)  \n",
       "5   tensor(33.8160)  \n",
       "10  tensor(41.3480)  \n",
       "12  tensor(43.2020)  \n",
       "13  tensor(43.0540)  \n",
       "15  tensor(46.9200)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qanguyen/anaconda3/envs/renormalization/lib/python3.7/site-packages/ipykernel_launcher.py:136: UserWarning: The palette list has more values (15) than needed (1), which may not be intended.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>P</th>\n",
       "      <th>D</th>\n",
       "      <th>N</th>\n",
       "      <th>logP/D</th>\n",
       "      <th>logN/D</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>train_acc5</th>\n",
       "      <th>train_acc1</th>\n",
       "      <th>val_acc5</th>\n",
       "      <th>val_acc1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>150528</td>\n",
       "      <td>10</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-9.619319</td>\n",
       "      <td>99</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>42.705785</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(56.7820)</td>\n",
       "      <td>tensor(13.9940)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>150528</td>\n",
       "      <td>10</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-9.619319</td>\n",
       "      <td>99</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>8.492419</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(58.1260)</td>\n",
       "      <td>tensor(13.4000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>150528</td>\n",
       "      <td>10</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-9.619319</td>\n",
       "      <td>99</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>32.670654</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(56.9440)</td>\n",
       "      <td>tensor(11.6320)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>150528</td>\n",
       "      <td>10</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-9.619319</td>\n",
       "      <td>99</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>9.265911</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(57.8200)</td>\n",
       "      <td>tensor(13.5580)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>150528</td>\n",
       "      <td>100</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-7.316734</td>\n",
       "      <td>99</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>3.829030</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(57.5460)</td>\n",
       "      <td>tensor(17.9200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>150528</td>\n",
       "      <td>100</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-7.316734</td>\n",
       "      <td>99</td>\n",
       "      <td>1.327262</td>\n",
       "      <td>3.726766</td>\n",
       "      <td>tensor(93.)</td>\n",
       "      <td>tensor(54.)</td>\n",
       "      <td>tensor(54.4480)</td>\n",
       "      <td>tensor(12.8860)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>150528</td>\n",
       "      <td>1000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-5.014149</td>\n",
       "      <td>99</td>\n",
       "      <td>0.428273</td>\n",
       "      <td>3.951138</td>\n",
       "      <td>tensor(99.8000)</td>\n",
       "      <td>tensor(87.7000)</td>\n",
       "      <td>tensor(63.8060)</td>\n",
       "      <td>tensor(19.5240)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>150528</td>\n",
       "      <td>1000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-5.014149</td>\n",
       "      <td>99</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>3.089814</td>\n",
       "      <td>tensor(100.0000)</td>\n",
       "      <td>tensor(100.0000)</td>\n",
       "      <td>tensor(72.8800)</td>\n",
       "      <td>tensor(25.6700)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>150528</td>\n",
       "      <td>5000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-3.404711</td>\n",
       "      <td>99</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>3.380503</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(77.1220)</td>\n",
       "      <td>tensor(28.8880)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>150528</td>\n",
       "      <td>5000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-3.404711</td>\n",
       "      <td>99</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>4.168438</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(78.4180)</td>\n",
       "      <td>tensor(29.6140)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>150528</td>\n",
       "      <td>10000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-2.711564</td>\n",
       "      <td>99</td>\n",
       "      <td>0.003034</td>\n",
       "      <td>4.439668</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(99.9900)</td>\n",
       "      <td>tensor(76.8040)</td>\n",
       "      <td>tensor(28.8860)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>150528</td>\n",
       "      <td>10000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-2.711564</td>\n",
       "      <td>99</td>\n",
       "      <td>0.003872</td>\n",
       "      <td>3.957560</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(99.9700)</td>\n",
       "      <td>tensor(81.2220)</td>\n",
       "      <td>tensor(33.8160)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>150528</td>\n",
       "      <td>50000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-1.102126</td>\n",
       "      <td>99</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>3.098319</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(86.3460)</td>\n",
       "      <td>tensor(41.3480)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>150528</td>\n",
       "      <td>50000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-1.102126</td>\n",
       "      <td>99</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>2.175500</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(86.4560)</td>\n",
       "      <td>tensor(43.2020)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>150528</td>\n",
       "      <td>100000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-0.408979</td>\n",
       "      <td>99</td>\n",
       "      <td>0.083440</td>\n",
       "      <td>3.318907</td>\n",
       "      <td>tensor(99.9870)</td>\n",
       "      <td>tensor(97.1790)</td>\n",
       "      <td>tensor(88.0160)</td>\n",
       "      <td>tensor(43.0540)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>150528</td>\n",
       "      <td>100000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-0.408979</td>\n",
       "      <td>99</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>2.655457</td>\n",
       "      <td>tensor(100.)</td>\n",
       "      <td>tensor(99.9930)</td>\n",
       "      <td>tensor(88.9120)</td>\n",
       "      <td>tensor(46.9200)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    block_size    lr  P       D       N  logP/D    logN/D  epoch  train_loss  \\\n",
       "1            1  0.10  0  150528      10    -inf -9.619319     99    0.000150   \n",
       "4            1  0.01  0  150528      10    -inf -9.619319     99    0.000290   \n",
       "6            1  0.10  0  150528      10    -inf -9.619319     99    0.000329   \n",
       "8            1  0.01  0  150528      10    -inf -9.619319     99    0.000261   \n",
       "3            1  0.01  0  150528     100    -inf -7.316734     99    0.002632   \n",
       "9            1  0.10  0  150528     100    -inf -7.316734     99    1.327262   \n",
       "0            1  0.10  0  150528    1000    -inf -5.014149     99    0.428273   \n",
       "14           1  0.01  0  150528    1000    -inf -5.014149     99    0.001529   \n",
       "7            1  0.01  0  150528    5000    -inf -3.404711     99    0.000358   \n",
       "11           1  0.10  0  150528    5000    -inf -3.404711     99    0.000196   \n",
       "2            1  0.01  0  150528   10000    -inf -2.711564     99    0.003034   \n",
       "5            1  0.10  0  150528   10000    -inf -2.711564     99    0.003872   \n",
       "10           1  0.01  0  150528   50000    -inf -1.102126     99    0.000217   \n",
       "12           1  0.10  0  150528   50000    -inf -1.102126     99    0.000469   \n",
       "13           1  0.10  0  150528  100000    -inf -0.408979     99    0.083440   \n",
       "15           1  0.01  0  150528  100000    -inf -0.408979     99    0.000504   \n",
       "\n",
       "    test_loss        train_acc5        train_acc1         val_acc5  \\\n",
       "1   42.705785      tensor(100.)      tensor(100.)  tensor(56.7820)   \n",
       "4    8.492419      tensor(100.)      tensor(100.)  tensor(58.1260)   \n",
       "6   32.670654      tensor(100.)      tensor(100.)  tensor(56.9440)   \n",
       "8    9.265911      tensor(100.)      tensor(100.)  tensor(57.8200)   \n",
       "3    3.829030      tensor(100.)      tensor(100.)  tensor(57.5460)   \n",
       "9    3.726766       tensor(93.)       tensor(54.)  tensor(54.4480)   \n",
       "0    3.951138   tensor(99.8000)   tensor(87.7000)  tensor(63.8060)   \n",
       "14   3.089814  tensor(100.0000)  tensor(100.0000)  tensor(72.8800)   \n",
       "7    3.380503      tensor(100.)      tensor(100.)  tensor(77.1220)   \n",
       "11   4.168438      tensor(100.)      tensor(100.)  tensor(78.4180)   \n",
       "2    4.439668      tensor(100.)   tensor(99.9900)  tensor(76.8040)   \n",
       "5    3.957560      tensor(100.)   tensor(99.9700)  tensor(81.2220)   \n",
       "10   3.098319      tensor(100.)      tensor(100.)  tensor(86.3460)   \n",
       "12   2.175500      tensor(100.)      tensor(100.)  tensor(86.4560)   \n",
       "13   3.318907   tensor(99.9870)   tensor(97.1790)  tensor(88.0160)   \n",
       "15   2.655457      tensor(100.)   tensor(99.9930)  tensor(88.9120)   \n",
       "\n",
       "           val_acc1  \n",
       "1   tensor(13.9940)  \n",
       "4   tensor(13.4000)  \n",
       "6   tensor(11.6320)  \n",
       "8   tensor(13.5580)  \n",
       "3   tensor(17.9200)  \n",
       "9   tensor(12.8860)  \n",
       "0   tensor(19.5240)  \n",
       "14  tensor(25.6700)  \n",
       "7   tensor(28.8880)  \n",
       "11  tensor(29.6140)  \n",
       "2   tensor(28.8860)  \n",
       "5   tensor(33.8160)  \n",
       "10  tensor(41.3480)  \n",
       "12  tensor(43.2020)  \n",
       "13  tensor(43.0540)  \n",
       "15  tensor(46.9200)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qanguyen/anaconda3/envs/renormalization/lib/python3.7/site-packages/ipykernel_launcher.py:146: UserWarning: The palette list has more values (15) than needed (1), which may not be intended.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#for num_hidden_features in (5, 10, 100, 1000, 5000, 10000, 50000, 100000):\n",
    "get_record(   \n",
    "           is_online=False, title = f\"Imagenet loss, loss vs. data_rescale\",\n",
    "           palette = sns.color_palette(\"RdBu\", 15),\n",
    "           outdir = f\"{workdir}/imagenet_info\",\n",
    "           image_transform_loader_list = ['SubsampleImagenet'],\n",
    "           hue_variable = \"block_size\",\n",
    "           num_hidden_features_list = None,\n",
    "    max_epoch =  99\n",
    ") \n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75995cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08afb462",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (renormalization)",
   "language": "python",
   "name": "renormalization"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "267.641px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
